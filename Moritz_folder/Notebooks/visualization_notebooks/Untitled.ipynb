{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all relevant packages\n",
    "import torch, torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from backpack import backpack, extend\n",
    "from backpack.extensions import DiagHessian\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from scipy.stats import pearsonr\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "import mpl_toolkits as mpl\n",
    "from scipy.stats import chi2, norm\n",
    "import random\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams[\"mpl_toolkits.legacy_colorbar\"] = False\n",
    "\n",
    "s=2\n",
    "np.random.seed(s)\n",
    "torch.manual_seed(s)\n",
    "torch.cuda.manual_seed(s)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "#plt stuff\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN():\n",
    "    \n",
    "    features = torch.nn.Sequential(\n",
    "        torch.nn.Linear(1, 1),\n",
    "        #torch.nn.Linear(1, 2)\n",
    "    )\n",
    "    return(features)\n",
    "\n",
    "net = NN()\n",
    "loss_function = torch.nn.MSELoss()\n",
    "\n",
    "train_optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([-0.7715,  0.9238,  0.0902, -0.7796, -0.2184], dtype=torch.float64), tensor([-0.7715,  0.9238,  0.0902, -0.7796, -0.2184], dtype=torch.float64)]\n",
      "1 [tensor([-0.3387, -0.9038,  0.3186, -0.3948,  0.4629], dtype=torch.float64), tensor([-0.3387, -0.9038,  0.3186, -0.3948,  0.4629], dtype=torch.float64)]\n",
      "2 [tensor([ 0.9760,  0.7435,  0.7234, -0.8437, -0.6433], dtype=torch.float64), tensor([ 0.9760,  0.7435,  0.7234, -0.8437, -0.6433], dtype=torch.float64)]\n",
      "3 [tensor([ 0.5752,  0.6393, -0.2064, -0.6994,  0.0621], dtype=torch.float64), tensor([ 0.5752,  0.6393, -0.2064, -0.6994,  0.0621], dtype=torch.float64)]\n",
      "4 [tensor([-0.0461,  0.1824, -0.9198, -0.0902,  0.5792], dtype=torch.float64), tensor([-0.0461,  0.1824, -0.9198, -0.0902,  0.5792], dtype=torch.float64)]\n",
      "5 [tensor([ 0.7074,  0.5551, -0.1944, -0.5551,  0.2705], dtype=torch.float64), tensor([ 0.7074,  0.5551, -0.1944, -0.5551,  0.2705], dtype=torch.float64)]\n",
      "6 [tensor([ 0.7635, -0.7074,  0.8838, -0.6353,  0.9078], dtype=torch.float64), tensor([ 0.7635, -0.7074,  0.8838, -0.6353,  0.9078], dtype=torch.float64)]\n",
      "7 [tensor([-0.1062, -0.5070,  0.4469, -0.1263, -0.4509], dtype=torch.float64), tensor([-0.1062, -0.5070,  0.4469, -0.1263, -0.4509], dtype=torch.float64)]\n",
      "8 [tensor([-0.2705, -0.8357,  0.5952,  0.7675, -0.1102], dtype=torch.float64), tensor([-0.2705, -0.8357,  0.5952,  0.7675, -0.1102], dtype=torch.float64)]\n",
      "9 [tensor([ 0.6834,  0.8918, -0.2786, -0.1864,  0.1743], dtype=torch.float64), tensor([ 0.6834,  0.8918, -0.2786, -0.1864,  0.1743], dtype=torch.float64)]\n",
      "10 [tensor([-0.0341,  0.3627, -0.3547,  0.9319, -0.7114], dtype=torch.float64), tensor([-0.0341,  0.3627, -0.3547,  0.9319, -0.7114], dtype=torch.float64)]\n",
      "11 [tensor([-0.5912, -0.8637, -0.8597, -0.6834,  0.9599], dtype=torch.float64), tensor([-0.5912, -0.8637, -0.8597, -0.6834,  0.9599], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "class NumbersDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.nums = torch.tensor(np.linspace(-1, 1, 500))#torch.rand(-1, 1, 500)\n",
    "        self.samples = []\n",
    "        #self.samples = self.nums.clone()\n",
    "        #self.samples = torch.tensor([self.nums.clone(), self.nums.clone()]).view(2, -1)\n",
    "        for x in self.nums:\n",
    "            self.samples.append((x, x))\n",
    "        #    if num > 0:\n",
    "        #        self.samples.append((num, 1))\n",
    "        #    else:\n",
    "        #        self.samples.append((num, 0))\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #return self.samples[idx]\n",
    "        num, label = self.samples[idx]\n",
    "        return num, label\n",
    "        #$return self.samples[idx]\n",
    "if __name__ == '__main__':\n",
    "    dataset = NumbersDataset()\n",
    "    #dataloader = DataLoader(dataset, batch_size=10, shuffle=True, num_workers=2)\n",
    "    #print(len(dataset))\n",
    "    #print(dataset[99])\n",
    "    #print(dataset[0])\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        print(i, batch)\n",
    "        if i > 10:\n",
    "            break\n",
    "        \n",
    "trainset, testset = random_split(dataset, [400, 100])\n",
    "\n",
    "dataloader = DataLoader(trainset, batch_size=5, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=5, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(output, targets):\n",
    "    \"\"\"Helper function to print the accuracy\"\"\"\n",
    "    predictions = output.argmax(dim=1, keepdim=True).view_as(targets)\n",
    "    return predictions.eq(targets).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.float()\n",
    "def train(verbose=False, num_iter=30):\n",
    "    max_len = len(dataloader)\n",
    "    for iter in range(num_iter):\n",
    "        for batch_idx, (x, y) in enumerate(dataloader):\n",
    "            y = y.view(-1, 1)\n",
    "            y = y.float()\n",
    "            #print(y)\n",
    "            x = x.view(-1, 1)\n",
    "            #print(x)\n",
    "            output = net(x.float())\n",
    "            #print(output)\n",
    "            #output_flat = output.view(-1)\n",
    "            #y_flat = y.view(-1)\n",
    "\n",
    "            accuracy = get_accuracy(output, y)\n",
    "\n",
    "            loss = loss_function(output, y)\n",
    "            loss.backward()\n",
    "            train_optimizer.step()\n",
    "            train_optimizer.zero_grad()\n",
    "\n",
    "            if verbose:\n",
    "                if batch_idx % 10 == 0:\n",
    "                    print(\n",
    "                        \"Iteration {}; {}/{} \\t\".format(iter, batch_idx, max_len) +\n",
    "                        \"Minibatch Loss %.3f  \" % (loss) +\n",
    "                        \"Accuracy %.0f\" % (accuracy * 100) + \"%\"\n",
    "                    )\n",
    "\n",
    "    #print(\"saving model at: {}\".format(MNIST_PATH))\n",
    "    #torch.save(mnist_model.state_dict(), MNIST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 0; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 0; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 0; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 0; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 0; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 0; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 0; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 1; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 1; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 1; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 1; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 1; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 1; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 1; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 1; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 2; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 2; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 2; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 2; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 2; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 2; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 2; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 2; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 3; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 3; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 3; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 3; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 3; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 3; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 3; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 3; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 4; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 4; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 4; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 4; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 4; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 4; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 4; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 4; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 5; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 5; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 5; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 5; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 5; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 5; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 5; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 5; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 6; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 6; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 6; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 6; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 6; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 6; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 6; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 6; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 7; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 7; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 7; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 7; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 7; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 7; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 7; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 7; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 8; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 8; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 8; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 8; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 8; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 8; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 8; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 8; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 9; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 9; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 9; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 9; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 9; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 9; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 9; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 9; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 10; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 10; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 10; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 10; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 10; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 10; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 10; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 10; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 11; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 11; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 11; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 11; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 11; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 11; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 11; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 11; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 12; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 12; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 12; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 12; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 12; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 12; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 12; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 12; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 13; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 13; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 13; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 13; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 13; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 13; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 13; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 13; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 14; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 14; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 14; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 14; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 14; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 14; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 14; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 14; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 15; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 15; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 15; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 15; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 15; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 15; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 15; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 15; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 16; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 16; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 16; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 16; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 16; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 16; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 16; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 16; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 17; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 17; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 17; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 17; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 17; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 17; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 17; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 17; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 18; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 18; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 18; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 18; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 18; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 18; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 18; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 18; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 19; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 19; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 19; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 19; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 19; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 19; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 19; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 19; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 20; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 20; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 20; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 20; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 20; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 20; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 20; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 20; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 21; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 21; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 21; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 21; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 21; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 21; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 21; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 21; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 22; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 22; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 22; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 22; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 22; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 22; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 22; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 22; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 23; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 23; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 23; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 23; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 23; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 23; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 23; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 23; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 24; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 24; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 24; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 24; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 24; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 24; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 24; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 24; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 25; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 25; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 25; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 25; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 25; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 25; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 25; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 25; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 26; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 26; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 26; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 26; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 26; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 26; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 26; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 26; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 27; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 27; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 27; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 27; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 27; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 27; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 27; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 27; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 28; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 28; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 28; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 28; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 28; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 28; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 28; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 28; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 29; 0/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 29; 10/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 29; 20/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 29; 30/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 29; 40/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 29; 50/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 29; 60/80 \tMinibatch Loss 0.000  Accuracy 0%\n",
      "Iteration 29; 70/80 \tMinibatch Loss 0.000  Accuracy 0%\n"
     ]
    }
   ],
   "source": [
    "train(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "tensor([[-0.1182],\n",
      "        [-0.7830],\n",
      "        [-0.0861],\n",
      "        [-0.6989],\n",
      "        [-0.9312]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1182],\n",
      "        [-0.7836],\n",
      "        [-0.0862],\n",
      "        [-0.6994],\n",
      "        [-0.9319]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[ 0.9472],\n",
      "        [-0.7670],\n",
      "        [-0.1742],\n",
      "        [-0.3745],\n",
      "        [ 0.9352]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9479],\n",
      "        [-0.7675],\n",
      "        [-0.1743],\n",
      "        [-0.3747],\n",
      "        [ 0.9359]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[ 0.7830],\n",
      "        [ 0.6388],\n",
      "        [-0.5547],\n",
      "        [-0.5467],\n",
      "        [-0.1983]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7836],\n",
      "        [ 0.6393],\n",
      "        [-0.5551],\n",
      "        [-0.5471],\n",
      "        [-0.1984]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[ 0.6788],\n",
      "        [-0.9632],\n",
      "        [-0.5347],\n",
      "        [-0.2263],\n",
      "        [ 0.3544]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6794],\n",
      "        [-0.9639],\n",
      "        [-0.5351],\n",
      "        [-0.2265],\n",
      "        [ 0.3547]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[ 0.4586],\n",
      "        [-0.7990],\n",
      "        [-0.4586],\n",
      "        [-0.3264],\n",
      "        [-0.3144]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4589],\n",
      "        [-0.7996],\n",
      "        [-0.4589],\n",
      "        [-0.3267],\n",
      "        [-0.3146]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[ 0.6668],\n",
      "        [ 0.8350],\n",
      "        [ 0.0300],\n",
      "        [-0.4386],\n",
      "        [ 0.9592]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6673],\n",
      "        [ 0.8357],\n",
      "        [ 0.0301],\n",
      "        [-0.4389],\n",
      "        [ 0.9599]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[ 0.7189],\n",
      "        [-0.2223],\n",
      "        [ 0.2944],\n",
      "        [ 0.7630],\n",
      "        [ 0.7269]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7194],\n",
      "        [-0.2224],\n",
      "        [ 0.2946],\n",
      "        [ 0.7635],\n",
      "        [ 0.7275]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[ 0.0420],\n",
      "        [ 0.0100],\n",
      "        [-0.5627],\n",
      "        [-0.7470],\n",
      "        [ 0.6949]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.0421],\n",
      "        [ 0.0100],\n",
      "        [-0.5631],\n",
      "        [-0.7475],\n",
      "        [ 0.6954]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[-0.0701],\n",
      "        [ 0.2823],\n",
      "        [-0.4265],\n",
      "        [ 0.8711],\n",
      "        [ 0.7389]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0701],\n",
      "        [ 0.2826],\n",
      "        [-0.4269],\n",
      "        [ 0.8717],\n",
      "        [ 0.7395]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[ 0.4626],\n",
      "        [-0.6709],\n",
      "        [ 0.9672],\n",
      "        [ 0.0260],\n",
      "        [-0.2503]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4629],\n",
      "        [-0.6713],\n",
      "        [ 0.9679],\n",
      "        [ 0.0261],\n",
      "        [-0.2505]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[-0.9712],\n",
      "        [-0.7790],\n",
      "        [-0.1502],\n",
      "        [ 0.6829],\n",
      "        [ 0.3584]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.9719],\n",
      "        [-0.7796],\n",
      "        [-0.1503],\n",
      "        [ 0.6834],\n",
      "        [ 0.3587]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[-0.0941],\n",
      "        [ 0.1582],\n",
      "        [ 0.5707],\n",
      "        [ 0.5987],\n",
      "        [-0.3905]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0942],\n",
      "        [ 0.1583],\n",
      "        [ 0.5711],\n",
      "        [ 0.5992],\n",
      "        [-0.3908]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[-0.6949],\n",
      "        [-0.5387],\n",
      "        [-0.6628],\n",
      "        [-0.7630],\n",
      "        [ 0.8631]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.6954],\n",
      "        [-0.5391],\n",
      "        [-0.6633],\n",
      "        [-0.7635],\n",
      "        [ 0.8637]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[-0.9873],\n",
      "        [ 0.4666],\n",
      "        [-0.3985],\n",
      "        [ 0.2623],\n",
      "        [ 0.3985]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.9880],\n",
      "        [ 0.4669],\n",
      "        [-0.3988],\n",
      "        [ 0.2625],\n",
      "        [ 0.3988]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[ 0.2383],\n",
      "        [-0.4946],\n",
      "        [-0.7429],\n",
      "        [ 0.5507],\n",
      "        [-0.4065]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2385],\n",
      "        [-0.4950],\n",
      "        [-0.7435],\n",
      "        [ 0.5511],\n",
      "        [-0.4068]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[ 0.9512],\n",
      "        [-0.8391],\n",
      "        [-0.6548],\n",
      "        [ 0.9392],\n",
      "        [-0.6468]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9519],\n",
      "        [-0.8397],\n",
      "        [-0.6553],\n",
      "        [ 0.9399],\n",
      "        [-0.6473]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[0.9071],\n",
      "        [0.7469],\n",
      "        [0.6228],\n",
      "        [0.0060],\n",
      "        [0.1422]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.9078],\n",
      "        [0.7475],\n",
      "        [0.6232],\n",
      "        [0.0060],\n",
      "        [0.1423]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[ 0.2904],\n",
      "        [-0.5988],\n",
      "        [-0.2383],\n",
      "        [ 0.9912],\n",
      "        [-0.5187]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2906],\n",
      "        [-0.5992],\n",
      "        [-0.2385],\n",
      "        [ 0.9920],\n",
      "        [-0.5190]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[-0.3585],\n",
      "        [-0.4746],\n",
      "        [-0.3344],\n",
      "        [ 0.1181],\n",
      "        [ 0.2663]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.3587],\n",
      "        [-0.4749],\n",
      "        [-0.3347],\n",
      "        [ 0.1182],\n",
      "        [ 0.2665]], dtype=torch.float64)\n",
      "0.0\n",
      "tensor([[0.5026],\n",
      "        [0.3144],\n",
      "        [0.3785],\n",
      "        [0.0461],\n",
      "        [0.7069]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5030],\n",
      "        [0.3146],\n",
      "        [0.3788],\n",
      "        [0.0461],\n",
      "        [0.7074]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for (x, y) in testloader:\n",
    "            y = y.view(-1, 1)\n",
    "            y = y.float()\n",
    "            #print(y)\n",
    "            x = x.view(-1, 1)\n",
    "            #print(x)\n",
    "            output = net(x.float())\n",
    "            #print(output)\n",
    "            #output_flat = output.view(-1)\n",
    "            #y_flat = y.view(-1)\n",
    "\n",
    "            accuracy = get_accuracy(output, y)\n",
    "            print(accuracy)\n",
    "            print(output)\n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[0.9993]])), ('0.bias', tensor([-8.1095e-06]))])\n"
     ]
    }
   ],
   "source": [
    "state = net.state_dict()\n",
    "print(state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all relevant packages\n",
    "import torch, torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from backpack import backpack, extend\n",
    "from backpack.extensions import DiagHessian, KFAC\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.autograd import Variable\n",
    "from scipy.stats import pearsonr\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "import mpl_toolkits as mpl\n",
    "from scipy.stats import chi2, norm\n",
    "import random\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams[\"mpl_toolkits.legacy_colorbar\"] = False\n",
    "\n",
    "s=2\n",
    "np.random.seed(s)\n",
    "torch.manual_seed(s)\n",
    "torch.cuda.manual_seed(s)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "#plt stuff\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN():\n",
    "    \n",
    "    features = torch.nn.Sequential(\n",
    "        torch.nn.Linear(1, 1)\n",
    "        #torch.nn.Linear(1, 1)\n",
    "    )\n",
    "    return(features)\n",
    "\n",
    "net = NN()\n",
    "#loss_function = torch.nn.MSELoss()\n",
    "\n",
    "#train_optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(out, label):\n",
    "    return (label - out)**2\n",
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 3), (2, 6), (3, 9), (4, 12), (5, 15), (6, 18), (7, 21), (8, 24), (9, 27), (10, 30)]\n"
     ]
    }
   ],
   "source": [
    "#___Create Dataset____\n",
    "#Network (Ax + b) should learn A=A_size, b=0 \n",
    "A_size = 3\n",
    "data = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    data.append((i, i*A_size))\n",
    "print(data)# = [(1,3), (2,6), (3,9), (4,12), (5,15), (6,18)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainloop():\n",
    "    for epoch in range(100):\n",
    "        for i, data2 in enumerate(data):\n",
    "            X, Y = iter(data2)\n",
    "            X, Y = Variable(torch.FloatTensor([X]), requires_grad=True), Variable(torch.FloatTensor([Y]), requires_grad=False)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(X)\n",
    "            loss = criterion(outputs, Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i % 10 == 0):\n",
    "                print(\"Epoch {} - loss: {}\".format(epoch, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - loss: 11.498779296875\n",
      "Epoch 1 - loss: 0.47282543778419495\n",
      "Epoch 2 - loss: 0.16993378102779388\n",
      "Epoch 3 - loss: 0.174896240234375\n",
      "Epoch 4 - loss: 0.15049239993095398\n",
      "Epoch 5 - loss: 0.13298319280147552\n",
      "Epoch 6 - loss: 0.11703185737133026\n",
      "Epoch 7 - loss: 0.103058822453022\n",
      "Epoch 8 - loss: 0.09074508398771286\n",
      "Epoch 9 - loss: 0.07990328222513199\n",
      "Epoch 10 - loss: 0.0703572928905487\n",
      "Epoch 11 - loss: 0.0619516521692276\n",
      "Epoch 12 - loss: 0.05454998090863228\n",
      "Epoch 13 - loss: 0.04803291708230972\n",
      "Epoch 14 - loss: 0.0422942154109478\n",
      "Epoch 15 - loss: 0.03724120929837227\n",
      "Epoch 16 - loss: 0.03279190510511398\n",
      "Epoch 17 - loss: 0.02887425385415554\n",
      "Epoch 18 - loss: 0.025424623861908913\n",
      "Epoch 19 - loss: 0.02238694578409195\n",
      "Epoch 20 - loss: 0.019712409004569054\n",
      "Epoch 21 - loss: 0.017357399687170982\n",
      "Epoch 22 - loss: 0.015283740125596523\n",
      "Epoch 23 - loss: 0.013457589782774448\n",
      "Epoch 24 - loss: 0.01185003574937582\n",
      "Epoch 25 - loss: 0.01043412834405899\n",
      "Epoch 26 - loss: 0.009187495335936546\n",
      "Epoch 27 - loss: 0.008089817129075527\n",
      "Epoch 28 - loss: 0.007123349700123072\n",
      "Epoch 29 - loss: 0.006272304803133011\n",
      "Epoch 30 - loss: 0.005523013416677713\n",
      "Epoch 31 - loss: 0.004863143432885408\n",
      "Epoch 32 - loss: 0.004282073583453894\n",
      "Epoch 33 - loss: 0.0037705085705965757\n",
      "Epoch 34 - loss: 0.00332006998360157\n",
      "Epoch 35 - loss: 0.0029234355315566063\n",
      "Epoch 36 - loss: 0.0025741367135196924\n",
      "Epoch 37 - loss: 0.002266602823510766\n",
      "Epoch 38 - loss: 0.0019957590848207474\n",
      "Epoch 39 - loss: 0.0017573419027030468\n",
      "Epoch 40 - loss: 0.0015473932726308703\n",
      "Epoch 41 - loss: 0.001362528302706778\n",
      "Epoch 42 - loss: 0.0011997364927083254\n",
      "Epoch 43 - loss: 0.0010563913965597749\n",
      "Epoch 44 - loss: 0.0009301878744736314\n",
      "Epoch 45 - loss: 0.0008190773660317063\n",
      "Epoch 46 - loss: 0.0007212033960968256\n",
      "Epoch 47 - loss: 0.0006350585026666522\n",
      "Epoch 48 - loss: 0.0005591839435510337\n",
      "Epoch 49 - loss: 0.000492379127535969\n",
      "Epoch 50 - loss: 0.00043355769594199955\n",
      "Epoch 51 - loss: 0.00038173055509105325\n",
      "Epoch 52 - loss: 0.00033614106359891593\n",
      "Epoch 53 - loss: 0.000295970996376127\n",
      "Epoch 54 - loss: 0.00026062995311804116\n",
      "Epoch 55 - loss: 0.00022948128753341734\n",
      "Epoch 56 - loss: 0.00020206601766403764\n",
      "Epoch 57 - loss: 0.0001779364247340709\n",
      "Epoch 58 - loss: 0.00015666869876440614\n",
      "Epoch 59 - loss: 0.00013795006088912487\n",
      "Epoch 60 - loss: 0.00012147072266088799\n",
      "Epoch 61 - loss: 0.0001069594727596268\n",
      "Epoch 62 - loss: 9.417906403541565e-05\n",
      "Epoch 63 - loss: 8.293081918964162e-05\n",
      "Epoch 64 - loss: 7.301161531358957e-05\n",
      "Epoch 65 - loss: 6.429624045267701e-05\n",
      "Epoch 66 - loss: 5.6614368077134714e-05\n",
      "Epoch 67 - loss: 4.984768747817725e-05\n",
      "Epoch 68 - loss: 4.389294917928055e-05\n",
      "Epoch 69 - loss: 3.865112375933677e-05\n",
      "Epoch 70 - loss: 3.402840957278386e-05\n",
      "Epoch 71 - loss: 2.996827788592782e-05\n",
      "Epoch 72 - loss: 2.6388426704215817e-05\n",
      "Epoch 73 - loss: 2.3226550183608197e-05\n",
      "Epoch 74 - loss: 2.045356814051047e-05\n",
      "Epoch 75 - loss: 1.800824611564167e-05\n",
      "Epoch 76 - loss: 1.5860656276345253e-05\n",
      "Epoch 77 - loss: 1.3966748156235553e-05\n",
      "Epoch 78 - loss: 1.2296667591726873e-05\n",
      "Epoch 79 - loss: 1.0828398444573395e-05\n",
      "Epoch 80 - loss: 9.534255696053151e-06\n",
      "Epoch 81 - loss: 8.394130418309942e-06\n",
      "Epoch 82 - loss: 7.393852229142794e-06\n",
      "Epoch 83 - loss: 6.50800302537391e-06\n",
      "Epoch 84 - loss: 5.732190402341075e-06\n",
      "Epoch 85 - loss: 5.049436367698945e-06\n",
      "Epoch 86 - loss: 4.442063072929159e-06\n",
      "Epoch 87 - loss: 3.914055923814885e-06\n",
      "Epoch 88 - loss: 3.4468353078409564e-06\n",
      "Epoch 89 - loss: 3.034167320947745e-06\n",
      "Epoch 90 - loss: 2.672689333849121e-06\n",
      "Epoch 91 - loss: 2.3516477085649967e-06\n",
      "Epoch 92 - loss: 2.070993105007801e-06\n",
      "Epoch 93 - loss: 1.8229438865091652e-06\n",
      "Epoch 94 - loss: 1.6069911907834467e-06\n",
      "Epoch 95 - loss: 1.4159741112962365e-06\n",
      "Epoch 96 - loss: 1.2450072972569615e-06\n",
      "Epoch 97 - loss: 1.0964904504362494e-06\n",
      "Epoch 98 - loss: 9.648829291108996e-07\n",
      "Epoch 99 - loss: 8.500188073412573e-07\n"
     ]
    }
   ],
   "source": [
    "trainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[2.9999]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0010], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3.0028]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(net(Variable(torch.Tensor([[[1]]]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Hessian_NN(model, train_loader, prec0, device='cpu', verbose=True):\n",
    "    lossfunc = criterion()\n",
    "\n",
    "    extend(lossfunc, debug=False)\n",
    "    extend(model, debug=False)\n",
    "\n",
    "    Cov_diag = []\n",
    "    for param in model.parameters():\n",
    "        ps = param.size()\n",
    "        print(\"parameter size: \", ps)\n",
    "        Cov_diag.append(torch.zeros(ps, device=device))\n",
    "        #print(param.numel())\n",
    "\n",
    "    #var0 = 1/prec0\n",
    "    max_len = len(train_loader)\n",
    "\n",
    "    with backpack(DiagHessian()):\n",
    "\n",
    "        for batch_idx, (x, y) in enumerate(train_loader):\n",
    "\n",
    "            if device == 'cuda':\n",
    "                x, y = x.float().cuda(), y.long().cuda()\n",
    "            \n",
    "            #y = y.view(-1, 1)\n",
    "            #y = y.float()\n",
    "            #print(y)\n",
    "            #x = x.view(-1, 1)\n",
    "\n",
    "            model.zero_grad()\n",
    "            lossfunc(model(x), y).backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Hessian of weight\n",
    "                for idx, param in enumerate(model.parameters()):\n",
    "\n",
    "                    H_ = param.diag_h\n",
    "                    #add prior here\n",
    "                    H_ += prec0 * torch.ones(H_.size())\n",
    "                    H_inv = torch.sqrt(1/H_) #<-- standard deviation\n",
    "                    #H_inv = 1/H_              #<-- variance \n",
    "\n",
    "                    rho = 1-1/(batch_idx+1)\n",
    "\n",
    "                    Cov_diag[idx] = rho*Cov_diag[idx] + (1-rho)* H_inv\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Batch: {}/{}\".format(batch_idx, max_len))\n",
    "    \n",
    "    return(Cov_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "criterion() missing 2 required positional arguments: 'out' and 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-250-37f606b0f841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperceptronDiagH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_Hessian_NN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperceptronDiagH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-249-d90b23f3da06>\u001b[0m in \u001b[0;36mget_Hessian_NN\u001b[0;34m(model, train_loader, prec0, device, verbose)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_Hessian_NN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlossfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlossfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: criterion() missing 2 required positional arguments: 'out' and 'label'"
     ]
    }
   ],
   "source": [
    "perceptronDiagH = get_Hessian_NN(net, train_loader=data, prec0=0.0001)\n",
    "print(perceptronDiagH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([-0.9078,  0.7275,  0.0220,  0.1062, -0.6072,  0.8116,  0.7194, -0.2064,\n",
      "        -0.2425,  0.3387], dtype=torch.float64), tensor([-0.9078,  0.7275,  0.0220,  0.1062, -0.6072,  0.8116,  0.7194, -0.2064,\n",
      "        -0.2425,  0.3387], dtype=torch.float64)]\n",
      "1 [tensor([ 0.3908, -0.7114,  0.1222,  0.1303,  0.0902, -0.6353, -0.4389, -0.7916,\n",
      "        -0.7395, -0.5030], dtype=torch.float64), tensor([ 0.3908, -0.7114,  0.1222,  0.1303,  0.0902, -0.6353, -0.4389, -0.7916,\n",
      "        -0.7395, -0.5030], dtype=torch.float64)]\n",
      "2 [tensor([ 0.6393, -0.5992,  0.7074,  0.0982, -0.3828, -0.0341, -0.4269, -0.6313,\n",
      "         0.2786, -0.5150], dtype=torch.float64), tensor([ 0.6393, -0.5992,  0.7074,  0.0982, -0.3828, -0.0341, -0.4269, -0.6313,\n",
      "         0.2786, -0.5150], dtype=torch.float64)]\n",
      "3 [tensor([-0.7756,  0.7355,  0.4870,  0.6232,  0.0461,  0.1743, -0.5190, -0.7635,\n",
      "         0.6834,  0.9639], dtype=torch.float64), tensor([-0.7756,  0.7355,  0.4870,  0.6232,  0.0461,  0.1743, -0.5190, -0.7635,\n",
      "         0.6834,  0.9639], dtype=torch.float64)]\n",
      "4 [tensor([ 0.7154,  0.0741,  1.0000,  0.0581,  0.5992, -0.6112,  0.0701, -0.5912,\n",
      "         0.8357, -0.7234], dtype=torch.float64), tensor([ 0.7154,  0.0741,  1.0000,  0.0581,  0.5992, -0.6112,  0.0701, -0.5912,\n",
      "         0.8357, -0.7234], dtype=torch.float64)]\n",
      "5 [tensor([ 0.8717,  0.1703,  0.0541, -0.0701,  0.1383,  0.8878,  0.9158,  0.8758,\n",
      "        -0.1824,  0.3707], dtype=torch.float64), tensor([ 0.8717,  0.1703,  0.0541, -0.0701,  0.1383,  0.8878,  0.9158,  0.8758,\n",
      "        -0.1824,  0.3707], dtype=torch.float64)]\n",
      "6 [tensor([ 0.0261, -0.8317, -0.9158, -0.4950, -0.8557,  0.9439,  0.8317, -0.6794,\n",
      "        -0.1062, -0.0982], dtype=torch.float64), tensor([ 0.0261, -0.8317, -0.9158, -0.4950, -0.8557,  0.9439,  0.8317, -0.6794,\n",
      "        -0.1062, -0.0982], dtype=torch.float64)]\n",
      "7 [tensor([ 0.9118, -0.6152,  0.8637, -0.0942,  0.3226, -0.0822, -0.3507, -0.8277,\n",
      "         0.3948,  0.3307], dtype=torch.float64), tensor([ 0.9118, -0.6152,  0.8637, -0.0942,  0.3226, -0.0822, -0.3507, -0.8277,\n",
      "         0.3948,  0.3307], dtype=torch.float64)]\n",
      "8 [tensor([ 0.4469,  0.5351,  0.2024, -0.9599, -0.1222,  0.3587,  0.2224,  0.2625,\n",
      "         0.0421, -0.1303], dtype=torch.float64), tensor([ 0.4469,  0.5351,  0.2024, -0.9599, -0.1222,  0.3587,  0.2224,  0.2625,\n",
      "         0.0421, -0.1303], dtype=torch.float64)]\n",
      "9 [tensor([ 0.2425, -0.0501, -0.8236,  0.0140,  0.5150,  0.4669, -0.9719, -0.9479,\n",
      "        -0.2144,  0.4269], dtype=torch.float64), tensor([ 0.2425, -0.0501, -0.8236,  0.0140,  0.5150,  0.4669, -0.9719, -0.9479,\n",
      "        -0.2144,  0.4269], dtype=torch.float64)]\n",
      "10 [tensor([-0.4148,  0.8998, -0.7675, -0.0782,  0.5190, -0.0661,  0.4910,  0.9880,\n",
      "         0.4549, -0.1263], dtype=torch.float64), tensor([-0.4148,  0.8998, -0.7675, -0.0782,  0.5190, -0.0661,  0.4910,  0.9880,\n",
      "         0.4549, -0.1263], dtype=torch.float64)]\n",
      "11 [tensor([-0.5271,  0.6713,  0.5832, -0.9559,  0.7114,  0.5030,  0.3868, -0.8838,\n",
      "         0.6633, -0.7034], dtype=torch.float64), tensor([-0.5271,  0.6713,  0.5832, -0.9559,  0.7114,  0.5030,  0.3868, -0.8838,\n",
      "         0.6633, -0.7034], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "class NumbersDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.nums = torch.tensor(np.linspace(-1, 1, 500))#torch.rand(-1, 1, 500)\n",
    "        self.samples = []\n",
    "        #self.samples = self.nums.clone()\n",
    "        #self.samples = torch.tensor([self.nums.clone(), self.nums.clone()]).view(2, -1)\n",
    "        self.w = 1\n",
    "        self.b = 1.3\n",
    "        for x in self.nums:\n",
    "            self.samples.append((x, x))# self.w * x + self.b))\n",
    "            #if x > 0:\n",
    "            #    self.samples.append((x, 1))\n",
    "            #else:\n",
    "            #    self.samples.append((x, 0))\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #return self.samples[idx]\n",
    "        num, label = self.samples[idx]\n",
    "        return num, label\n",
    "        #$return self.samples[idx]\n",
    "if __name__ == '__main__':\n",
    "    dataset = NumbersDataset()\n",
    "    trainset, testset = random_split(dataset, [400, 100])\n",
    "    dataloader = DataLoader(trainset, batch_size=10, shuffle=True, num_workers=2)\n",
    "    testloader = DataLoader(testset, batch_size=5, shuffle=False, num_workers=2)\n",
    "    #print(len(dataset))\n",
    "    #print(dataset[99])\n",
    "    #print(dataset[0])\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        print(i, batch)\n",
    "        if i > 10:\n",
    "            break\n",
    "        \n",
    "#trainset, testset = random_split(dataset, [400, 100])\n",
    "\n",
    "#dataloader = DataLoader(trainset, batch_size=5, shuffle=True, num_workers=2)\n",
    "#testloader = DataLoader(testset, batch_size=5, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(output, targets):\n",
    "    \"\"\"Helper function to print the accuracy\"\"\"\n",
    "    predictions = output.argmax(dim=1, keepdim=True).view_as(targets)\n",
    "    return predictions.eq(targets).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.float()\n",
    "def train(verbose=False, num_iter=30):\n",
    "    max_len = len(dataloader)\n",
    "    for iter in range(num_iter):\n",
    "        for batch_idx, (x, y) in enumerate(dataloader):\n",
    "            y = y.view(-1, 1)\n",
    "            y = y.float()\n",
    "            #print(y)\n",
    "            x = x.view(-1, 1)\n",
    "            #print(x)\n",
    "            output = net(x.float())\n",
    "            #print(output)\n",
    "            #output_flat = output.view(-1)\n",
    "            #y_flat = y.view(-1)\n",
    "\n",
    "            accuracy = get_accuracy(output, y)\n",
    "\n",
    "            loss = loss_function(output, y)\n",
    "            loss.backward()\n",
    "            train_optimizer.step()\n",
    "            train_optimizer.zero_grad()\n",
    "\n",
    "            if verbose:\n",
    "                if batch_idx % 10 == 0:\n",
    "                    print(\n",
    "                        \"Iteration {}; {}/{} \\t\".format(iter, batch_idx, max_len) +\n",
    "                        \"Minibatch Loss %.3f  \" % (loss) +\n",
    "                        \"Accuracy %.0f\" % (accuracy * 100) + \"%\"\n",
    "                    )\n",
    "\n",
    "    #print(\"saving model at: {}\".format(MNIST_PATH))\n",
    "    #torch.save(mnist_model.state_dict(), MNIST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0; 0/40 \tMinibatch Loss 2.050  Accuracy 0%\n",
      "Iteration 0; 10/40 \tMinibatch Loss 1.324  Accuracy 0%\n",
      "Iteration 0; 20/40 \tMinibatch Loss 1.633  Accuracy 0%\n",
      "Iteration 0; 30/40 \tMinibatch Loss 1.168  Accuracy 0%\n",
      "Iteration 1; 0/40 \tMinibatch Loss 1.345  Accuracy 0%\n",
      "Iteration 1; 10/40 \tMinibatch Loss 1.551  Accuracy 0%\n",
      "Iteration 1; 20/40 \tMinibatch Loss 1.061  Accuracy 0%\n",
      "Iteration 1; 30/40 \tMinibatch Loss 1.396  Accuracy 0%\n",
      "Iteration 2; 0/40 \tMinibatch Loss 1.331  Accuracy 0%\n",
      "Iteration 2; 10/40 \tMinibatch Loss 0.995  Accuracy 0%\n",
      "Iteration 2; 20/40 \tMinibatch Loss 1.182  Accuracy 0%\n",
      "Iteration 2; 30/40 \tMinibatch Loss 1.788  Accuracy 0%\n",
      "Iteration 3; 0/40 \tMinibatch Loss 0.974  Accuracy 0%\n",
      "Iteration 3; 10/40 \tMinibatch Loss 0.886  Accuracy 0%\n",
      "Iteration 3; 20/40 \tMinibatch Loss 1.330  Accuracy 0%\n",
      "Iteration 3; 30/40 \tMinibatch Loss 1.411  Accuracy 0%\n",
      "Iteration 4; 0/40 \tMinibatch Loss 0.981  Accuracy 0%\n",
      "Iteration 4; 10/40 \tMinibatch Loss 1.654  Accuracy 0%\n",
      "Iteration 4; 20/40 \tMinibatch Loss 1.002  Accuracy 0%\n",
      "Iteration 4; 30/40 \tMinibatch Loss 0.923  Accuracy 0%\n",
      "Iteration 5; 0/40 \tMinibatch Loss 0.859  Accuracy 0%\n",
      "Iteration 5; 10/40 \tMinibatch Loss 1.542  Accuracy 0%\n",
      "Iteration 5; 20/40 \tMinibatch Loss 1.538  Accuracy 0%\n",
      "Iteration 5; 30/40 \tMinibatch Loss 1.714  Accuracy 0%\n",
      "Iteration 6; 0/40 \tMinibatch Loss 1.555  Accuracy 0%\n",
      "Iteration 6; 10/40 \tMinibatch Loss 0.751  Accuracy 0%\n",
      "Iteration 6; 20/40 \tMinibatch Loss 1.348  Accuracy 0%\n",
      "Iteration 6; 30/40 \tMinibatch Loss 1.463  Accuracy 0%\n",
      "Iteration 7; 0/40 \tMinibatch Loss 1.200  Accuracy 0%\n",
      "Iteration 7; 10/40 \tMinibatch Loss 2.237  Accuracy 0%\n",
      "Iteration 7; 20/40 \tMinibatch Loss 1.639  Accuracy 0%\n",
      "Iteration 7; 30/40 \tMinibatch Loss 1.198  Accuracy 0%\n",
      "Iteration 8; 0/40 \tMinibatch Loss 1.044  Accuracy 0%\n",
      "Iteration 8; 10/40 \tMinibatch Loss 1.967  Accuracy 0%\n",
      "Iteration 8; 20/40 \tMinibatch Loss 1.922  Accuracy 0%\n",
      "Iteration 8; 30/40 \tMinibatch Loss 1.049  Accuracy 0%\n",
      "Iteration 9; 0/40 \tMinibatch Loss 1.294  Accuracy 0%\n",
      "Iteration 9; 10/40 \tMinibatch Loss 1.609  Accuracy 0%\n",
      "Iteration 9; 20/40 \tMinibatch Loss 0.937  Accuracy 0%\n",
      "Iteration 9; 30/40 \tMinibatch Loss 1.391  Accuracy 0%\n",
      "Iteration 10; 0/40 \tMinibatch Loss 1.170  Accuracy 0%\n",
      "Iteration 10; 10/40 \tMinibatch Loss 1.230  Accuracy 0%\n",
      "Iteration 10; 20/40 \tMinibatch Loss 1.437  Accuracy 0%\n",
      "Iteration 10; 30/40 \tMinibatch Loss 1.929  Accuracy 0%\n",
      "Iteration 11; 0/40 \tMinibatch Loss 1.308  Accuracy 0%\n",
      "Iteration 11; 10/40 \tMinibatch Loss 1.558  Accuracy 0%\n",
      "Iteration 11; 20/40 \tMinibatch Loss 1.767  Accuracy 0%\n",
      "Iteration 11; 30/40 \tMinibatch Loss 0.842  Accuracy 0%\n",
      "Iteration 12; 0/40 \tMinibatch Loss 1.516  Accuracy 0%\n",
      "Iteration 12; 10/40 \tMinibatch Loss 1.105  Accuracy 0%\n",
      "Iteration 12; 20/40 \tMinibatch Loss 1.110  Accuracy 0%\n",
      "Iteration 12; 30/40 \tMinibatch Loss 1.829  Accuracy 0%\n",
      "Iteration 13; 0/40 \tMinibatch Loss 1.319  Accuracy 0%\n",
      "Iteration 13; 10/40 \tMinibatch Loss 1.105  Accuracy 0%\n",
      "Iteration 13; 20/40 \tMinibatch Loss 1.323  Accuracy 0%\n",
      "Iteration 13; 30/40 \tMinibatch Loss 1.517  Accuracy 0%\n",
      "Iteration 14; 0/40 \tMinibatch Loss 1.290  Accuracy 0%\n",
      "Iteration 14; 10/40 \tMinibatch Loss 2.190  Accuracy 0%\n",
      "Iteration 14; 20/40 \tMinibatch Loss 1.543  Accuracy 0%\n",
      "Iteration 14; 30/40 \tMinibatch Loss 1.283  Accuracy 0%\n",
      "Iteration 15; 0/40 \tMinibatch Loss 1.202  Accuracy 0%\n",
      "Iteration 15; 10/40 \tMinibatch Loss 1.779  Accuracy 0%\n",
      "Iteration 15; 20/40 \tMinibatch Loss 1.155  Accuracy 0%\n",
      "Iteration 15; 30/40 \tMinibatch Loss 0.747  Accuracy 0%\n",
      "Iteration 16; 0/40 \tMinibatch Loss 1.449  Accuracy 0%\n",
      "Iteration 16; 10/40 \tMinibatch Loss 1.153  Accuracy 0%\n",
      "Iteration 16; 20/40 \tMinibatch Loss 1.390  Accuracy 0%\n",
      "Iteration 16; 30/40 \tMinibatch Loss 1.932  Accuracy 0%\n",
      "Iteration 17; 0/40 \tMinibatch Loss 1.123  Accuracy 0%\n",
      "Iteration 17; 10/40 \tMinibatch Loss 1.485  Accuracy 0%\n",
      "Iteration 17; 20/40 \tMinibatch Loss 1.102  Accuracy 0%\n",
      "Iteration 17; 30/40 \tMinibatch Loss 0.889  Accuracy 0%\n",
      "Iteration 18; 0/40 \tMinibatch Loss 1.427  Accuracy 0%\n",
      "Iteration 18; 10/40 \tMinibatch Loss 1.881  Accuracy 0%\n",
      "Iteration 18; 20/40 \tMinibatch Loss 1.349  Accuracy 0%\n",
      "Iteration 18; 30/40 \tMinibatch Loss 1.626  Accuracy 0%\n",
      "Iteration 19; 0/40 \tMinibatch Loss 1.413  Accuracy 0%\n",
      "Iteration 19; 10/40 \tMinibatch Loss 2.024  Accuracy 0%\n",
      "Iteration 19; 20/40 \tMinibatch Loss 1.028  Accuracy 0%\n",
      "Iteration 19; 30/40 \tMinibatch Loss 1.711  Accuracy 0%\n",
      "Iteration 20; 0/40 \tMinibatch Loss 1.538  Accuracy 0%\n",
      "Iteration 20; 10/40 \tMinibatch Loss 1.746  Accuracy 0%\n",
      "Iteration 20; 20/40 \tMinibatch Loss 0.698  Accuracy 0%\n",
      "Iteration 20; 30/40 \tMinibatch Loss 1.955  Accuracy 0%\n",
      "Iteration 21; 0/40 \tMinibatch Loss 1.177  Accuracy 0%\n",
      "Iteration 21; 10/40 \tMinibatch Loss 1.351  Accuracy 0%\n",
      "Iteration 21; 20/40 \tMinibatch Loss 1.751  Accuracy 0%\n",
      "Iteration 21; 30/40 \tMinibatch Loss 0.856  Accuracy 0%\n",
      "Iteration 22; 0/40 \tMinibatch Loss 1.961  Accuracy 0%\n",
      "Iteration 22; 10/40 \tMinibatch Loss 1.604  Accuracy 0%\n",
      "Iteration 22; 20/40 \tMinibatch Loss 0.994  Accuracy 0%\n",
      "Iteration 22; 30/40 \tMinibatch Loss 1.331  Accuracy 0%\n",
      "Iteration 23; 0/40 \tMinibatch Loss 1.356  Accuracy 0%\n",
      "Iteration 23; 10/40 \tMinibatch Loss 1.403  Accuracy 0%\n",
      "Iteration 23; 20/40 \tMinibatch Loss 1.636  Accuracy 0%\n",
      "Iteration 23; 30/40 \tMinibatch Loss 1.024  Accuracy 0%\n",
      "Iteration 24; 0/40 \tMinibatch Loss 1.023  Accuracy 0%\n",
      "Iteration 24; 10/40 \tMinibatch Loss 0.762  Accuracy 0%\n",
      "Iteration 24; 20/40 \tMinibatch Loss 0.835  Accuracy 0%\n",
      "Iteration 24; 30/40 \tMinibatch Loss 1.671  Accuracy 0%\n",
      "Iteration 25; 0/40 \tMinibatch Loss 1.282  Accuracy 0%\n",
      "Iteration 25; 10/40 \tMinibatch Loss 1.522  Accuracy 0%\n",
      "Iteration 25; 20/40 \tMinibatch Loss 0.702  Accuracy 0%\n",
      "Iteration 25; 30/40 \tMinibatch Loss 1.601  Accuracy 0%\n",
      "Iteration 26; 0/40 \tMinibatch Loss 1.349  Accuracy 0%\n",
      "Iteration 26; 10/40 \tMinibatch Loss 1.061  Accuracy 0%\n",
      "Iteration 26; 20/40 \tMinibatch Loss 1.501  Accuracy 0%\n",
      "Iteration 26; 30/40 \tMinibatch Loss 1.441  Accuracy 0%\n",
      "Iteration 27; 0/40 \tMinibatch Loss 1.203  Accuracy 0%\n",
      "Iteration 27; 10/40 \tMinibatch Loss 1.100  Accuracy 0%\n",
      "Iteration 27; 20/40 \tMinibatch Loss 1.195  Accuracy 0%\n",
      "Iteration 27; 30/40 \tMinibatch Loss 1.847  Accuracy 0%\n",
      "Iteration 28; 0/40 \tMinibatch Loss 1.396  Accuracy 0%\n",
      "Iteration 28; 10/40 \tMinibatch Loss 1.445  Accuracy 0%\n",
      "Iteration 28; 20/40 \tMinibatch Loss 1.302  Accuracy 0%\n",
      "Iteration 28; 30/40 \tMinibatch Loss 1.741  Accuracy 0%\n",
      "Iteration 29; 0/40 \tMinibatch Loss 1.486  Accuracy 0%\n",
      "Iteration 29; 10/40 \tMinibatch Loss 1.473  Accuracy 0%\n",
      "Iteration 29; 20/40 \tMinibatch Loss 1.578  Accuracy 0%\n",
      "Iteration 29; 30/40 \tMinibatch Loss 1.764  Accuracy 0%\n"
     ]
    }
   ],
   "source": [
    "train(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1423],\n",
      "        [-0.3307],\n",
      "        [-0.2545],\n",
      "        [-0.1423],\n",
      "        [ 0.4749]], dtype=torch.float64)\n",
      "tensor([[ 0.4302],\n",
      "        [-0.9884],\n",
      "        [-0.7599],\n",
      "        [-0.4233],\n",
      "        [ 1.4280]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[ 0.6353],\n",
      "        [-0.2745],\n",
      "        [-0.6232],\n",
      "        [ 0.2064],\n",
      "        [ 0.3747]], dtype=torch.float64)\n",
      "tensor([[ 1.9088],\n",
      "        [-0.8201],\n",
      "        [-1.8659],\n",
      "        [ 0.6225],\n",
      "        [ 1.1274]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[-0.1543],\n",
      "        [ 0.5752],\n",
      "        [ 0.1503],\n",
      "        [ 0.1463],\n",
      "        [ 0.6313]], dtype=torch.float64)\n",
      "tensor([[-0.4594],\n",
      "        [ 1.7285],\n",
      "        [ 0.4542],\n",
      "        [ 0.4422],\n",
      "        [ 1.8968]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[-0.7355],\n",
      "        [-0.3186],\n",
      "        [-0.9679],\n",
      "        [ 0.9238],\n",
      "        [ 0.9399]], dtype=torch.float64)\n",
      "tensor([[-2.2025],\n",
      "        [-0.9523],\n",
      "        [-2.8998],\n",
      "        [ 2.7744],\n",
      "        [ 2.8225]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[ 0.2986],\n",
      "        [ 0.5271],\n",
      "        [ 0.4990],\n",
      "        [-0.2024],\n",
      "        [-0.5952]], dtype=torch.float64)\n",
      "tensor([[ 0.8990],\n",
      "        [ 1.5843],\n",
      "        [ 1.5001],\n",
      "        [-0.6037],\n",
      "        [-1.7818]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[ 0.2866],\n",
      "        [-0.6032],\n",
      "        [-0.2184],\n",
      "        [-0.9960],\n",
      "        [-0.7275]], dtype=torch.float64)\n",
      "tensor([[ 0.8630],\n",
      "        [-1.8058],\n",
      "        [-0.6518],\n",
      "        [-2.9839],\n",
      "        [-2.1785]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[-0.9840],\n",
      "        [ 0.9760],\n",
      "        [ 0.4028],\n",
      "        [ 0.7555],\n",
      "        [ 0.5471]], dtype=torch.float64)\n",
      "tensor([[-2.9479],\n",
      "        [ 2.9307],\n",
      "        [ 1.2116],\n",
      "        [ 2.2695],\n",
      "        [ 1.6444]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[ 0.9359],\n",
      "        [-0.1102],\n",
      "        [ 0.6273],\n",
      "        [ 0.7956],\n",
      "        [ 0.4148]], dtype=torch.float64)\n",
      "tensor([[ 2.8105],\n",
      "        [-0.3272],\n",
      "        [ 1.8848],\n",
      "        [ 2.3897],\n",
      "        [ 1.2477]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[ 0.7876],\n",
      "        [-0.0421],\n",
      "        [-0.1142],\n",
      "        [ 0.8196],\n",
      "        [ 0.7756]], dtype=torch.float64)\n",
      "tensor([[ 2.3657],\n",
      "        [-0.1228],\n",
      "        [-0.3392],\n",
      "        [ 2.4618],\n",
      "        [ 2.3296]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[-0.4028],\n",
      "        [-0.4749],\n",
      "        [ 0.5591],\n",
      "        [-0.0140],\n",
      "        [ 0.3788]], dtype=torch.float64)\n",
      "tensor([[-1.2047],\n",
      "        [-1.4211],\n",
      "        [ 1.6804],\n",
      "        [-0.0387],\n",
      "        [ 1.1395]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[ 0.3186],\n",
      "        [-0.2585],\n",
      "        [ 0.5391],\n",
      "        [-0.4068],\n",
      "        [-0.4509]], dtype=torch.float64)\n",
      "tensor([[ 0.9591],\n",
      "        [-0.7720],\n",
      "        [ 1.6203],\n",
      "        [-1.2168],\n",
      "        [-1.3490]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[ 0.7515],\n",
      "        [-0.3226],\n",
      "        [ 0.1944],\n",
      "        [-0.8878],\n",
      "        [-0.9118]], dtype=torch.float64)\n",
      "tensor([[ 2.2575],\n",
      "        [-0.9643],\n",
      "        [ 0.5865],\n",
      "        [-2.6594],\n",
      "        [-2.7315]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[-0.5872],\n",
      "        [ 0.1263],\n",
      "        [-0.8397],\n",
      "        [ 0.4830],\n",
      "        [-0.9519]], dtype=torch.float64)\n",
      "tensor([[-1.7577],\n",
      "        [ 0.3821],\n",
      "        [-2.5151],\n",
      "        [ 1.4520],\n",
      "        [-2.8517]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[ 0.5912],\n",
      "        [-0.5311],\n",
      "        [ 0.9719],\n",
      "        [-0.5351],\n",
      "        [ 0.5952]], dtype=torch.float64)\n",
      "tensor([[ 1.7766],\n",
      "        [-1.5894],\n",
      "        [ 2.9187],\n",
      "        [-1.6015],\n",
      "        [ 1.7886]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[-0.2906],\n",
      "        [-0.7435],\n",
      "        [-0.9038],\n",
      "        [-0.5110],\n",
      "        [ 0.4108]], dtype=torch.float64)\n",
      "tensor([[-0.8681],\n",
      "        [-2.2266],\n",
      "        [-2.7074],\n",
      "        [-1.5293],\n",
      "        [ 1.2356]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[-0.3627],\n",
      "        [ 0.2585],\n",
      "        [ 0.3667],\n",
      "        [-0.6713],\n",
      "        [-0.0621]], dtype=torch.float64)\n",
      "tensor([[-1.0845],\n",
      "        [ 0.7788],\n",
      "        [ 1.1034],\n",
      "        [-2.0102],\n",
      "        [-0.1829]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[-0.5591],\n",
      "        [-0.2265],\n",
      "        [-0.3868],\n",
      "        [ 0.4790],\n",
      "        [-0.6914]], dtype=torch.float64)\n",
      "tensor([[-1.6736],\n",
      "        [-0.6758],\n",
      "        [-1.1567],\n",
      "        [ 1.4400],\n",
      "        [-2.0703]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[-0.0060],\n",
      "        [-0.9439],\n",
      "        [-0.4309],\n",
      "        [-0.2465],\n",
      "        [-0.3547]], dtype=torch.float64)\n",
      "tensor([[-0.0146],\n",
      "        [-2.8277],\n",
      "        [-1.2889],\n",
      "        [-0.7359],\n",
      "        [-1.0605]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[-0.3146],\n",
      "        [ 0.9559],\n",
      "        [ 0.9519],\n",
      "        [-0.1663],\n",
      "        [ 0.8918]], dtype=torch.float64)\n",
      "tensor([[-0.9403],\n",
      "        [ 2.8706],\n",
      "        [ 2.8586],\n",
      "        [-0.4955],\n",
      "        [ 2.6782]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n",
      "tensor([[ 0.2465],\n",
      "        [-0.4108],\n",
      "        [-0.0301],\n",
      "        [-0.0220],\n",
      "        [-0.4228]], dtype=torch.float64)\n",
      "tensor([[ 0.7428],\n",
      "        [-1.2288],\n",
      "        [-0.0867],\n",
      "        [-0.0627],\n",
      "        [-1.2649]], grad_fn=<AddmmBackward>)\n",
      "0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (x, y) in testloader:\n",
    "            y = y.view(-1, 1)\n",
    "            y = y.float()\n",
    "            #print(y)\n",
    "            x = x.view(-1, 1)\n",
    "            #print(x)\n",
    "            output = net(x.float())\n",
    "            #print(output)\n",
    "            #output_flat = output.view(-1)\n",
    "            #y_flat = y.view(-1)\n",
    "\n",
    "            accuracy = get_accuracy(output, y)\n",
    "            print(x)\n",
    "            print(output)\n",
    "            print(accuracy)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[2.9994]])), ('0.bias', tensor([0.0034]))])\n"
     ]
    }
   ],
   "source": [
    "state = net.state_dict()\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight\n",
      "tensor([[1621.3851]])\n",
      "tensor([[0.7700]])\n",
      "tensor([[1.1396]])\n",
      "0.bias\n",
      "tensor([8.2693])\n",
      "tensor([2.])\n",
      "tensor([0.7071])\n"
     ]
    }
   ],
   "source": [
    "for i, (a, b) in enumerate(dataloader):\n",
    "    X = a\n",
    "    y = b\n",
    "    if i > 0:\n",
    "        break\n",
    "        \n",
    "y = y.view(-1, 1)\n",
    "y = y.float()\n",
    "#print(y)\n",
    "X = X.view(-1, 1)\n",
    "#X, y = dataloader\n",
    "model = extend(net)\n",
    "lossfunc = extend(loss_function)\n",
    "loss = lossfunc(model(X.float()), y)\n",
    "\n",
    "with backpack(DiagHessian()):\n",
    "    loss.backward()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "    print(param.grad)\n",
    "    print(param.diag_h)\n",
    "    print(torch.sqrt(1/param.diag_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter size:  torch.Size([1, 1])\n",
      "parameter size:  torch.Size([1])\n",
      "Batch: 0/40\n",
      "Batch: 1/40\n",
      "Batch: 2/40\n",
      "Batch: 3/40\n",
      "Batch: 4/40\n",
      "Batch: 5/40\n",
      "Batch: 6/40\n",
      "Batch: 7/40\n",
      "Batch: 8/40\n",
      "Batch: 9/40\n",
      "Batch: 10/40\n",
      "Batch: 11/40\n",
      "Batch: 12/40\n",
      "Batch: 13/40\n",
      "Batch: 14/40\n",
      "Batch: 15/40\n",
      "Batch: 16/40\n",
      "Batch: 17/40\n",
      "Batch: 18/40\n",
      "Batch: 19/40\n",
      "Batch: 20/40\n",
      "Batch: 21/40\n",
      "Batch: 22/40\n",
      "Batch: 23/40\n",
      "Batch: 24/40\n",
      "Batch: 25/40\n",
      "Batch: 26/40\n",
      "Batch: 27/40\n",
      "Batch: 28/40\n",
      "Batch: 29/40\n",
      "Batch: 30/40\n",
      "Batch: 31/40\n",
      "Batch: 32/40\n",
      "Batch: 33/40\n",
      "Batch: 34/40\n",
      "Batch: 35/40\n",
      "Batch: 36/40\n",
      "Batch: 37/40\n",
      "Batch: 38/40\n",
      "Batch: 39/40\n",
      "[tensor([[1.2560]]), tensor([0.7071])]\n"
     ]
    }
   ],
   "source": [
    "test = get_Hessian_NN(model=net, train_loader=dataloader, prec0=0.0001)\n",
    "print(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all relevant packages\n",
    "import torch, torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from backpack import backpack, extend\n",
    "from backpack.extensions import DiagHessian\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.nn import functional as F\n",
    "\n",
    "s=1107\n",
    "np.random.seed(s)\n",
    "torch.manual_seed(s)\n",
    "torch.cuda.manual_seed(s)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data wrangling: load MNIST\n",
    "MNIST_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "MNIST_train = torchvision.datasets.MNIST(\n",
    "        '~/data/mnist',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=MNIST_transform)\n",
    "\n",
    "\n",
    "MNIST_test = torchvision.datasets.MNIST(\n",
    "        '~/data/mnist',\n",
    "        train=False,\n",
    "        download=False,\n",
    "        transform=MNIST_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# have a look at the data to verify\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    #plt.imshow(npimg)\n",
    "    plt.show()\n",
    "\n",
    "images = MNIST_train.data[:10].view(10, 1, 28, 28)\n",
    "imshow(torchvision.utils.make_grid(images, nrow=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_loader = torch.utils.data.dataloader.DataLoader(\n",
    "    MNIST_train,\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "mnist_test_loader = torch.utils.data.dataloader.DataLoader(\n",
    "    MNIST_test,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the network\n",
    "def NN(num_classes=10):\n",
    "    \n",
    "    features = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(1, 32, 5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(2,2),\n",
    "        torch.nn.Conv2d(32, 32, 5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(2,2),\n",
    "        torch.nn.Flatten(),\n",
    "        torch.nn.Linear(4 * 4 * 32, num_classes)\n",
    "    )\n",
    "    return(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the training routine\n",
    "mnist_model = NN(num_classes=10)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "mnist_train_optimizer = torch.optim.Adam(mnist_model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "#dont use SGD, it is way worse than Adam here\n",
    "MNIST_PATH = \"MNIST_weights.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get accuracy\n",
    "def get_accuracy(output, targets):\n",
    "    \"\"\"Helper function to print the accuracy\"\"\"\n",
    "    predictions = output.argmax(dim=1, keepdim=True).view_as(targets)\n",
    "    return predictions.eq(targets).float().mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the training routine and save the model at FMNIST_PATH\n",
    "\n",
    "def train(verbose=False, num_iter=5):\n",
    "    max_len = len(mnist_train_loader)\n",
    "    for iter in range(num_iter):\n",
    "        for batch_idx, (x, y) in enumerate(mnist_train_loader):\n",
    "            output = mnist_model(x)\n",
    "\n",
    "            accuracy = get_accuracy(output, y)\n",
    "\n",
    "            loss = loss_function(output, y)\n",
    "            loss.backward()\n",
    "            mnist_train_optimizer.step()\n",
    "            mnist_train_optimizer.zero_grad()\n",
    "\n",
    "            if verbose:\n",
    "                if batch_idx % 10 == 0:\n",
    "                    print(\n",
    "                        \"Iteration {}; {}/{} \\t\".format(iter, batch_idx, max_len) +\n",
    "                        \"Minibatch Loss %.3f  \" % (loss) +\n",
    "                        \"Accuracy %.0f\" % (accuracy * 100) + \"%\"\n",
    "                    )\n",
    "\n",
    "    print(\"saving model at: {}\".format(MNIST_PATH))\n",
    "    torch.save(mnist_model.state_dict(), MNIST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0; 0/469 \tMinibatch Loss 2.324  Accuracy 6%\n",
      "Iteration 0; 10/469 \tMinibatch Loss 1.905  Accuracy 70%\n",
      "Iteration 0; 20/469 \tMinibatch Loss 1.137  Accuracy 72%\n",
      "Iteration 0; 30/469 \tMinibatch Loss 0.641  Accuracy 82%\n",
      "Iteration 0; 40/469 \tMinibatch Loss 0.454  Accuracy 88%\n",
      "Iteration 0; 50/469 \tMinibatch Loss 0.307  Accuracy 92%\n",
      "Iteration 0; 60/469 \tMinibatch Loss 0.422  Accuracy 87%\n",
      "Iteration 0; 70/469 \tMinibatch Loss 0.288  Accuracy 93%\n",
      "Iteration 0; 80/469 \tMinibatch Loss 0.219  Accuracy 95%\n",
      "Iteration 0; 90/469 \tMinibatch Loss 0.398  Accuracy 87%\n",
      "Iteration 0; 100/469 \tMinibatch Loss 0.265  Accuracy 91%\n",
      "Iteration 0; 110/469 \tMinibatch Loss 0.242  Accuracy 93%\n",
      "Iteration 0; 120/469 \tMinibatch Loss 0.187  Accuracy 93%\n",
      "Iteration 0; 130/469 \tMinibatch Loss 0.228  Accuracy 95%\n",
      "Iteration 0; 140/469 \tMinibatch Loss 0.153  Accuracy 96%\n",
      "Iteration 0; 150/469 \tMinibatch Loss 0.168  Accuracy 97%\n",
      "Iteration 0; 160/469 \tMinibatch Loss 0.178  Accuracy 95%\n",
      "Iteration 0; 170/469 \tMinibatch Loss 0.159  Accuracy 95%\n",
      "Iteration 0; 180/469 \tMinibatch Loss 0.126  Accuracy 97%\n",
      "Iteration 0; 190/469 \tMinibatch Loss 0.151  Accuracy 96%\n",
      "Iteration 0; 200/469 \tMinibatch Loss 0.140  Accuracy 96%\n",
      "Iteration 0; 210/469 \tMinibatch Loss 0.159  Accuracy 97%\n",
      "Iteration 0; 220/469 \tMinibatch Loss 0.117  Accuracy 97%\n",
      "Iteration 0; 230/469 \tMinibatch Loss 0.111  Accuracy 98%\n",
      "Iteration 0; 240/469 \tMinibatch Loss 0.133  Accuracy 98%\n",
      "Iteration 0; 250/469 \tMinibatch Loss 0.126  Accuracy 95%\n",
      "Iteration 0; 260/469 \tMinibatch Loss 0.104  Accuracy 97%\n",
      "Iteration 0; 270/469 \tMinibatch Loss 0.080  Accuracy 98%\n",
      "Iteration 0; 280/469 \tMinibatch Loss 0.140  Accuracy 95%\n",
      "Iteration 0; 290/469 \tMinibatch Loss 0.130  Accuracy 95%\n",
      "Iteration 0; 300/469 \tMinibatch Loss 0.231  Accuracy 95%\n",
      "Iteration 0; 310/469 \tMinibatch Loss 0.149  Accuracy 95%\n",
      "Iteration 0; 320/469 \tMinibatch Loss 0.142  Accuracy 97%\n",
      "Iteration 0; 330/469 \tMinibatch Loss 0.091  Accuracy 98%\n",
      "Iteration 0; 340/469 \tMinibatch Loss 0.086  Accuracy 98%\n",
      "Iteration 0; 350/469 \tMinibatch Loss 0.038  Accuracy 99%\n",
      "Iteration 0; 360/469 \tMinibatch Loss 0.165  Accuracy 96%\n",
      "Iteration 0; 370/469 \tMinibatch Loss 0.132  Accuracy 96%\n",
      "Iteration 0; 380/469 \tMinibatch Loss 0.220  Accuracy 92%\n",
      "Iteration 0; 390/469 \tMinibatch Loss 0.107  Accuracy 98%\n",
      "Iteration 0; 400/469 \tMinibatch Loss 0.142  Accuracy 96%\n",
      "Iteration 0; 410/469 \tMinibatch Loss 0.104  Accuracy 98%\n",
      "Iteration 0; 420/469 \tMinibatch Loss 0.115  Accuracy 97%\n",
      "Iteration 0; 430/469 \tMinibatch Loss 0.089  Accuracy 97%\n",
      "Iteration 0; 440/469 \tMinibatch Loss 0.086  Accuracy 97%\n",
      "Iteration 0; 450/469 \tMinibatch Loss 0.136  Accuracy 94%\n",
      "Iteration 0; 460/469 \tMinibatch Loss 0.094  Accuracy 98%\n",
      "Iteration 1; 0/469 \tMinibatch Loss 0.059  Accuracy 98%\n",
      "Iteration 1; 10/469 \tMinibatch Loss 0.116  Accuracy 98%\n",
      "Iteration 1; 20/469 \tMinibatch Loss 0.084  Accuracy 97%\n",
      "Iteration 1; 30/469 \tMinibatch Loss 0.072  Accuracy 98%\n",
      "Iteration 1; 40/469 \tMinibatch Loss 0.137  Accuracy 96%\n",
      "Iteration 1; 50/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 1; 60/469 \tMinibatch Loss 0.055  Accuracy 99%\n",
      "Iteration 1; 70/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 1; 80/469 \tMinibatch Loss 0.089  Accuracy 98%\n",
      "Iteration 1; 90/469 \tMinibatch Loss 0.097  Accuracy 98%\n",
      "Iteration 1; 100/469 \tMinibatch Loss 0.071  Accuracy 98%\n",
      "Iteration 1; 110/469 \tMinibatch Loss 0.086  Accuracy 98%\n",
      "Iteration 1; 120/469 \tMinibatch Loss 0.060  Accuracy 98%\n",
      "Iteration 1; 130/469 \tMinibatch Loss 0.079  Accuracy 98%\n",
      "Iteration 1; 140/469 \tMinibatch Loss 0.119  Accuracy 96%\n",
      "Iteration 1; 150/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 1; 160/469 \tMinibatch Loss 0.080  Accuracy 98%\n",
      "Iteration 1; 170/469 \tMinibatch Loss 0.098  Accuracy 97%\n",
      "Iteration 1; 180/469 \tMinibatch Loss 0.147  Accuracy 98%\n",
      "Iteration 1; 190/469 \tMinibatch Loss 0.126  Accuracy 97%\n",
      "Iteration 1; 200/469 \tMinibatch Loss 0.121  Accuracy 97%\n",
      "Iteration 1; 210/469 \tMinibatch Loss 0.071  Accuracy 97%\n",
      "Iteration 1; 220/469 \tMinibatch Loss 0.067  Accuracy 98%\n",
      "Iteration 1; 230/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 1; 240/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 1; 250/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 1; 260/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 1; 270/469 \tMinibatch Loss 0.074  Accuracy 96%\n",
      "Iteration 1; 280/469 \tMinibatch Loss 0.129  Accuracy 95%\n",
      "Iteration 1; 290/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 1; 300/469 \tMinibatch Loss 0.055  Accuracy 97%\n",
      "Iteration 1; 310/469 \tMinibatch Loss 0.048  Accuracy 99%\n",
      "Iteration 1; 320/469 \tMinibatch Loss 0.061  Accuracy 98%\n",
      "Iteration 1; 330/469 \tMinibatch Loss 0.067  Accuracy 96%\n",
      "Iteration 1; 340/469 \tMinibatch Loss 0.135  Accuracy 96%\n",
      "Iteration 1; 350/469 \tMinibatch Loss 0.085  Accuracy 97%\n",
      "Iteration 1; 360/469 \tMinibatch Loss 0.030  Accuracy 99%\n",
      "Iteration 1; 370/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 1; 380/469 \tMinibatch Loss 0.102  Accuracy 98%\n",
      "Iteration 1; 390/469 \tMinibatch Loss 0.085  Accuracy 97%\n",
      "Iteration 1; 400/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 1; 410/469 \tMinibatch Loss 0.093  Accuracy 96%\n",
      "Iteration 1; 420/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 1; 430/469 \tMinibatch Loss 0.056  Accuracy 98%\n",
      "Iteration 1; 440/469 \tMinibatch Loss 0.073  Accuracy 98%\n",
      "Iteration 1; 450/469 \tMinibatch Loss 0.168  Accuracy 95%\n",
      "Iteration 1; 460/469 \tMinibatch Loss 0.158  Accuracy 97%\n",
      "Iteration 2; 0/469 \tMinibatch Loss 0.046  Accuracy 99%\n",
      "Iteration 2; 10/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 2; 20/469 \tMinibatch Loss 0.036  Accuracy 99%\n",
      "Iteration 2; 30/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 2; 40/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 2; 50/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 2; 60/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 2; 70/469 \tMinibatch Loss 0.088  Accuracy 98%\n",
      "Iteration 2; 80/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 2; 90/469 \tMinibatch Loss 0.030  Accuracy 100%\n",
      "Iteration 2; 100/469 \tMinibatch Loss 0.078  Accuracy 98%\n",
      "Iteration 2; 110/469 \tMinibatch Loss 0.104  Accuracy 97%\n",
      "Iteration 2; 120/469 \tMinibatch Loss 0.138  Accuracy 95%\n",
      "Iteration 2; 130/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 2; 140/469 \tMinibatch Loss 0.098  Accuracy 98%\n",
      "Iteration 2; 150/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 2; 160/469 \tMinibatch Loss 0.135  Accuracy 97%\n",
      "Iteration 2; 170/469 \tMinibatch Loss 0.066  Accuracy 98%\n",
      "Iteration 2; 180/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 2; 190/469 \tMinibatch Loss 0.023  Accuracy 100%\n",
      "Iteration 2; 200/469 \tMinibatch Loss 0.025  Accuracy 99%\n",
      "Iteration 2; 210/469 \tMinibatch Loss 0.025  Accuracy 100%\n",
      "Iteration 2; 220/469 \tMinibatch Loss 0.025  Accuracy 100%\n",
      "Iteration 2; 230/469 \tMinibatch Loss 0.053  Accuracy 98%\n",
      "Iteration 2; 240/469 \tMinibatch Loss 0.066  Accuracy 98%\n",
      "Iteration 2; 250/469 \tMinibatch Loss 0.069  Accuracy 98%\n",
      "Iteration 2; 260/469 \tMinibatch Loss 0.099  Accuracy 96%\n",
      "Iteration 2; 270/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 2; 280/469 \tMinibatch Loss 0.042  Accuracy 99%\n",
      "Iteration 2; 290/469 \tMinibatch Loss 0.039  Accuracy 98%\n",
      "Iteration 2; 300/469 \tMinibatch Loss 0.078  Accuracy 98%\n",
      "Iteration 2; 310/469 \tMinibatch Loss 0.019  Accuracy 100%\n",
      "Iteration 2; 320/469 \tMinibatch Loss 0.128  Accuracy 97%\n",
      "Iteration 2; 330/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 2; 340/469 \tMinibatch Loss 0.045  Accuracy 99%\n",
      "Iteration 2; 350/469 \tMinibatch Loss 0.087  Accuracy 98%\n",
      "Iteration 2; 360/469 \tMinibatch Loss 0.072  Accuracy 98%\n",
      "Iteration 2; 370/469 \tMinibatch Loss 0.053  Accuracy 99%\n",
      "Iteration 2; 380/469 \tMinibatch Loss 0.039  Accuracy 99%\n",
      "Iteration 2; 390/469 \tMinibatch Loss 0.065  Accuracy 98%\n",
      "Iteration 2; 400/469 \tMinibatch Loss 0.041  Accuracy 99%\n",
      "Iteration 2; 410/469 \tMinibatch Loss 0.068  Accuracy 98%\n",
      "Iteration 2; 420/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 2; 430/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 2; 440/469 \tMinibatch Loss 0.040  Accuracy 99%\n",
      "Iteration 2; 450/469 \tMinibatch Loss 0.071  Accuracy 98%\n",
      "Iteration 2; 460/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 3; 0/469 \tMinibatch Loss 0.069  Accuracy 97%\n",
      "Iteration 3; 10/469 \tMinibatch Loss 0.173  Accuracy 99%\n",
      "Iteration 3; 20/469 \tMinibatch Loss 0.060  Accuracy 98%\n",
      "Iteration 3; 30/469 \tMinibatch Loss 0.060  Accuracy 99%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3; 40/469 \tMinibatch Loss 0.021  Accuracy 99%\n",
      "Iteration 3; 50/469 \tMinibatch Loss 0.101  Accuracy 95%\n",
      "Iteration 3; 60/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 3; 70/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 3; 80/469 \tMinibatch Loss 0.060  Accuracy 96%\n",
      "Iteration 3; 90/469 \tMinibatch Loss 0.033  Accuracy 98%\n",
      "Iteration 3; 100/469 \tMinibatch Loss 0.041  Accuracy 99%\n",
      "Iteration 3; 110/469 \tMinibatch Loss 0.103  Accuracy 99%\n",
      "Iteration 3; 120/469 \tMinibatch Loss 0.008  Accuracy 100%\n",
      "Iteration 3; 130/469 \tMinibatch Loss 0.066  Accuracy 98%\n",
      "Iteration 3; 140/469 \tMinibatch Loss 0.024  Accuracy 99%\n",
      "Iteration 3; 150/469 \tMinibatch Loss 0.079  Accuracy 98%\n",
      "Iteration 3; 160/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 3; 170/469 \tMinibatch Loss 0.078  Accuracy 99%\n",
      "Iteration 3; 180/469 \tMinibatch Loss 0.060  Accuracy 98%\n",
      "Iteration 3; 190/469 \tMinibatch Loss 0.051  Accuracy 97%\n",
      "Iteration 3; 200/469 \tMinibatch Loss 0.023  Accuracy 99%\n",
      "Iteration 3; 210/469 \tMinibatch Loss 0.097  Accuracy 97%\n",
      "Iteration 3; 220/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 3; 230/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 3; 240/469 \tMinibatch Loss 0.096  Accuracy 98%\n",
      "Iteration 3; 250/469 \tMinibatch Loss 0.098  Accuracy 98%\n",
      "Iteration 3; 260/469 \tMinibatch Loss 0.048  Accuracy 98%\n",
      "Iteration 3; 270/469 \tMinibatch Loss 0.031  Accuracy 99%\n",
      "Iteration 3; 280/469 \tMinibatch Loss 0.009  Accuracy 100%\n",
      "Iteration 3; 290/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 3; 300/469 \tMinibatch Loss 0.040  Accuracy 98%\n",
      "Iteration 3; 310/469 \tMinibatch Loss 0.021  Accuracy 100%\n",
      "Iteration 3; 320/469 \tMinibatch Loss 0.060  Accuracy 98%\n",
      "Iteration 3; 330/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 3; 340/469 \tMinibatch Loss 0.031  Accuracy 98%\n",
      "Iteration 3; 350/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 3; 360/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 3; 370/469 \tMinibatch Loss 0.064  Accuracy 98%\n",
      "Iteration 3; 380/469 \tMinibatch Loss 0.087  Accuracy 98%\n",
      "Iteration 3; 390/469 \tMinibatch Loss 0.174  Accuracy 98%\n",
      "Iteration 3; 400/469 \tMinibatch Loss 0.146  Accuracy 96%\n",
      "Iteration 3; 410/469 \tMinibatch Loss 0.038  Accuracy 98%\n",
      "Iteration 3; 420/469 \tMinibatch Loss 0.015  Accuracy 100%\n",
      "Iteration 3; 430/469 \tMinibatch Loss 0.049  Accuracy 98%\n",
      "Iteration 3; 440/469 \tMinibatch Loss 0.016  Accuracy 100%\n",
      "Iteration 3; 450/469 \tMinibatch Loss 0.018  Accuracy 99%\n",
      "Iteration 3; 460/469 \tMinibatch Loss 0.039  Accuracy 99%\n",
      "Iteration 4; 0/469 \tMinibatch Loss 0.097  Accuracy 98%\n",
      "Iteration 4; 10/469 \tMinibatch Loss 0.013  Accuracy 100%\n",
      "Iteration 4; 20/469 \tMinibatch Loss 0.041  Accuracy 98%\n",
      "Iteration 4; 30/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 4; 40/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 4; 50/469 \tMinibatch Loss 0.049  Accuracy 99%\n",
      "Iteration 4; 60/469 \tMinibatch Loss 0.045  Accuracy 98%\n",
      "Iteration 4; 70/469 \tMinibatch Loss 0.010  Accuracy 100%\n",
      "Iteration 4; 80/469 \tMinibatch Loss 0.042  Accuracy 98%\n",
      "Iteration 4; 90/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 4; 100/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 4; 110/469 \tMinibatch Loss 0.033  Accuracy 99%\n",
      "Iteration 4; 120/469 \tMinibatch Loss 0.074  Accuracy 97%\n",
      "Iteration 4; 130/469 \tMinibatch Loss 0.027  Accuracy 98%\n",
      "Iteration 4; 140/469 \tMinibatch Loss 0.014  Accuracy 100%\n",
      "Iteration 4; 150/469 \tMinibatch Loss 0.081  Accuracy 98%\n",
      "Iteration 4; 160/469 \tMinibatch Loss 0.019  Accuracy 100%\n",
      "Iteration 4; 170/469 \tMinibatch Loss 0.029  Accuracy 98%\n",
      "Iteration 4; 180/469 \tMinibatch Loss 0.027  Accuracy 98%\n",
      "Iteration 4; 190/469 \tMinibatch Loss 0.019  Accuracy 100%\n",
      "Iteration 4; 200/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 4; 210/469 \tMinibatch Loss 0.025  Accuracy 100%\n",
      "Iteration 4; 220/469 \tMinibatch Loss 0.054  Accuracy 98%\n",
      "Iteration 4; 230/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 4; 240/469 \tMinibatch Loss 0.061  Accuracy 98%\n",
      "Iteration 4; 250/469 \tMinibatch Loss 0.020  Accuracy 99%\n",
      "Iteration 4; 260/469 \tMinibatch Loss 0.055  Accuracy 98%\n",
      "Iteration 4; 270/469 \tMinibatch Loss 0.011  Accuracy 100%\n",
      "Iteration 4; 280/469 \tMinibatch Loss 0.062  Accuracy 98%\n",
      "Iteration 4; 290/469 \tMinibatch Loss 0.107  Accuracy 97%\n",
      "Iteration 4; 300/469 \tMinibatch Loss 0.050  Accuracy 98%\n",
      "Iteration 4; 310/469 \tMinibatch Loss 0.037  Accuracy 99%\n",
      "Iteration 4; 320/469 \tMinibatch Loss 0.027  Accuracy 100%\n",
      "Iteration 4; 330/469 \tMinibatch Loss 0.022  Accuracy 99%\n",
      "Iteration 4; 340/469 \tMinibatch Loss 0.013  Accuracy 99%\n",
      "Iteration 4; 350/469 \tMinibatch Loss 0.026  Accuracy 98%\n",
      "Iteration 4; 360/469 \tMinibatch Loss 0.037  Accuracy 98%\n",
      "Iteration 4; 370/469 \tMinibatch Loss 0.053  Accuracy 97%\n",
      "Iteration 4; 380/469 \tMinibatch Loss 0.051  Accuracy 98%\n",
      "Iteration 4; 390/469 \tMinibatch Loss 0.027  Accuracy 99%\n",
      "Iteration 4; 400/469 \tMinibatch Loss 0.034  Accuracy 98%\n",
      "Iteration 4; 410/469 \tMinibatch Loss 0.015  Accuracy 99%\n",
      "Iteration 4; 420/469 \tMinibatch Loss 0.032  Accuracy 99%\n",
      "Iteration 4; 430/469 \tMinibatch Loss 0.006  Accuracy 100%\n",
      "Iteration 4; 440/469 \tMinibatch Loss 0.035  Accuracy 98%\n",
      "Iteration 4; 450/469 \tMinibatch Loss 0.028  Accuracy 99%\n",
      "Iteration 4; 460/469 \tMinibatch Loss 0.050  Accuracy 98%\n",
      "saving model at: MNIST_weights.pth\n"
     ]
    }
   ],
   "source": [
    "#after training it once, comment this out to save time if you rerun the entire script\n",
    "train(verbose=True, num_iter=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from: MNIST_weights.pth\n",
      "Batch 0/79 \tAccuracy 99%\n",
      "Batch 10/79 \tAccuracy 97%\n",
      "Batch 20/79 \tAccuracy 98%\n",
      "Batch 30/79 \tAccuracy 98%\n",
      "Batch 40/79 \tAccuracy 100%\n",
      "Batch 50/79 \tAccuracy 99%\n",
      "Batch 60/79 \tAccuracy 100%\n",
      "Batch 70/79 \tAccuracy 99%\n",
      "overall test accuracy on MNIST: 98.75 %\n"
     ]
    }
   ],
   "source": [
    "#predict in distribution\n",
    "MNIST_PATH = \"MNIST_weights.pth\"\n",
    "\n",
    "mnist_model = NN(num_classes=10)\n",
    "print(\"loading model from: {}\".format(MNIST_PATH))\n",
    "mnist_model.load_state_dict(torch.load(MNIST_PATH))\n",
    "mnist_model.eval()\n",
    "\n",
    "acc = []\n",
    "\n",
    "max_len = len(mnist_test_loader)\n",
    "for batch_idx, (x, y) in enumerate(mnist_test_loader):\n",
    "        output = mnist_model(x)\n",
    "        accuracy = get_accuracy(output, y)\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(\n",
    "                \"Batch {}/{} \\t\".format(batch_idx, max_len) + \n",
    "                \"Accuracy %.0f\" % (accuracy * 100) + \"%\"\n",
    "            )\n",
    "        acc.append(accuracy)\n",
    "    \n",
    "avg_acc = np.mean(acc)\n",
    "print('overall test accuracy on MNIST: {:.02f} %'.format(avg_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laplace approximation of the weights\n",
    "* we use the BackPACK package to approximate the Hessian of the parameters. Especially look at the DiagHessian() method.\n",
    "* we do one iteration over the entire training set and use the mean of the Hessian of the mini-batches as the best approximation of the Hessian.\n",
    "* we add a prior variance to our Hessian. The precision is 1 over the variance. we use a prior precision of 10, 20, and 50 (or variance of 1/10, 1/20, 1/50).\n",
    "    * edit: I will use precicisions of 10, 60, 120, 1000 in the following\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Hessian_NN(model, train_loader, prec0, device='cpu', verbose=True):\n",
    "    lossfunc = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    extend(lossfunc, debug=False)\n",
    "    extend(model, debug=False)\n",
    "\n",
    "    Hessian_diag = []\n",
    "    for param in model.parameters():\n",
    "        ps = param.size()\n",
    "        print(\"parameter size: \", ps)\n",
    "        Hessian_diag.append(torch.zeros(ps, device=device))\n",
    "        #print(param.numel())\n",
    "\n",
    "    var0 = 1/prec0\n",
    "    max_len = len(train_loader)\n",
    "\n",
    "    with backpack(DiagHessian()):\n",
    "\n",
    "        for batch_idx, (x, y) in enumerate(train_loader):\n",
    "\n",
    "            if device == 'cuda':\n",
    "                x, y = x.float().cuda(), y.long().cuda()\n",
    "\n",
    "            model.zero_grad()\n",
    "            lossfunc(model(x), y).backward()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Hessian of weight\n",
    "                for idx, param in enumerate(model.parameters()):\n",
    "\n",
    "                    H_ = param.diag_h\n",
    "                    #add prior here\n",
    "                    H_ += var0 * torch.ones(H_.size())\n",
    "\n",
    "                    rho = 1-1/(batch_idx+1)\n",
    "\n",
    "                    Hessian_diag[idx] = rho*Hessian_diag[idx] + (1-rho)* H_\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Batch: {}/{}\".format(batch_idx, max_len))\n",
    "    \n",
    "    return(Hessian_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter size:  torch.Size([32, 1, 5, 5])\n",
      "parameter size:  torch.Size([32])\n",
      "parameter size:  torch.Size([32, 32, 5, 5])\n",
      "parameter size:  torch.Size([32])\n",
      "parameter size:  torch.Size([10, 512])\n",
      "parameter size:  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "MNIST_NN_Hessian_diag_10 = get_Hessian_NN(model=mnist_model, train_loader=mnist_train_loader, prec0=10,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0.1037, 0.1051, 0.1051, 0.1048, 0.1055],\n",
      "          [0.1031, 0.1068, 0.1095, 0.1094, 0.1096],\n",
      "          [0.1041, 0.1085, 0.1117, 0.1107, 0.1091],\n",
      "          [0.1064, 0.1085, 0.1079, 0.1073, 0.1070],\n",
      "          [0.1062, 0.1057, 0.1054, 0.1067, 0.1087]]],\n",
      "\n",
      "\n",
      "        [[[0.1005, 0.1006, 0.1006, 0.1006, 0.1005],\n",
      "          [0.1004, 0.1005, 0.1005, 0.1005, 0.1004],\n",
      "          [0.1004, 0.1005, 0.1005, 0.1004, 0.1003],\n",
      "          [0.1005, 0.1006, 0.1005, 0.1003, 0.1003],\n",
      "          [0.1006, 0.1007, 0.1004, 0.1003, 0.1003]]],\n",
      "\n",
      "\n",
      "        [[[0.1011, 0.1020, 0.1029, 0.1030, 0.1030],\n",
      "          [0.1013, 0.1022, 0.1034, 0.1041, 0.1044],\n",
      "          [0.1014, 0.1024, 0.1031, 0.1041, 0.1045],\n",
      "          [0.1017, 0.1021, 0.1022, 0.1028, 0.1034],\n",
      "          [0.1017, 0.1016, 0.1016, 0.1020, 0.1025]]],\n",
      "\n",
      "\n",
      "        [[[0.1035, 0.1046, 0.1041, 0.1021, 0.1012],\n",
      "          [0.1037, 0.1048, 0.1034, 0.1015, 0.1011],\n",
      "          [0.1034, 0.1045, 0.1035, 0.1021, 0.1020],\n",
      "          [0.1028, 0.1039, 0.1041, 0.1038, 0.1037],\n",
      "          [0.1023, 0.1031, 0.1040, 0.1043, 0.1038]]],\n",
      "\n",
      "\n",
      "        [[[0.1015, 0.1022, 0.1020, 0.1013, 0.1012],\n",
      "          [0.1018, 0.1019, 0.1014, 0.1012, 0.1016],\n",
      "          [0.1019, 0.1017, 0.1014, 0.1018, 0.1029],\n",
      "          [0.1018, 0.1018, 0.1021, 0.1034, 0.1042],\n",
      "          [0.1016, 0.1019, 0.1029, 0.1042, 0.1042]]],\n",
      "\n",
      "\n",
      "        [[[0.1005, 0.1008, 0.1010, 0.1009, 0.1010],\n",
      "          [0.1006, 0.1009, 0.1008, 0.1007, 0.1007],\n",
      "          [0.1008, 0.1009, 0.1006, 0.1005, 0.1005],\n",
      "          [0.1009, 0.1008, 0.1004, 0.1004, 0.1006],\n",
      "          [0.1010, 0.1008, 0.1005, 0.1006, 0.1007]]],\n",
      "\n",
      "\n",
      "        [[[0.1011, 0.1012, 0.1016, 0.1023, 0.1026],\n",
      "          [0.1012, 0.1016, 0.1027, 0.1034, 0.1029],\n",
      "          [0.1018, 0.1029, 0.1040, 0.1033, 0.1020],\n",
      "          [0.1029, 0.1041, 0.1038, 0.1020, 0.1011],\n",
      "          [0.1036, 0.1039, 0.1027, 0.1013, 0.1009]]],\n",
      "\n",
      "\n",
      "        [[[0.1054, 0.1069, 0.1047, 0.1021, 0.1014],\n",
      "          [0.1063, 0.1065, 0.1033, 0.1014, 0.1011],\n",
      "          [0.1064, 0.1066, 0.1036, 0.1019, 0.1017],\n",
      "          [0.1062, 0.1071, 0.1053, 0.1036, 0.1034],\n",
      "          [0.1057, 0.1066, 0.1060, 0.1051, 0.1044]]],\n",
      "\n",
      "\n",
      "        [[[0.1014, 0.1012, 0.1021, 0.1032, 0.1031],\n",
      "          [0.1012, 0.1013, 0.1022, 0.1034, 0.1035],\n",
      "          [0.1018, 0.1019, 0.1021, 0.1028, 0.1031],\n",
      "          [0.1024, 0.1019, 0.1014, 0.1019, 0.1028],\n",
      "          [0.1022, 0.1011, 0.1009, 0.1017, 0.1025]]],\n",
      "\n",
      "\n",
      "        [[[0.1008, 0.1008, 0.1016, 0.1046, 0.1084],\n",
      "          [0.1005, 0.1005, 0.1016, 0.1062, 0.1110],\n",
      "          [0.1003, 0.1005, 0.1018, 0.1078, 0.1131],\n",
      "          [0.1004, 0.1009, 0.1033, 0.1101, 0.1131],\n",
      "          [0.1009, 0.1020, 0.1058, 0.1105, 0.1111]]],\n",
      "\n",
      "\n",
      "        [[[0.1019, 0.1023, 0.1019, 0.1018, 0.1022],\n",
      "          [0.1025, 0.1031, 0.1030, 0.1032, 0.1040],\n",
      "          [0.1036, 0.1045, 0.1051, 0.1061, 0.1063],\n",
      "          [0.1039, 0.1052, 0.1063, 0.1071, 0.1068],\n",
      "          [0.1036, 0.1047, 0.1059, 0.1067, 0.1056]]],\n",
      "\n",
      "\n",
      "        [[[0.1015, 0.1015, 0.1015, 0.1017, 0.1021],\n",
      "          [0.1011, 0.1010, 0.1011, 0.1017, 0.1023],\n",
      "          [0.1006, 0.1006, 0.1010, 0.1020, 0.1024],\n",
      "          [0.1007, 0.1009, 0.1016, 0.1025, 0.1023],\n",
      "          [0.1011, 0.1015, 0.1021, 0.1024, 0.1018]]],\n",
      "\n",
      "\n",
      "        [[[0.1032, 0.1042, 0.1047, 0.1050, 0.1042],\n",
      "          [0.1033, 0.1038, 0.1038, 0.1034, 0.1028],\n",
      "          [0.1025, 0.1021, 0.1015, 0.1012, 0.1013],\n",
      "          [0.1017, 0.1010, 0.1005, 0.1004, 0.1006],\n",
      "          [0.1012, 0.1006, 0.1003, 0.1002, 0.1005]]],\n",
      "\n",
      "\n",
      "        [[[0.1017, 0.1025, 0.1036, 0.1042, 0.1040],\n",
      "          [0.1021, 0.1032, 0.1040, 0.1040, 0.1038],\n",
      "          [0.1022, 0.1026, 0.1023, 0.1020, 0.1024],\n",
      "          [0.1017, 0.1015, 0.1010, 0.1010, 0.1015],\n",
      "          [0.1013, 0.1009, 0.1008, 0.1009, 0.1015]]],\n",
      "\n",
      "\n",
      "        [[[0.1027, 0.1021, 0.1012, 0.1008, 0.1008],\n",
      "          [0.1024, 0.1016, 0.1008, 0.1007, 0.1008],\n",
      "          [0.1025, 0.1016, 0.1010, 0.1010, 0.1012],\n",
      "          [0.1029, 0.1026, 0.1024, 0.1021, 0.1019],\n",
      "          [0.1030, 0.1033, 0.1034, 0.1029, 0.1023]]],\n",
      "\n",
      "\n",
      "        [[[0.1002, 0.1003, 0.1003, 0.1002, 0.1002],\n",
      "          [0.1002, 0.1003, 0.1003, 0.1002, 0.1002],\n",
      "          [0.1003, 0.1003, 0.1003, 0.1002, 0.1003],\n",
      "          [0.1003, 0.1003, 0.1002, 0.1003, 0.1003],\n",
      "          [0.1002, 0.1002, 0.1002, 0.1002, 0.1003]]],\n",
      "\n",
      "\n",
      "        [[[0.1005, 0.1004, 0.1008, 0.1024, 0.1051],\n",
      "          [0.1003, 0.1003, 0.1011, 0.1042, 0.1071],\n",
      "          [0.1004, 0.1007, 0.1025, 0.1067, 0.1083],\n",
      "          [0.1009, 0.1019, 0.1051, 0.1084, 0.1079],\n",
      "          [0.1022, 0.1041, 0.1072, 0.1087, 0.1068]]],\n",
      "\n",
      "\n",
      "        [[[0.1013, 0.1011, 0.1012, 0.1018, 0.1025],\n",
      "          [0.1013, 0.1013, 0.1019, 0.1030, 0.1038],\n",
      "          [0.1017, 0.1025, 0.1042, 0.1058, 0.1054],\n",
      "          [0.1030, 0.1051, 0.1068, 0.1068, 0.1056],\n",
      "          [0.1042, 0.1061, 0.1069, 0.1057, 0.1046]]],\n",
      "\n",
      "\n",
      "        [[[0.1009, 0.1010, 0.1015, 0.1020, 0.1020],\n",
      "          [0.1010, 0.1013, 0.1019, 0.1022, 0.1019],\n",
      "          [0.1016, 0.1020, 0.1021, 0.1017, 0.1013],\n",
      "          [0.1020, 0.1019, 0.1015, 0.1010, 0.1009],\n",
      "          [0.1018, 0.1014, 0.1011, 0.1008, 0.1008]]],\n",
      "\n",
      "\n",
      "        [[[0.1026, 0.1031, 0.1034, 0.1036, 0.1037],\n",
      "          [0.1024, 0.1024, 0.1026, 0.1030, 0.1033],\n",
      "          [0.1015, 0.1012, 0.1014, 0.1019, 0.1024],\n",
      "          [0.1007, 0.1006, 0.1009, 0.1015, 0.1018],\n",
      "          [0.1005, 0.1006, 0.1009, 0.1014, 0.1016]]],\n",
      "\n",
      "\n",
      "        [[[0.1044, 0.1060, 0.1077, 0.1090, 0.1080],\n",
      "          [0.1045, 0.1058, 0.1068, 0.1072, 0.1071],\n",
      "          [0.1042, 0.1042, 0.1034, 0.1039, 0.1054],\n",
      "          [0.1034, 0.1024, 0.1017, 0.1026, 0.1044],\n",
      "          [0.1026, 0.1016, 0.1015, 0.1028, 0.1043]]],\n",
      "\n",
      "\n",
      "        [[[0.1009, 0.1008, 0.1010, 0.1012, 0.1012],\n",
      "          [0.1006, 0.1006, 0.1009, 0.1011, 0.1009],\n",
      "          [0.1006, 0.1007, 0.1009, 0.1009, 0.1006],\n",
      "          [0.1007, 0.1009, 0.1009, 0.1007, 0.1005],\n",
      "          [0.1009, 0.1010, 0.1009, 0.1006, 0.1005]]],\n",
      "\n",
      "\n",
      "        [[[0.1009, 0.1007, 0.1007, 0.1004, 0.1003],\n",
      "          [0.1005, 0.1004, 0.1005, 0.1004, 0.1004],\n",
      "          [0.1004, 0.1004, 0.1005, 0.1004, 0.1004],\n",
      "          [0.1006, 0.1005, 0.1004, 0.1004, 0.1005],\n",
      "          [0.1006, 0.1005, 0.1004, 0.1005, 0.1006]]],\n",
      "\n",
      "\n",
      "        [[[0.1008, 0.1009, 0.1014, 0.1027, 0.1043],\n",
      "          [0.1007, 0.1009, 0.1019, 0.1040, 0.1057],\n",
      "          [0.1010, 0.1016, 0.1032, 0.1061, 0.1067],\n",
      "          [0.1018, 0.1032, 0.1057, 0.1076, 0.1067],\n",
      "          [0.1023, 0.1041, 0.1064, 0.1071, 0.1054]]],\n",
      "\n",
      "\n",
      "        [[[0.1013, 0.1019, 0.1014, 0.1006, 0.1004],\n",
      "          [0.1016, 0.1018, 0.1009, 0.1004, 0.1005],\n",
      "          [0.1017, 0.1016, 0.1008, 0.1006, 0.1007],\n",
      "          [0.1017, 0.1015, 0.1009, 0.1009, 0.1010],\n",
      "          [0.1017, 0.1016, 0.1011, 0.1009, 0.1008]]],\n",
      "\n",
      "\n",
      "        [[[0.1036, 0.1045, 0.1053, 0.1068, 0.1064],\n",
      "          [0.1035, 0.1042, 0.1049, 0.1055, 0.1053],\n",
      "          [0.1033, 0.1030, 0.1026, 0.1028, 0.1037],\n",
      "          [0.1023, 0.1016, 0.1014, 0.1019, 0.1030],\n",
      "          [0.1016, 0.1012, 0.1013, 0.1020, 0.1033]]],\n",
      "\n",
      "\n",
      "        [[[0.1006, 0.1006, 0.1004, 0.1004, 0.1005],\n",
      "          [0.1007, 0.1007, 0.1005, 0.1005, 0.1006],\n",
      "          [0.1008, 0.1008, 0.1008, 0.1008, 0.1008],\n",
      "          [0.1009, 0.1010, 0.1010, 0.1011, 0.1009],\n",
      "          [0.1008, 0.1009, 0.1010, 0.1011, 0.1009]]],\n",
      "\n",
      "\n",
      "        [[[0.1020, 0.1032, 0.1042, 0.1035, 0.1019],\n",
      "          [0.1025, 0.1040, 0.1046, 0.1029, 0.1013],\n",
      "          [0.1032, 0.1048, 0.1046, 0.1021, 0.1010],\n",
      "          [0.1037, 0.1053, 0.1043, 0.1016, 0.1008],\n",
      "          [0.1038, 0.1050, 0.1038, 0.1018, 0.1011]]],\n",
      "\n",
      "\n",
      "        [[[0.1061, 0.1090, 0.1103, 0.1103, 0.1090],\n",
      "          [0.1101, 0.1137, 0.1129, 0.1123, 0.1099],\n",
      "          [0.1105, 0.1112, 0.1102, 0.1083, 0.1072],\n",
      "          [0.1075, 0.1055, 0.1049, 0.1044, 0.1045],\n",
      "          [0.1039, 0.1030, 0.1028, 0.1030, 0.1038]]],\n",
      "\n",
      "\n",
      "        [[[0.1012, 0.1011, 0.1007, 0.1006, 0.1008],\n",
      "          [0.1010, 0.1009, 0.1005, 0.1006, 0.1009],\n",
      "          [0.1008, 0.1008, 0.1007, 0.1009, 0.1010],\n",
      "          [0.1008, 0.1009, 0.1009, 0.1010, 0.1009],\n",
      "          [0.1009, 0.1010, 0.1007, 0.1006, 0.1007]]],\n",
      "\n",
      "\n",
      "        [[[0.1006, 0.1007, 0.1005, 0.1004, 0.1005],\n",
      "          [0.1007, 0.1005, 0.1003, 0.1003, 0.1006],\n",
      "          [0.1006, 0.1004, 0.1003, 0.1005, 0.1007],\n",
      "          [0.1005, 0.1004, 0.1004, 0.1007, 0.1007],\n",
      "          [0.1006, 0.1006, 0.1007, 0.1009, 0.1006]]],\n",
      "\n",
      "\n",
      "        [[[0.1003, 0.1003, 0.1004, 0.1004, 0.1004],\n",
      "          [0.1003, 0.1003, 0.1004, 0.1004, 0.1004],\n",
      "          [0.1003, 0.1004, 0.1004, 0.1004, 0.1003],\n",
      "          [0.1003, 0.1004, 0.1003, 0.1002, 0.1002],\n",
      "          [0.1004, 0.1005, 0.1003, 0.1002, 0.1002]]]]), tensor([0.1292, 0.1010, 0.1074, 0.1114, 0.1070, 0.1027, 0.1071, 0.1139, 0.1124,\n",
      "        0.1275, 0.1155, 0.1040, 0.1220, 0.1136, 0.1050, 0.1007, 0.1228, 0.1131,\n",
      "        0.1053, 0.1119, 0.1282, 0.1023, 0.1029, 0.1184, 0.1037, 0.1142, 0.1018,\n",
      "        0.1095, 0.1284, 0.1029, 0.1018, 0.1008]), tensor([[[[0.1001, 0.1001, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1001, 0.1000, 0.1000, 0.1001, 0.1001],\n",
      "          [0.1001, 0.1001, 0.1002, 0.1002, 0.1001]],\n",
      "\n",
      "         [[0.1003, 0.1002, 0.1003, 0.1005, 0.1005],\n",
      "          [0.1003, 0.1003, 0.1005, 0.1006, 0.1005],\n",
      "          [0.1003, 0.1004, 0.1005, 0.1005, 0.1004],\n",
      "          [0.1004, 0.1005, 0.1005, 0.1005, 0.1007],\n",
      "          [0.1005, 0.1007, 0.1007, 0.1008, 0.1009]],\n",
      "\n",
      "         [[0.1003, 0.1002, 0.1003, 0.1004, 0.1004],\n",
      "          [0.1003, 0.1003, 0.1005, 0.1006, 0.1005],\n",
      "          [0.1002, 0.1002, 0.1004, 0.1004, 0.1003],\n",
      "          [0.1002, 0.1003, 0.1003, 0.1003, 0.1003],\n",
      "          [0.1005, 0.1006, 0.1007, 0.1007, 0.1007]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.1001, 0.1001, 0.1001, 0.1002, 0.1002],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1002, 0.1001],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1001, 0.1002, 0.1002, 0.1003, 0.1002],\n",
      "          [0.1002, 0.1002, 0.1003, 0.1004, 0.1003]],\n",
      "\n",
      "         [[0.1000, 0.1000, 0.1000, 0.1000, 0.1001],\n",
      "          [0.1001, 0.1000, 0.1000, 0.1001, 0.1001],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1001, 0.1001]],\n",
      "\n",
      "         [[0.1001, 0.1001, 0.1002, 0.1003, 0.1002],\n",
      "          [0.1001, 0.1002, 0.1003, 0.1003, 0.1002],\n",
      "          [0.1001, 0.1002, 0.1003, 0.1002, 0.1001],\n",
      "          [0.1002, 0.1002, 0.1002, 0.1002, 0.1003],\n",
      "          [0.1002, 0.1003, 0.1003, 0.1004, 0.1004]]],\n",
      "\n",
      "\n",
      "        [[[0.1001, 0.1001, 0.1001, 0.1001, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1001, 0.1001, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1001],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1001, 0.1000],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1000, 0.1000]],\n",
      "\n",
      "         [[0.1003, 0.1004, 0.1005, 0.1005, 0.1004],\n",
      "          [0.1003, 0.1004, 0.1005, 0.1005, 0.1005],\n",
      "          [0.1003, 0.1004, 0.1005, 0.1006, 0.1006],\n",
      "          [0.1003, 0.1004, 0.1006, 0.1007, 0.1005],\n",
      "          [0.1003, 0.1005, 0.1006, 0.1004, 0.1002]],\n",
      "\n",
      "         [[0.1003, 0.1004, 0.1005, 0.1004, 0.1003],\n",
      "          [0.1002, 0.1003, 0.1003, 0.1003, 0.1003],\n",
      "          [0.1002, 0.1002, 0.1002, 0.1003, 0.1004],\n",
      "          [0.1004, 0.1004, 0.1005, 0.1006, 0.1005],\n",
      "          [0.1004, 0.1005, 0.1005, 0.1005, 0.1003]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.1001, 0.1001, 0.1001, 0.1002, 0.1002],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1001, 0.1002],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1002, 0.1002],\n",
      "          [0.1001, 0.1002, 0.1002, 0.1002, 0.1002],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1001, 0.1001]],\n",
      "\n",
      "         [[0.1000, 0.1000, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1000, 0.1001, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1000, 0.1001, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1000, 0.1000, 0.1001, 0.1001, 0.1001]],\n",
      "\n",
      "         [[0.1001, 0.1002, 0.1002, 0.1002, 0.1002],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1001, 0.1002],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1002, 0.1003],\n",
      "          [0.1001, 0.1001, 0.1003, 0.1003, 0.1002],\n",
      "          [0.1001, 0.1002, 0.1002, 0.1001, 0.1001]]],\n",
      "\n",
      "\n",
      "        [[[0.1000, 0.1000, 0.1000, 0.1001, 0.1001],\n",
      "          [0.1000, 0.1000, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1000, 0.1001, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1000, 0.1001, 0.1002, 0.1002, 0.1001]],\n",
      "\n",
      "         [[0.1001, 0.1001, 0.1003, 0.1006, 0.1006],\n",
      "          [0.1001, 0.1002, 0.1008, 0.1009, 0.1006],\n",
      "          [0.1001, 0.1006, 0.1012, 0.1009, 0.1006],\n",
      "          [0.1004, 0.1010, 0.1012, 0.1008, 0.1007],\n",
      "          [0.1005, 0.1010, 0.1010, 0.1007, 0.1007]],\n",
      "\n",
      "         [[0.1001, 0.1001, 0.1001, 0.1003, 0.1004],\n",
      "          [0.1000, 0.1000, 0.1003, 0.1006, 0.1006],\n",
      "          [0.1001, 0.1001, 0.1006, 0.1007, 0.1004],\n",
      "          [0.1002, 0.1005, 0.1008, 0.1006, 0.1004],\n",
      "          [0.1003, 0.1009, 0.1012, 0.1008, 0.1006]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.1000, 0.1000, 0.1001, 0.1002, 0.1002],\n",
      "          [0.1000, 0.1000, 0.1002, 0.1003, 0.1002],\n",
      "          [0.1000, 0.1001, 0.1003, 0.1003, 0.1002],\n",
      "          [0.1001, 0.1001, 0.1004, 0.1004, 0.1003],\n",
      "          [0.1001, 0.1001, 0.1004, 0.1003, 0.1002]],\n",
      "\n",
      "         [[0.1000, 0.1000, 0.1000, 0.1001, 0.1001],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1001, 0.1001],\n",
      "          [0.1000, 0.1000, 0.1001, 0.1002, 0.1002],\n",
      "          [0.1000, 0.1000, 0.1002, 0.1002, 0.1001],\n",
      "          [0.1000, 0.1001, 0.1002, 0.1002, 0.1001]],\n",
      "\n",
      "         [[0.1000, 0.1000, 0.1001, 0.1003, 0.1003],\n",
      "          [0.1000, 0.1001, 0.1004, 0.1005, 0.1003],\n",
      "          [0.1000, 0.1002, 0.1006, 0.1004, 0.1002],\n",
      "          [0.1001, 0.1003, 0.1005, 0.1003, 0.1003],\n",
      "          [0.1002, 0.1003, 0.1003, 0.1002, 0.1002]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.1000, 0.1000, 0.1000, 0.1001, 0.1001],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1001, 0.1001],\n",
      "          [0.1000, 0.1001, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1000, 0.1001, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000]],\n",
      "\n",
      "         [[0.1002, 0.1003, 0.1003, 0.1003, 0.1003],\n",
      "          [0.1003, 0.1003, 0.1003, 0.1004, 0.1004],\n",
      "          [0.1003, 0.1004, 0.1004, 0.1004, 0.1003],\n",
      "          [0.1002, 0.1003, 0.1002, 0.1002, 0.1002],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1001, 0.1002]],\n",
      "\n",
      "         [[0.1001, 0.1002, 0.1002, 0.1002, 0.1003],\n",
      "          [0.1002, 0.1002, 0.1003, 0.1003, 0.1004],\n",
      "          [0.1003, 0.1004, 0.1004, 0.1004, 0.1004],\n",
      "          [0.1003, 0.1003, 0.1003, 0.1003, 0.1002],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1001, 0.1001]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.1000, 0.1001, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1000, 0.1001, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1000, 0.1001, 0.1001, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1001]],\n",
      "\n",
      "         [[0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1001, 0.1000, 0.1001],\n",
      "          [0.1000, 0.1001, 0.1001, 0.1000, 0.1001],\n",
      "          [0.1000, 0.1000, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000]],\n",
      "\n",
      "         [[0.1001, 0.1001, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1002, 0.1002],\n",
      "          [0.1001, 0.1001, 0.1002, 0.1002, 0.1001],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1001, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1001]]],\n",
      "\n",
      "\n",
      "        [[[0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000]],\n",
      "\n",
      "         [[0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000]],\n",
      "\n",
      "         [[0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000]],\n",
      "\n",
      "         [[0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000]],\n",
      "\n",
      "         [[0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1000, 0.1000]]],\n",
      "\n",
      "\n",
      "        [[[0.1001, 0.1001, 0.1002, 0.1002, 0.1002],\n",
      "          [0.1003, 0.1004, 0.1003, 0.1002, 0.1001],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1000, 0.1001],\n",
      "          [0.1000, 0.1000, 0.1000, 0.1001, 0.1001],\n",
      "          [0.1001, 0.1001, 0.1002, 0.1002, 0.1001]],\n",
      "\n",
      "         [[0.1005, 0.1008, 0.1011, 0.1011, 0.1011],\n",
      "          [0.1009, 0.1012, 0.1012, 0.1011, 0.1012],\n",
      "          [0.1007, 0.1007, 0.1006, 0.1008, 0.1013],\n",
      "          [0.1004, 0.1003, 0.1005, 0.1011, 0.1013],\n",
      "          [0.1004, 0.1005, 0.1010, 0.1014, 0.1012]],\n",
      "\n",
      "         [[0.1004, 0.1005, 0.1008, 0.1009, 0.1008],\n",
      "          [0.1011, 0.1016, 0.1016, 0.1012, 0.1009],\n",
      "          [0.1006, 0.1007, 0.1006, 0.1004, 0.1006],\n",
      "          [0.1002, 0.1002, 0.1002, 0.1004, 0.1008],\n",
      "          [0.1004, 0.1005, 0.1006, 0.1010, 0.1010]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.1002, 0.1004, 0.1005, 0.1004, 0.1004],\n",
      "          [0.1002, 0.1003, 0.1003, 0.1003, 0.1003],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1002, 0.1003],\n",
      "          [0.1001, 0.1001, 0.1002, 0.1003, 0.1003],\n",
      "          [0.1002, 0.1003, 0.1003, 0.1003, 0.1004]],\n",
      "\n",
      "         [[0.1001, 0.1001, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1002, 0.1002],\n",
      "          [0.1001, 0.1001, 0.1002, 0.1002, 0.1002],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1001, 0.1001],\n",
      "          [0.1001, 0.1001, 0.1001, 0.1001, 0.1002]],\n",
      "\n",
      "         [[0.1002, 0.1004, 0.1005, 0.1005, 0.1004],\n",
      "          [0.1004, 0.1005, 0.1004, 0.1003, 0.1004],\n",
      "          [0.1003, 0.1002, 0.1001, 0.1002, 0.1005],\n",
      "          [0.1001, 0.1001, 0.1002, 0.1005, 0.1006],\n",
      "          [0.1002, 0.1002, 0.1005, 0.1006, 0.1005]]]]), tensor([0.1014, 0.1010, 0.1014, 0.1013, 0.1007, 0.1005, 0.1015, 0.1008, 0.1000,\n",
      "        0.1012, 0.1005, 0.1009, 0.1012, 0.1018, 0.1000, 0.1011, 0.1011, 0.1003,\n",
      "        0.1000, 0.1010, 0.1015, 0.1012, 0.1020, 0.1007, 0.1007, 0.1012, 0.1004,\n",
      "        0.1000, 0.1007, 0.1007, 0.1000, 0.1028]), tensor([[0.1045, 0.1088, 0.1072,  ..., 0.1047, 0.1076, 0.1074],\n",
      "        [0.1043, 0.1044, 0.1020,  ..., 0.1021, 0.1014, 0.1024],\n",
      "        [0.1237, 0.1367, 0.1187,  ..., 0.1141, 0.1149, 0.1153],\n",
      "        ...,\n",
      "        [0.1113, 0.1141, 0.1082,  ..., 0.1190, 0.1107, 0.1092],\n",
      "        [0.1141, 0.1397, 0.1330,  ..., 0.1081, 0.1074, 0.1064],\n",
      "        [0.1076, 0.1172, 0.1117,  ..., 0.1363, 0.1171, 0.1041]]), tensor([0.1014, 0.1016, 0.1027, 0.1032, 0.1023, 0.1024, 0.1014, 0.1028, 0.1039,\n",
      "        0.1035])]\n"
     ]
    }
   ],
   "source": [
    "print(MNIST_NN_Hessian_diag_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter size:  torch.Size([32, 1, 5, 5])\n",
      "parameter size:  torch.Size([32])\n",
      "parameter size:  torch.Size([32, 32, 5, 5])\n",
      "parameter size:  torch.Size([32])\n",
      "parameter size:  torch.Size([10, 512])\n",
      "parameter size:  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "MNIST_NN_Hessian_diag_60 = get_Hessian_NN(model=mnist_model, train_loader=mnist_train_loader, prec0=60,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0.0174, 0.0174, 0.0174, 0.0173, 0.0171],\n",
      "          [0.0173, 0.0173, 0.0173, 0.0172, 0.0170],\n",
      "          [0.0174, 0.0174, 0.0173, 0.0171, 0.0171],\n",
      "          [0.0174, 0.0175, 0.0173, 0.0171, 0.0171],\n",
      "          [0.0174, 0.0175, 0.0174, 0.0172, 0.0171]]],\n",
      "\n",
      "\n",
      "        [[[0.0171, 0.0172, 0.0173, 0.0173, 0.0171],\n",
      "          [0.0172, 0.0172, 0.0173, 0.0171, 0.0171],\n",
      "          [0.0172, 0.0172, 0.0173, 0.0172, 0.0171],\n",
      "          [0.0171, 0.0171, 0.0172, 0.0172, 0.0172],\n",
      "          [0.0170, 0.0171, 0.0171, 0.0172, 0.0172]]],\n",
      "\n",
      "\n",
      "        [[[0.0182, 0.0187, 0.0196, 0.0203, 0.0200],\n",
      "          [0.0186, 0.0197, 0.0206, 0.0202, 0.0190],\n",
      "          [0.0193, 0.0204, 0.0205, 0.0190, 0.0180],\n",
      "          [0.0202, 0.0208, 0.0195, 0.0179, 0.0174],\n",
      "          [0.0208, 0.0207, 0.0190, 0.0177, 0.0174]]],\n",
      "\n",
      "\n",
      "        [[[0.0169, 0.0170, 0.0172, 0.0177, 0.0180],\n",
      "          [0.0169, 0.0170, 0.0175, 0.0182, 0.0181],\n",
      "          [0.0170, 0.0174, 0.0182, 0.0186, 0.0181],\n",
      "          [0.0174, 0.0181, 0.0188, 0.0186, 0.0178],\n",
      "          [0.0179, 0.0187, 0.0189, 0.0182, 0.0176]]],\n",
      "\n",
      "\n",
      "        [[[0.0193, 0.0198, 0.0190, 0.0177, 0.0172],\n",
      "          [0.0199, 0.0198, 0.0184, 0.0173, 0.0171],\n",
      "          [0.0208, 0.0205, 0.0187, 0.0177, 0.0176],\n",
      "          [0.0217, 0.0215, 0.0198, 0.0187, 0.0185],\n",
      "          [0.0222, 0.0220, 0.0206, 0.0194, 0.0190]]],\n",
      "\n",
      "\n",
      "        [[[0.0175, 0.0173, 0.0173, 0.0176, 0.0177],\n",
      "          [0.0174, 0.0172, 0.0172, 0.0178, 0.0179],\n",
      "          [0.0174, 0.0172, 0.0176, 0.0182, 0.0180],\n",
      "          [0.0177, 0.0178, 0.0183, 0.0184, 0.0178],\n",
      "          [0.0182, 0.0185, 0.0186, 0.0182, 0.0176]]],\n",
      "\n",
      "\n",
      "        [[[0.0172, 0.0172, 0.0173, 0.0173, 0.0173],\n",
      "          [0.0172, 0.0173, 0.0174, 0.0172, 0.0171],\n",
      "          [0.0173, 0.0174, 0.0173, 0.0170, 0.0170],\n",
      "          [0.0172, 0.0174, 0.0174, 0.0171, 0.0169],\n",
      "          [0.0171, 0.0174, 0.0175, 0.0172, 0.0170]]],\n",
      "\n",
      "\n",
      "        [[[0.0170, 0.0170, 0.0171, 0.0171, 0.0170],\n",
      "          [0.0171, 0.0171, 0.0171, 0.0170, 0.0170],\n",
      "          [0.0171, 0.0170, 0.0170, 0.0170, 0.0170],\n",
      "          [0.0170, 0.0170, 0.0170, 0.0171, 0.0171],\n",
      "          [0.0170, 0.0170, 0.0170, 0.0171, 0.0172]]],\n",
      "\n",
      "\n",
      "        [[[0.0199, 0.0198, 0.0203, 0.0213, 0.0219],\n",
      "          [0.0205, 0.0195, 0.0189, 0.0193, 0.0202],\n",
      "          [0.0231, 0.0208, 0.0187, 0.0188, 0.0191],\n",
      "          [0.0255, 0.0237, 0.0208, 0.0200, 0.0194],\n",
      "          [0.0255, 0.0259, 0.0234, 0.0214, 0.0201]]],\n",
      "\n",
      "\n",
      "        [[[0.0179, 0.0182, 0.0183, 0.0181, 0.0179],\n",
      "          [0.0181, 0.0182, 0.0181, 0.0178, 0.0176],\n",
      "          [0.0181, 0.0178, 0.0173, 0.0172, 0.0172],\n",
      "          [0.0178, 0.0174, 0.0170, 0.0170, 0.0172],\n",
      "          [0.0176, 0.0173, 0.0171, 0.0171, 0.0176]]],\n",
      "\n",
      "\n",
      "        [[[0.0171, 0.0170, 0.0171, 0.0172, 0.0173],\n",
      "          [0.0173, 0.0173, 0.0174, 0.0176, 0.0176],\n",
      "          [0.0179, 0.0179, 0.0180, 0.0178, 0.0176],\n",
      "          [0.0186, 0.0183, 0.0181, 0.0179, 0.0176],\n",
      "          [0.0184, 0.0181, 0.0182, 0.0182, 0.0180]]],\n",
      "\n",
      "\n",
      "        [[[0.0194, 0.0198, 0.0203, 0.0201, 0.0196],\n",
      "          [0.0181, 0.0178, 0.0176, 0.0174, 0.0177],\n",
      "          [0.0171, 0.0169, 0.0169, 0.0169, 0.0175],\n",
      "          [0.0169, 0.0168, 0.0169, 0.0174, 0.0191],\n",
      "          [0.0174, 0.0175, 0.0182, 0.0197, 0.0213]]],\n",
      "\n",
      "\n",
      "        [[[0.0177, 0.0176, 0.0173, 0.0172, 0.0174],\n",
      "          [0.0178, 0.0176, 0.0174, 0.0174, 0.0179],\n",
      "          [0.0179, 0.0180, 0.0179, 0.0181, 0.0183],\n",
      "          [0.0177, 0.0181, 0.0184, 0.0184, 0.0181],\n",
      "          [0.0175, 0.0179, 0.0184, 0.0183, 0.0178]]],\n",
      "\n",
      "\n",
      "        [[[0.0173, 0.0170, 0.0168, 0.0169, 0.0171],\n",
      "          [0.0176, 0.0171, 0.0169, 0.0168, 0.0170],\n",
      "          [0.0186, 0.0180, 0.0175, 0.0174, 0.0179],\n",
      "          [0.0203, 0.0203, 0.0198, 0.0197, 0.0204],\n",
      "          [0.0213, 0.0222, 0.0221, 0.0222, 0.0229]]],\n",
      "\n",
      "\n",
      "        [[[0.0178, 0.0177, 0.0177, 0.0177, 0.0176],\n",
      "          [0.0177, 0.0176, 0.0175, 0.0175, 0.0176],\n",
      "          [0.0175, 0.0173, 0.0171, 0.0171, 0.0172],\n",
      "          [0.0173, 0.0172, 0.0169, 0.0169, 0.0170],\n",
      "          [0.0173, 0.0171, 0.0169, 0.0169, 0.0170]]],\n",
      "\n",
      "\n",
      "        [[[0.0174, 0.0176, 0.0178, 0.0178, 0.0174],\n",
      "          [0.0174, 0.0174, 0.0176, 0.0177, 0.0174],\n",
      "          [0.0172, 0.0171, 0.0173, 0.0177, 0.0176],\n",
      "          [0.0170, 0.0170, 0.0173, 0.0177, 0.0177],\n",
      "          [0.0169, 0.0170, 0.0174, 0.0177, 0.0177]]],\n",
      "\n",
      "\n",
      "        [[[0.0173, 0.0170, 0.0170, 0.0179, 0.0197],\n",
      "          [0.0169, 0.0168, 0.0170, 0.0183, 0.0214],\n",
      "          [0.0168, 0.0168, 0.0174, 0.0203, 0.0237],\n",
      "          [0.0170, 0.0173, 0.0191, 0.0230, 0.0247],\n",
      "          [0.0177, 0.0188, 0.0215, 0.0249, 0.0249]]],\n",
      "\n",
      "\n",
      "        [[[0.0174, 0.0173, 0.0171, 0.0170, 0.0171],\n",
      "          [0.0175, 0.0174, 0.0172, 0.0171, 0.0172],\n",
      "          [0.0177, 0.0177, 0.0176, 0.0175, 0.0175],\n",
      "          [0.0176, 0.0179, 0.0179, 0.0179, 0.0177],\n",
      "          [0.0175, 0.0177, 0.0179, 0.0179, 0.0176]]],\n",
      "\n",
      "\n",
      "        [[[0.0170, 0.0169, 0.0169, 0.0170, 0.0170],\n",
      "          [0.0170, 0.0169, 0.0169, 0.0170, 0.0171],\n",
      "          [0.0170, 0.0170, 0.0170, 0.0171, 0.0171],\n",
      "          [0.0171, 0.0171, 0.0172, 0.0173, 0.0173],\n",
      "          [0.0174, 0.0174, 0.0174, 0.0172, 0.0171]]],\n",
      "\n",
      "\n",
      "        [[[0.0174, 0.0172, 0.0171, 0.0175, 0.0178],\n",
      "          [0.0174, 0.0172, 0.0173, 0.0178, 0.0180],\n",
      "          [0.0175, 0.0176, 0.0180, 0.0186, 0.0183],\n",
      "          [0.0180, 0.0184, 0.0188, 0.0187, 0.0179],\n",
      "          [0.0183, 0.0186, 0.0187, 0.0181, 0.0176]]],\n",
      "\n",
      "\n",
      "        [[[0.0170, 0.0169, 0.0169, 0.0171, 0.0174],\n",
      "          [0.0169, 0.0168, 0.0168, 0.0169, 0.0173],\n",
      "          [0.0170, 0.0169, 0.0170, 0.0171, 0.0177],\n",
      "          [0.0177, 0.0179, 0.0179, 0.0185, 0.0191],\n",
      "          [0.0185, 0.0190, 0.0193, 0.0199, 0.0201]]],\n",
      "\n",
      "\n",
      "        [[[0.0172, 0.0173, 0.0173, 0.0175, 0.0177],\n",
      "          [0.0171, 0.0171, 0.0172, 0.0176, 0.0178],\n",
      "          [0.0170, 0.0170, 0.0172, 0.0177, 0.0178],\n",
      "          [0.0170, 0.0171, 0.0174, 0.0178, 0.0176],\n",
      "          [0.0172, 0.0174, 0.0177, 0.0178, 0.0174]]],\n",
      "\n",
      "\n",
      "        [[[0.0243, 0.0294, 0.0330, 0.0345, 0.0321],\n",
      "          [0.0279, 0.0330, 0.0334, 0.0320, 0.0301],\n",
      "          [0.0296, 0.0300, 0.0263, 0.0247, 0.0250],\n",
      "          [0.0256, 0.0224, 0.0207, 0.0213, 0.0229],\n",
      "          [0.0218, 0.0196, 0.0195, 0.0215, 0.0246]]],\n",
      "\n",
      "\n",
      "        [[[0.0173, 0.0175, 0.0179, 0.0180, 0.0178],\n",
      "          [0.0175, 0.0176, 0.0181, 0.0184, 0.0182],\n",
      "          [0.0177, 0.0178, 0.0179, 0.0182, 0.0182],\n",
      "          [0.0176, 0.0175, 0.0174, 0.0178, 0.0180],\n",
      "          [0.0172, 0.0171, 0.0172, 0.0178, 0.0179]]],\n",
      "\n",
      "\n",
      "        [[[0.0170, 0.0171, 0.0177, 0.0192, 0.0208],\n",
      "          [0.0168, 0.0169, 0.0175, 0.0201, 0.0221],\n",
      "          [0.0168, 0.0169, 0.0177, 0.0210, 0.0228],\n",
      "          [0.0170, 0.0172, 0.0185, 0.0216, 0.0229],\n",
      "          [0.0172, 0.0178, 0.0193, 0.0217, 0.0221]]],\n",
      "\n",
      "\n",
      "        [[[0.0170, 0.0173, 0.0184, 0.0199, 0.0205],\n",
      "          [0.0169, 0.0173, 0.0192, 0.0219, 0.0214],\n",
      "          [0.0170, 0.0176, 0.0209, 0.0234, 0.0216],\n",
      "          [0.0174, 0.0191, 0.0236, 0.0243, 0.0209],\n",
      "          [0.0185, 0.0214, 0.0243, 0.0232, 0.0202]]],\n",
      "\n",
      "\n",
      "        [[[0.0177, 0.0175, 0.0175, 0.0176, 0.0178],\n",
      "          [0.0173, 0.0171, 0.0171, 0.0175, 0.0179],\n",
      "          [0.0171, 0.0171, 0.0173, 0.0179, 0.0180],\n",
      "          [0.0173, 0.0175, 0.0180, 0.0181, 0.0176],\n",
      "          [0.0177, 0.0181, 0.0183, 0.0178, 0.0173]]],\n",
      "\n",
      "\n",
      "        [[[0.0185, 0.0183, 0.0177, 0.0174, 0.0176],\n",
      "          [0.0184, 0.0180, 0.0175, 0.0174, 0.0176],\n",
      "          [0.0183, 0.0179, 0.0176, 0.0177, 0.0180],\n",
      "          [0.0181, 0.0182, 0.0183, 0.0184, 0.0184],\n",
      "          [0.0179, 0.0184, 0.0186, 0.0185, 0.0183]]],\n",
      "\n",
      "\n",
      "        [[[0.0175, 0.0174, 0.0171, 0.0169, 0.0169],\n",
      "          [0.0174, 0.0174, 0.0170, 0.0169, 0.0170],\n",
      "          [0.0175, 0.0175, 0.0171, 0.0170, 0.0172],\n",
      "          [0.0175, 0.0176, 0.0174, 0.0173, 0.0174],\n",
      "          [0.0173, 0.0176, 0.0176, 0.0175, 0.0173]]],\n",
      "\n",
      "\n",
      "        [[[0.0187, 0.0181, 0.0175, 0.0177, 0.0187],\n",
      "          [0.0186, 0.0177, 0.0176, 0.0185, 0.0197],\n",
      "          [0.0188, 0.0183, 0.0187, 0.0200, 0.0201],\n",
      "          [0.0191, 0.0194, 0.0199, 0.0201, 0.0191],\n",
      "          [0.0190, 0.0195, 0.0194, 0.0190, 0.0185]]],\n",
      "\n",
      "\n",
      "        [[[0.0216, 0.0220, 0.0225, 0.0233, 0.0238],\n",
      "          [0.0205, 0.0204, 0.0205, 0.0205, 0.0214],\n",
      "          [0.0191, 0.0186, 0.0181, 0.0181, 0.0195],\n",
      "          [0.0188, 0.0179, 0.0173, 0.0177, 0.0191],\n",
      "          [0.0197, 0.0184, 0.0177, 0.0182, 0.0194]]],\n",
      "\n",
      "\n",
      "        [[[0.0173, 0.0174, 0.0181, 0.0194, 0.0202],\n",
      "          [0.0172, 0.0173, 0.0182, 0.0199, 0.0207],\n",
      "          [0.0171, 0.0173, 0.0183, 0.0203, 0.0216],\n",
      "          [0.0171, 0.0175, 0.0188, 0.0209, 0.0220],\n",
      "          [0.0172, 0.0178, 0.0193, 0.0212, 0.0217]]]]), tensor([0.0183, 0.0177, 0.0248, 0.0206, 0.0291, 0.0200, 0.0188, 0.0176, 0.0398,\n",
      "        0.0207, 0.0219, 0.0445, 0.0195, 0.0464, 0.0178, 0.0194, 0.0338, 0.0192,\n",
      "        0.0180, 0.0207, 0.0293, 0.0185, 0.0590, 0.0200, 0.0278, 0.0324, 0.0207,\n",
      "        0.0190, 0.0180, 0.0246, 0.0373, 0.0273]), tensor([[[[0.0168, 0.0169, 0.0170, 0.0170, 0.0170],\n",
      "          [0.0168, 0.0169, 0.0171, 0.0171, 0.0170],\n",
      "          [0.0168, 0.0169, 0.0170, 0.0172, 0.0171],\n",
      "          [0.0169, 0.0169, 0.0170, 0.0172, 0.0172],\n",
      "          [0.0169, 0.0169, 0.0170, 0.0171, 0.0171]],\n",
      "\n",
      "         [[0.0167, 0.0168, 0.0169, 0.0168, 0.0168],\n",
      "          [0.0167, 0.0168, 0.0169, 0.0169, 0.0168],\n",
      "          [0.0167, 0.0167, 0.0168, 0.0170, 0.0169],\n",
      "          [0.0168, 0.0168, 0.0168, 0.0169, 0.0169],\n",
      "          [0.0168, 0.0168, 0.0168, 0.0168, 0.0168]],\n",
      "\n",
      "         [[0.0167, 0.0168, 0.0169, 0.0170, 0.0170],\n",
      "          [0.0168, 0.0168, 0.0169, 0.0170, 0.0171],\n",
      "          [0.0168, 0.0169, 0.0169, 0.0170, 0.0171],\n",
      "          [0.0168, 0.0169, 0.0169, 0.0170, 0.0170],\n",
      "          [0.0168, 0.0168, 0.0169, 0.0170, 0.0169]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0167, 0.0168, 0.0168, 0.0168, 0.0168],\n",
      "          [0.0168, 0.0168, 0.0168, 0.0168, 0.0168],\n",
      "          [0.0168, 0.0168, 0.0168, 0.0168, 0.0168],\n",
      "          [0.0168, 0.0168, 0.0168, 0.0168, 0.0168],\n",
      "          [0.0167, 0.0168, 0.0168, 0.0167, 0.0167]],\n",
      "\n",
      "         [[0.0168, 0.0168, 0.0167, 0.0168, 0.0168],\n",
      "          [0.0169, 0.0169, 0.0168, 0.0167, 0.0168],\n",
      "          [0.0168, 0.0169, 0.0169, 0.0167, 0.0167],\n",
      "          [0.0168, 0.0168, 0.0170, 0.0169, 0.0168],\n",
      "          [0.0169, 0.0169, 0.0170, 0.0171, 0.0170]],\n",
      "\n",
      "         [[0.0168, 0.0169, 0.0168, 0.0168, 0.0167],\n",
      "          [0.0168, 0.0169, 0.0169, 0.0168, 0.0167],\n",
      "          [0.0168, 0.0168, 0.0170, 0.0169, 0.0167],\n",
      "          [0.0168, 0.0168, 0.0169, 0.0169, 0.0167],\n",
      "          [0.0168, 0.0168, 0.0168, 0.0168, 0.0167]]],\n",
      "\n",
      "\n",
      "        [[[0.0172, 0.0171, 0.0169, 0.0169, 0.0170],\n",
      "          [0.0173, 0.0170, 0.0168, 0.0169, 0.0172],\n",
      "          [0.0173, 0.0170, 0.0169, 0.0173, 0.0176],\n",
      "          [0.0173, 0.0172, 0.0173, 0.0179, 0.0180],\n",
      "          [0.0174, 0.0175, 0.0178, 0.0182, 0.0180]],\n",
      "\n",
      "         [[0.0169, 0.0168, 0.0168, 0.0168, 0.0169],\n",
      "          [0.0169, 0.0168, 0.0168, 0.0170, 0.0171],\n",
      "          [0.0170, 0.0169, 0.0170, 0.0172, 0.0172],\n",
      "          [0.0171, 0.0171, 0.0172, 0.0173, 0.0172],\n",
      "          [0.0171, 0.0171, 0.0171, 0.0172, 0.0172]],\n",
      "\n",
      "         [[0.0178, 0.0176, 0.0169, 0.0168, 0.0170],\n",
      "          [0.0179, 0.0172, 0.0167, 0.0169, 0.0176],\n",
      "          [0.0175, 0.0169, 0.0168, 0.0175, 0.0185],\n",
      "          [0.0172, 0.0170, 0.0173, 0.0183, 0.0185],\n",
      "          [0.0171, 0.0173, 0.0178, 0.0183, 0.0177]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0170, 0.0168, 0.0167, 0.0168, 0.0169],\n",
      "          [0.0168, 0.0168, 0.0168, 0.0170, 0.0172],\n",
      "          [0.0168, 0.0169, 0.0171, 0.0174, 0.0173],\n",
      "          [0.0170, 0.0172, 0.0174, 0.0172, 0.0171],\n",
      "          [0.0170, 0.0172, 0.0172, 0.0170, 0.0170]],\n",
      "\n",
      "         [[0.0169, 0.0169, 0.0170, 0.0170, 0.0169],\n",
      "          [0.0169, 0.0169, 0.0169, 0.0168, 0.0168],\n",
      "          [0.0168, 0.0168, 0.0168, 0.0168, 0.0168],\n",
      "          [0.0169, 0.0169, 0.0170, 0.0169, 0.0170],\n",
      "          [0.0172, 0.0172, 0.0174, 0.0173, 0.0172]],\n",
      "\n",
      "         [[0.0168, 0.0167, 0.0168, 0.0170, 0.0170],\n",
      "          [0.0167, 0.0167, 0.0170, 0.0172, 0.0170],\n",
      "          [0.0168, 0.0169, 0.0173, 0.0173, 0.0169],\n",
      "          [0.0169, 0.0170, 0.0174, 0.0173, 0.0168],\n",
      "          [0.0170, 0.0172, 0.0174, 0.0171, 0.0168]]],\n",
      "\n",
      "\n",
      "        [[[0.0173, 0.0173, 0.0172, 0.0171, 0.0171],\n",
      "          [0.0174, 0.0172, 0.0170, 0.0169, 0.0172],\n",
      "          [0.0174, 0.0173, 0.0169, 0.0169, 0.0173],\n",
      "          [0.0175, 0.0174, 0.0171, 0.0170, 0.0174],\n",
      "          [0.0174, 0.0174, 0.0171, 0.0170, 0.0173]],\n",
      "\n",
      "         [[0.0170, 0.0169, 0.0168, 0.0169, 0.0170],\n",
      "          [0.0170, 0.0169, 0.0168, 0.0168, 0.0170],\n",
      "          [0.0171, 0.0171, 0.0169, 0.0169, 0.0171],\n",
      "          [0.0171, 0.0171, 0.0169, 0.0168, 0.0170],\n",
      "          [0.0170, 0.0170, 0.0169, 0.0168, 0.0169]],\n",
      "\n",
      "         [[0.0174, 0.0177, 0.0172, 0.0168, 0.0169],\n",
      "          [0.0175, 0.0176, 0.0169, 0.0167, 0.0169],\n",
      "          [0.0174, 0.0173, 0.0169, 0.0168, 0.0170],\n",
      "          [0.0173, 0.0173, 0.0171, 0.0169, 0.0171],\n",
      "          [0.0172, 0.0172, 0.0170, 0.0168, 0.0173]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0170, 0.0169, 0.0168, 0.0167, 0.0168],\n",
      "          [0.0168, 0.0168, 0.0168, 0.0168, 0.0169],\n",
      "          [0.0168, 0.0170, 0.0170, 0.0170, 0.0169],\n",
      "          [0.0169, 0.0170, 0.0170, 0.0169, 0.0168],\n",
      "          [0.0168, 0.0168, 0.0169, 0.0169, 0.0169]],\n",
      "\n",
      "         [[0.0170, 0.0171, 0.0173, 0.0172, 0.0170],\n",
      "          [0.0170, 0.0170, 0.0172, 0.0172, 0.0169],\n",
      "          [0.0169, 0.0168, 0.0169, 0.0171, 0.0169],\n",
      "          [0.0171, 0.0170, 0.0170, 0.0173, 0.0173],\n",
      "          [0.0173, 0.0173, 0.0173, 0.0174, 0.0173]],\n",
      "\n",
      "         [[0.0170, 0.0168, 0.0168, 0.0170, 0.0170],\n",
      "          [0.0170, 0.0167, 0.0168, 0.0171, 0.0171],\n",
      "          [0.0170, 0.0167, 0.0167, 0.0171, 0.0173],\n",
      "          [0.0171, 0.0168, 0.0167, 0.0171, 0.0173],\n",
      "          [0.0171, 0.0168, 0.0168, 0.0170, 0.0172]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0172, 0.0174, 0.0173, 0.0171, 0.0170],\n",
      "          [0.0171, 0.0173, 0.0173, 0.0171, 0.0170],\n",
      "          [0.0174, 0.0175, 0.0173, 0.0171, 0.0170],\n",
      "          [0.0177, 0.0178, 0.0175, 0.0173, 0.0171],\n",
      "          [0.0175, 0.0176, 0.0175, 0.0173, 0.0171]],\n",
      "\n",
      "         [[0.0169, 0.0171, 0.0170, 0.0169, 0.0169],\n",
      "          [0.0169, 0.0170, 0.0169, 0.0169, 0.0168],\n",
      "          [0.0171, 0.0172, 0.0171, 0.0169, 0.0169],\n",
      "          [0.0171, 0.0172, 0.0171, 0.0170, 0.0169],\n",
      "          [0.0169, 0.0169, 0.0170, 0.0169, 0.0168]],\n",
      "\n",
      "         [[0.0171, 0.0175, 0.0178, 0.0172, 0.0171],\n",
      "          [0.0172, 0.0179, 0.0177, 0.0171, 0.0171],\n",
      "          [0.0174, 0.0179, 0.0175, 0.0173, 0.0174],\n",
      "          [0.0176, 0.0176, 0.0175, 0.0176, 0.0173],\n",
      "          [0.0176, 0.0174, 0.0174, 0.0173, 0.0170]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0169, 0.0169, 0.0169, 0.0169, 0.0168],\n",
      "          [0.0170, 0.0169, 0.0169, 0.0169, 0.0168],\n",
      "          [0.0172, 0.0170, 0.0171, 0.0170, 0.0169],\n",
      "          [0.0170, 0.0170, 0.0171, 0.0169, 0.0168],\n",
      "          [0.0168, 0.0169, 0.0168, 0.0168, 0.0168]],\n",
      "\n",
      "         [[0.0171, 0.0169, 0.0169, 0.0169, 0.0168],\n",
      "          [0.0170, 0.0170, 0.0170, 0.0169, 0.0168],\n",
      "          [0.0168, 0.0168, 0.0168, 0.0168, 0.0168],\n",
      "          [0.0171, 0.0169, 0.0169, 0.0169, 0.0168],\n",
      "          [0.0175, 0.0174, 0.0173, 0.0171, 0.0170]],\n",
      "\n",
      "         [[0.0171, 0.0171, 0.0168, 0.0168, 0.0168],\n",
      "          [0.0171, 0.0170, 0.0168, 0.0169, 0.0168],\n",
      "          [0.0171, 0.0169, 0.0169, 0.0168, 0.0167],\n",
      "          [0.0171, 0.0170, 0.0169, 0.0168, 0.0167],\n",
      "          [0.0170, 0.0170, 0.0169, 0.0168, 0.0167]]],\n",
      "\n",
      "\n",
      "        [[[0.0167, 0.0167, 0.0167, 0.0168, 0.0168],\n",
      "          [0.0168, 0.0168, 0.0169, 0.0169, 0.0169],\n",
      "          [0.0168, 0.0168, 0.0169, 0.0170, 0.0170],\n",
      "          [0.0168, 0.0168, 0.0169, 0.0169, 0.0169],\n",
      "          [0.0168, 0.0168, 0.0169, 0.0168, 0.0168]],\n",
      "\n",
      "         [[0.0167, 0.0167, 0.0168, 0.0168, 0.0168],\n",
      "          [0.0167, 0.0168, 0.0168, 0.0169, 0.0169],\n",
      "          [0.0167, 0.0167, 0.0167, 0.0168, 0.0168],\n",
      "          [0.0167, 0.0167, 0.0167, 0.0167, 0.0167],\n",
      "          [0.0167, 0.0168, 0.0168, 0.0168, 0.0167]],\n",
      "\n",
      "         [[0.0167, 0.0167, 0.0167, 0.0168, 0.0168],\n",
      "          [0.0167, 0.0168, 0.0168, 0.0169, 0.0170],\n",
      "          [0.0168, 0.0169, 0.0170, 0.0170, 0.0169],\n",
      "          [0.0168, 0.0168, 0.0169, 0.0169, 0.0169],\n",
      "          [0.0167, 0.0168, 0.0168, 0.0169, 0.0169]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0167, 0.0167, 0.0167, 0.0168, 0.0168],\n",
      "          [0.0168, 0.0168, 0.0169, 0.0169, 0.0168],\n",
      "          [0.0167, 0.0168, 0.0168, 0.0167, 0.0167],\n",
      "          [0.0167, 0.0167, 0.0167, 0.0167, 0.0167],\n",
      "          [0.0167, 0.0167, 0.0168, 0.0168, 0.0168]],\n",
      "\n",
      "         [[0.0167, 0.0167, 0.0167, 0.0167, 0.0167],\n",
      "          [0.0167, 0.0167, 0.0167, 0.0167, 0.0167],\n",
      "          [0.0168, 0.0169, 0.0170, 0.0170, 0.0169],\n",
      "          [0.0168, 0.0168, 0.0169, 0.0169, 0.0169],\n",
      "          [0.0168, 0.0168, 0.0167, 0.0167, 0.0167]],\n",
      "\n",
      "         [[0.0167, 0.0167, 0.0167, 0.0167, 0.0167],\n",
      "          [0.0167, 0.0168, 0.0168, 0.0168, 0.0167],\n",
      "          [0.0168, 0.0168, 0.0168, 0.0168, 0.0168],\n",
      "          [0.0168, 0.0168, 0.0168, 0.0168, 0.0168],\n",
      "          [0.0168, 0.0168, 0.0168, 0.0167, 0.0168]]],\n",
      "\n",
      "\n",
      "        [[[0.0175, 0.0175, 0.0173, 0.0171, 0.0171],\n",
      "          [0.0177, 0.0177, 0.0174, 0.0172, 0.0172],\n",
      "          [0.0177, 0.0179, 0.0176, 0.0173, 0.0172],\n",
      "          [0.0177, 0.0179, 0.0177, 0.0172, 0.0171],\n",
      "          [0.0178, 0.0177, 0.0174, 0.0170, 0.0170]],\n",
      "\n",
      "         [[0.0172, 0.0172, 0.0170, 0.0169, 0.0170],\n",
      "          [0.0172, 0.0173, 0.0172, 0.0169, 0.0169],\n",
      "          [0.0171, 0.0173, 0.0171, 0.0169, 0.0169],\n",
      "          [0.0171, 0.0171, 0.0170, 0.0169, 0.0169],\n",
      "          [0.0170, 0.0170, 0.0169, 0.0168, 0.0168]],\n",
      "\n",
      "         [[0.0174, 0.0176, 0.0176, 0.0174, 0.0173],\n",
      "          [0.0175, 0.0175, 0.0178, 0.0177, 0.0174],\n",
      "          [0.0172, 0.0176, 0.0184, 0.0178, 0.0172],\n",
      "          [0.0173, 0.0184, 0.0183, 0.0173, 0.0169],\n",
      "          [0.0177, 0.0181, 0.0174, 0.0169, 0.0170]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0171, 0.0170, 0.0170, 0.0170, 0.0170],\n",
      "          [0.0170, 0.0170, 0.0171, 0.0171, 0.0169],\n",
      "          [0.0170, 0.0171, 0.0172, 0.0170, 0.0168],\n",
      "          [0.0172, 0.0172, 0.0169, 0.0168, 0.0168],\n",
      "          [0.0171, 0.0169, 0.0168, 0.0169, 0.0169]],\n",
      "\n",
      "         [[0.0169, 0.0170, 0.0170, 0.0170, 0.0169],\n",
      "          [0.0171, 0.0170, 0.0170, 0.0171, 0.0171],\n",
      "          [0.0173, 0.0171, 0.0169, 0.0170, 0.0171],\n",
      "          [0.0171, 0.0171, 0.0171, 0.0171, 0.0170],\n",
      "          [0.0176, 0.0176, 0.0173, 0.0171, 0.0169]],\n",
      "\n",
      "         [[0.0170, 0.0169, 0.0169, 0.0169, 0.0169],\n",
      "          [0.0171, 0.0170, 0.0169, 0.0169, 0.0169],\n",
      "          [0.0172, 0.0171, 0.0169, 0.0168, 0.0169],\n",
      "          [0.0172, 0.0170, 0.0168, 0.0168, 0.0170],\n",
      "          [0.0171, 0.0169, 0.0168, 0.0169, 0.0170]]]]), tensor([0.0172, 0.0189, 0.0186, 0.0172, 0.0174, 0.0172, 0.0167, 0.0171, 0.0180,\n",
      "        0.0193, 0.0175, 0.0170, 0.0173, 0.0171, 0.0171, 0.0174, 0.0177, 0.0175,\n",
      "        0.0174, 0.0171, 0.0167, 0.0177, 0.0167, 0.0175, 0.0180, 0.0174, 0.0177,\n",
      "        0.0182, 0.0179, 0.0177, 0.0170, 0.0179]), tensor([[0.0170, 0.0178, 0.0205,  ..., 0.0206, 0.0323, 0.0273],\n",
      "        [0.0175, 0.0196, 0.0185,  ..., 0.0238, 0.0254, 0.0207],\n",
      "        [0.0174, 0.0210, 0.0260,  ..., 0.0285, 0.0352, 0.0298],\n",
      "        ...,\n",
      "        [0.0174, 0.0194, 0.0211,  ..., 0.0331, 0.0367, 0.0238],\n",
      "        [0.0185, 0.0202, 0.0252,  ..., 0.0271, 0.0493, 0.0540],\n",
      "        [0.0182, 0.0202, 0.0258,  ..., 0.0373, 0.0496, 0.0323]]), tensor([0.0181, 0.0184, 0.0196, 0.0195, 0.0191, 0.0189, 0.0182, 0.0192, 0.0199,\n",
      "        0.0203])]\n"
     ]
    }
   ],
   "source": [
    "print(MNIST_NN_Hessian_diag_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter size:  torch.Size([32, 1, 5, 5])\n",
      "parameter size:  torch.Size([32])\n",
      "parameter size:  torch.Size([32, 32, 5, 5])\n",
      "parameter size:  torch.Size([32])\n",
      "parameter size:  torch.Size([10, 512])\n",
      "parameter size:  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "MNIST_NN_Hessian_diag_120 = get_Hessian_NN(model=mnist_model, train_loader=mnist_train_loader, prec0=120,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0.0090, 0.0091, 0.0090, 0.0089, 0.0088],\n",
      "          [0.0090, 0.0090, 0.0090, 0.0088, 0.0087],\n",
      "          [0.0090, 0.0090, 0.0090, 0.0088, 0.0087],\n",
      "          [0.0091, 0.0091, 0.0090, 0.0088, 0.0088],\n",
      "          [0.0091, 0.0092, 0.0090, 0.0089, 0.0088]]],\n",
      "\n",
      "\n",
      "        [[[0.0088, 0.0089, 0.0090, 0.0089, 0.0087],\n",
      "          [0.0088, 0.0089, 0.0089, 0.0088, 0.0087],\n",
      "          [0.0088, 0.0089, 0.0089, 0.0088, 0.0088],\n",
      "          [0.0088, 0.0088, 0.0088, 0.0089, 0.0089],\n",
      "          [0.0087, 0.0087, 0.0088, 0.0089, 0.0089]]],\n",
      "\n",
      "\n",
      "        [[[0.0098, 0.0104, 0.0113, 0.0120, 0.0116],\n",
      "          [0.0103, 0.0113, 0.0122, 0.0119, 0.0107],\n",
      "          [0.0110, 0.0121, 0.0121, 0.0106, 0.0096],\n",
      "          [0.0119, 0.0125, 0.0111, 0.0095, 0.0091],\n",
      "          [0.0125, 0.0123, 0.0107, 0.0094, 0.0091]]],\n",
      "\n",
      "\n",
      "        [[[0.0086, 0.0086, 0.0089, 0.0093, 0.0096],\n",
      "          [0.0086, 0.0087, 0.0092, 0.0098, 0.0098],\n",
      "          [0.0087, 0.0090, 0.0098, 0.0102, 0.0097],\n",
      "          [0.0090, 0.0097, 0.0105, 0.0103, 0.0094],\n",
      "          [0.0096, 0.0104, 0.0106, 0.0099, 0.0092]]],\n",
      "\n",
      "\n",
      "        [[[0.0110, 0.0114, 0.0106, 0.0093, 0.0089],\n",
      "          [0.0115, 0.0115, 0.0101, 0.0090, 0.0088],\n",
      "          [0.0125, 0.0122, 0.0104, 0.0094, 0.0093],\n",
      "          [0.0134, 0.0132, 0.0115, 0.0104, 0.0102],\n",
      "          [0.0139, 0.0136, 0.0123, 0.0111, 0.0107]]],\n",
      "\n",
      "\n",
      "        [[[0.0092, 0.0090, 0.0090, 0.0093, 0.0094],\n",
      "          [0.0091, 0.0088, 0.0089, 0.0095, 0.0096],\n",
      "          [0.0090, 0.0089, 0.0092, 0.0098, 0.0096],\n",
      "          [0.0093, 0.0094, 0.0100, 0.0100, 0.0095],\n",
      "          [0.0099, 0.0102, 0.0103, 0.0098, 0.0092]]],\n",
      "\n",
      "\n",
      "        [[[0.0089, 0.0089, 0.0090, 0.0090, 0.0090],\n",
      "          [0.0089, 0.0090, 0.0090, 0.0089, 0.0087],\n",
      "          [0.0090, 0.0090, 0.0090, 0.0087, 0.0086],\n",
      "          [0.0088, 0.0090, 0.0091, 0.0088, 0.0086],\n",
      "          [0.0088, 0.0090, 0.0092, 0.0089, 0.0087]]],\n",
      "\n",
      "\n",
      "        [[[0.0086, 0.0087, 0.0088, 0.0088, 0.0087],\n",
      "          [0.0087, 0.0088, 0.0087, 0.0087, 0.0086],\n",
      "          [0.0088, 0.0087, 0.0087, 0.0086, 0.0087],\n",
      "          [0.0087, 0.0087, 0.0087, 0.0087, 0.0088],\n",
      "          [0.0087, 0.0087, 0.0087, 0.0088, 0.0089]]],\n",
      "\n",
      "\n",
      "        [[[0.0116, 0.0115, 0.0120, 0.0130, 0.0136],\n",
      "          [0.0121, 0.0112, 0.0105, 0.0110, 0.0119],\n",
      "          [0.0148, 0.0124, 0.0104, 0.0105, 0.0108],\n",
      "          [0.0172, 0.0153, 0.0125, 0.0117, 0.0110],\n",
      "          [0.0171, 0.0176, 0.0150, 0.0131, 0.0118]]],\n",
      "\n",
      "\n",
      "        [[[0.0096, 0.0099, 0.0100, 0.0098, 0.0095],\n",
      "          [0.0097, 0.0099, 0.0097, 0.0095, 0.0093],\n",
      "          [0.0097, 0.0094, 0.0090, 0.0088, 0.0089],\n",
      "          [0.0095, 0.0090, 0.0087, 0.0087, 0.0088],\n",
      "          [0.0093, 0.0090, 0.0088, 0.0088, 0.0092]]],\n",
      "\n",
      "\n",
      "        [[[0.0088, 0.0087, 0.0087, 0.0089, 0.0090],\n",
      "          [0.0089, 0.0089, 0.0090, 0.0092, 0.0092],\n",
      "          [0.0096, 0.0095, 0.0096, 0.0095, 0.0092],\n",
      "          [0.0102, 0.0099, 0.0098, 0.0096, 0.0093],\n",
      "          [0.0101, 0.0097, 0.0099, 0.0099, 0.0097]]],\n",
      "\n",
      "\n",
      "        [[[0.0111, 0.0115, 0.0120, 0.0118, 0.0113],\n",
      "          [0.0098, 0.0094, 0.0092, 0.0091, 0.0094],\n",
      "          [0.0087, 0.0085, 0.0085, 0.0086, 0.0092],\n",
      "          [0.0086, 0.0085, 0.0086, 0.0091, 0.0108],\n",
      "          [0.0091, 0.0092, 0.0099, 0.0113, 0.0130]]],\n",
      "\n",
      "\n",
      "        [[[0.0094, 0.0093, 0.0090, 0.0089, 0.0091],\n",
      "          [0.0094, 0.0093, 0.0091, 0.0091, 0.0095],\n",
      "          [0.0095, 0.0096, 0.0095, 0.0098, 0.0100],\n",
      "          [0.0094, 0.0098, 0.0101, 0.0101, 0.0098],\n",
      "          [0.0092, 0.0096, 0.0101, 0.0099, 0.0095]]],\n",
      "\n",
      "\n",
      "        [[[0.0089, 0.0086, 0.0085, 0.0085, 0.0088],\n",
      "          [0.0092, 0.0088, 0.0085, 0.0085, 0.0087],\n",
      "          [0.0103, 0.0097, 0.0091, 0.0091, 0.0095],\n",
      "          [0.0119, 0.0120, 0.0115, 0.0114, 0.0120],\n",
      "          [0.0129, 0.0139, 0.0138, 0.0139, 0.0145]]],\n",
      "\n",
      "\n",
      "        [[[0.0095, 0.0094, 0.0094, 0.0094, 0.0093],\n",
      "          [0.0094, 0.0093, 0.0092, 0.0092, 0.0092],\n",
      "          [0.0091, 0.0090, 0.0088, 0.0088, 0.0089],\n",
      "          [0.0090, 0.0088, 0.0086, 0.0085, 0.0087],\n",
      "          [0.0089, 0.0088, 0.0086, 0.0085, 0.0087]]],\n",
      "\n",
      "\n",
      "        [[[0.0090, 0.0092, 0.0094, 0.0094, 0.0091],\n",
      "          [0.0091, 0.0090, 0.0092, 0.0094, 0.0091],\n",
      "          [0.0089, 0.0087, 0.0090, 0.0094, 0.0092],\n",
      "          [0.0087, 0.0086, 0.0089, 0.0093, 0.0094],\n",
      "          [0.0086, 0.0087, 0.0091, 0.0094, 0.0094]]],\n",
      "\n",
      "\n",
      "        [[[0.0090, 0.0087, 0.0087, 0.0095, 0.0113],\n",
      "          [0.0086, 0.0084, 0.0086, 0.0100, 0.0131],\n",
      "          [0.0085, 0.0085, 0.0091, 0.0120, 0.0153],\n",
      "          [0.0087, 0.0090, 0.0108, 0.0147, 0.0164],\n",
      "          [0.0094, 0.0104, 0.0132, 0.0166, 0.0166]]],\n",
      "\n",
      "\n",
      "        [[[0.0090, 0.0089, 0.0088, 0.0087, 0.0087],\n",
      "          [0.0091, 0.0091, 0.0089, 0.0088, 0.0088],\n",
      "          [0.0093, 0.0094, 0.0093, 0.0091, 0.0091],\n",
      "          [0.0093, 0.0095, 0.0096, 0.0095, 0.0093],\n",
      "          [0.0092, 0.0094, 0.0096, 0.0095, 0.0092]]],\n",
      "\n",
      "\n",
      "        [[[0.0086, 0.0085, 0.0085, 0.0086, 0.0087],\n",
      "          [0.0086, 0.0086, 0.0086, 0.0087, 0.0087],\n",
      "          [0.0087, 0.0086, 0.0087, 0.0087, 0.0088],\n",
      "          [0.0088, 0.0088, 0.0088, 0.0089, 0.0089],\n",
      "          [0.0091, 0.0091, 0.0090, 0.0089, 0.0088]]],\n",
      "\n",
      "\n",
      "        [[[0.0091, 0.0089, 0.0088, 0.0092, 0.0095],\n",
      "          [0.0090, 0.0089, 0.0089, 0.0095, 0.0097],\n",
      "          [0.0092, 0.0093, 0.0096, 0.0102, 0.0100],\n",
      "          [0.0096, 0.0100, 0.0104, 0.0103, 0.0096],\n",
      "          [0.0099, 0.0103, 0.0104, 0.0098, 0.0092]]],\n",
      "\n",
      "\n",
      "        [[[0.0087, 0.0086, 0.0086, 0.0088, 0.0091],\n",
      "          [0.0085, 0.0084, 0.0085, 0.0086, 0.0089],\n",
      "          [0.0087, 0.0086, 0.0086, 0.0088, 0.0094],\n",
      "          [0.0094, 0.0095, 0.0096, 0.0102, 0.0107],\n",
      "          [0.0101, 0.0107, 0.0110, 0.0115, 0.0117]]],\n",
      "\n",
      "\n",
      "        [[[0.0089, 0.0089, 0.0090, 0.0092, 0.0094],\n",
      "          [0.0088, 0.0087, 0.0088, 0.0093, 0.0095],\n",
      "          [0.0086, 0.0086, 0.0088, 0.0093, 0.0094],\n",
      "          [0.0087, 0.0088, 0.0091, 0.0095, 0.0093],\n",
      "          [0.0088, 0.0091, 0.0094, 0.0095, 0.0091]]],\n",
      "\n",
      "\n",
      "        [[[0.0160, 0.0211, 0.0246, 0.0261, 0.0238],\n",
      "          [0.0195, 0.0247, 0.0251, 0.0237, 0.0217],\n",
      "          [0.0212, 0.0216, 0.0180, 0.0163, 0.0167],\n",
      "          [0.0173, 0.0140, 0.0123, 0.0130, 0.0146],\n",
      "          [0.0134, 0.0113, 0.0112, 0.0132, 0.0163]]],\n",
      "\n",
      "\n",
      "        [[[0.0090, 0.0092, 0.0096, 0.0096, 0.0095],\n",
      "          [0.0092, 0.0093, 0.0098, 0.0101, 0.0098],\n",
      "          [0.0094, 0.0094, 0.0096, 0.0099, 0.0098],\n",
      "          [0.0093, 0.0092, 0.0091, 0.0094, 0.0096],\n",
      "          [0.0089, 0.0088, 0.0089, 0.0094, 0.0096]]],\n",
      "\n",
      "\n",
      "        [[[0.0086, 0.0088, 0.0093, 0.0109, 0.0124],\n",
      "          [0.0085, 0.0085, 0.0092, 0.0117, 0.0138],\n",
      "          [0.0085, 0.0086, 0.0094, 0.0127, 0.0145],\n",
      "          [0.0086, 0.0089, 0.0101, 0.0132, 0.0146],\n",
      "          [0.0089, 0.0094, 0.0110, 0.0133, 0.0138]]],\n",
      "\n",
      "\n",
      "        [[[0.0087, 0.0090, 0.0101, 0.0116, 0.0121],\n",
      "          [0.0086, 0.0089, 0.0109, 0.0136, 0.0131],\n",
      "          [0.0086, 0.0093, 0.0126, 0.0150, 0.0132],\n",
      "          [0.0090, 0.0108, 0.0153, 0.0159, 0.0126],\n",
      "          [0.0102, 0.0131, 0.0160, 0.0148, 0.0118]]],\n",
      "\n",
      "\n",
      "        [[[0.0094, 0.0091, 0.0091, 0.0093, 0.0094],\n",
      "          [0.0090, 0.0088, 0.0088, 0.0092, 0.0096],\n",
      "          [0.0087, 0.0087, 0.0089, 0.0095, 0.0096],\n",
      "          [0.0089, 0.0092, 0.0096, 0.0098, 0.0093],\n",
      "          [0.0094, 0.0098, 0.0099, 0.0095, 0.0090]]],\n",
      "\n",
      "\n",
      "        [[[0.0101, 0.0100, 0.0094, 0.0091, 0.0092],\n",
      "          [0.0101, 0.0097, 0.0091, 0.0091, 0.0093],\n",
      "          [0.0099, 0.0096, 0.0093, 0.0094, 0.0097],\n",
      "          [0.0098, 0.0099, 0.0100, 0.0101, 0.0100],\n",
      "          [0.0096, 0.0100, 0.0103, 0.0101, 0.0100]]],\n",
      "\n",
      "\n",
      "        [[[0.0091, 0.0091, 0.0088, 0.0086, 0.0086],\n",
      "          [0.0091, 0.0091, 0.0087, 0.0085, 0.0087],\n",
      "          [0.0092, 0.0091, 0.0088, 0.0087, 0.0089],\n",
      "          [0.0092, 0.0093, 0.0090, 0.0090, 0.0090],\n",
      "          [0.0090, 0.0092, 0.0093, 0.0092, 0.0090]]],\n",
      "\n",
      "\n",
      "        [[[0.0104, 0.0097, 0.0091, 0.0094, 0.0104],\n",
      "          [0.0103, 0.0094, 0.0092, 0.0102, 0.0113],\n",
      "          [0.0105, 0.0099, 0.0104, 0.0117, 0.0117],\n",
      "          [0.0108, 0.0110, 0.0116, 0.0117, 0.0108],\n",
      "          [0.0106, 0.0112, 0.0111, 0.0106, 0.0102]]],\n",
      "\n",
      "\n",
      "        [[[0.0133, 0.0137, 0.0142, 0.0149, 0.0155],\n",
      "          [0.0121, 0.0121, 0.0122, 0.0122, 0.0131],\n",
      "          [0.0107, 0.0103, 0.0097, 0.0098, 0.0111],\n",
      "          [0.0105, 0.0096, 0.0090, 0.0094, 0.0107],\n",
      "          [0.0114, 0.0101, 0.0094, 0.0098, 0.0111]]],\n",
      "\n",
      "\n",
      "        [[[0.0089, 0.0091, 0.0098, 0.0111, 0.0119],\n",
      "          [0.0089, 0.0090, 0.0099, 0.0116, 0.0124],\n",
      "          [0.0087, 0.0090, 0.0100, 0.0120, 0.0133],\n",
      "          [0.0087, 0.0091, 0.0104, 0.0125, 0.0137],\n",
      "          [0.0088, 0.0094, 0.0110, 0.0129, 0.0134]]]]), tensor([0.0099, 0.0093, 0.0165, 0.0122, 0.0207, 0.0117, 0.0105, 0.0093, 0.0314,\n",
      "        0.0123, 0.0136, 0.0362, 0.0111, 0.0380, 0.0095, 0.0111, 0.0254, 0.0109,\n",
      "        0.0096, 0.0124, 0.0210, 0.0102, 0.0507, 0.0117, 0.0194, 0.0241, 0.0124,\n",
      "        0.0107, 0.0097, 0.0163, 0.0290, 0.0190]), tensor([[[[0.0085, 0.0086, 0.0086, 0.0086, 0.0086],\n",
      "          [0.0085, 0.0086, 0.0087, 0.0087, 0.0086],\n",
      "          [0.0085, 0.0086, 0.0087, 0.0089, 0.0087],\n",
      "          [0.0085, 0.0086, 0.0087, 0.0089, 0.0089],\n",
      "          [0.0086, 0.0086, 0.0086, 0.0087, 0.0088]],\n",
      "\n",
      "         [[0.0084, 0.0085, 0.0086, 0.0085, 0.0085],\n",
      "          [0.0084, 0.0085, 0.0086, 0.0086, 0.0085],\n",
      "          [0.0084, 0.0084, 0.0085, 0.0086, 0.0086],\n",
      "          [0.0084, 0.0084, 0.0084, 0.0086, 0.0086],\n",
      "          [0.0084, 0.0084, 0.0084, 0.0084, 0.0085]],\n",
      "\n",
      "         [[0.0084, 0.0084, 0.0086, 0.0087, 0.0087],\n",
      "          [0.0084, 0.0085, 0.0085, 0.0087, 0.0088],\n",
      "          [0.0085, 0.0086, 0.0085, 0.0086, 0.0087],\n",
      "          [0.0085, 0.0085, 0.0085, 0.0086, 0.0087],\n",
      "          [0.0084, 0.0085, 0.0086, 0.0086, 0.0086]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0084, 0.0084, 0.0085, 0.0085, 0.0085],\n",
      "          [0.0084, 0.0084, 0.0085, 0.0085, 0.0085],\n",
      "          [0.0084, 0.0084, 0.0084, 0.0085, 0.0085],\n",
      "          [0.0084, 0.0084, 0.0085, 0.0084, 0.0085],\n",
      "          [0.0084, 0.0084, 0.0084, 0.0084, 0.0084]],\n",
      "\n",
      "         [[0.0085, 0.0085, 0.0084, 0.0084, 0.0085],\n",
      "          [0.0085, 0.0086, 0.0085, 0.0084, 0.0084],\n",
      "          [0.0084, 0.0086, 0.0086, 0.0084, 0.0084],\n",
      "          [0.0084, 0.0085, 0.0087, 0.0086, 0.0084],\n",
      "          [0.0086, 0.0085, 0.0087, 0.0088, 0.0087]],\n",
      "\n",
      "         [[0.0085, 0.0085, 0.0085, 0.0084, 0.0084],\n",
      "          [0.0085, 0.0086, 0.0086, 0.0085, 0.0084],\n",
      "          [0.0084, 0.0085, 0.0086, 0.0085, 0.0084],\n",
      "          [0.0085, 0.0085, 0.0086, 0.0086, 0.0084],\n",
      "          [0.0085, 0.0084, 0.0085, 0.0085, 0.0084]]],\n",
      "\n",
      "\n",
      "        [[[0.0089, 0.0088, 0.0086, 0.0086, 0.0086],\n",
      "          [0.0089, 0.0087, 0.0085, 0.0086, 0.0088],\n",
      "          [0.0089, 0.0086, 0.0086, 0.0090, 0.0093],\n",
      "          [0.0090, 0.0089, 0.0090, 0.0096, 0.0097],\n",
      "          [0.0091, 0.0092, 0.0094, 0.0098, 0.0097]],\n",
      "\n",
      "         [[0.0086, 0.0085, 0.0084, 0.0085, 0.0086],\n",
      "          [0.0086, 0.0085, 0.0085, 0.0087, 0.0087],\n",
      "          [0.0087, 0.0086, 0.0087, 0.0089, 0.0089],\n",
      "          [0.0088, 0.0088, 0.0088, 0.0090, 0.0089],\n",
      "          [0.0088, 0.0088, 0.0088, 0.0089, 0.0088]],\n",
      "\n",
      "         [[0.0095, 0.0093, 0.0085, 0.0084, 0.0087],\n",
      "          [0.0095, 0.0088, 0.0084, 0.0085, 0.0092],\n",
      "          [0.0091, 0.0086, 0.0085, 0.0091, 0.0102],\n",
      "          [0.0088, 0.0087, 0.0090, 0.0100, 0.0102],\n",
      "          [0.0088, 0.0090, 0.0095, 0.0099, 0.0094]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0086, 0.0085, 0.0084, 0.0084, 0.0085],\n",
      "          [0.0085, 0.0085, 0.0085, 0.0086, 0.0089],\n",
      "          [0.0085, 0.0086, 0.0088, 0.0091, 0.0090],\n",
      "          [0.0086, 0.0089, 0.0091, 0.0089, 0.0087],\n",
      "          [0.0087, 0.0089, 0.0088, 0.0086, 0.0087]],\n",
      "\n",
      "         [[0.0085, 0.0086, 0.0087, 0.0086, 0.0086],\n",
      "          [0.0085, 0.0086, 0.0085, 0.0085, 0.0084],\n",
      "          [0.0085, 0.0085, 0.0085, 0.0084, 0.0085],\n",
      "          [0.0086, 0.0086, 0.0086, 0.0086, 0.0086],\n",
      "          [0.0089, 0.0089, 0.0091, 0.0090, 0.0088]],\n",
      "\n",
      "         [[0.0085, 0.0084, 0.0085, 0.0086, 0.0086],\n",
      "          [0.0084, 0.0084, 0.0087, 0.0089, 0.0086],\n",
      "          [0.0084, 0.0085, 0.0090, 0.0090, 0.0085],\n",
      "          [0.0086, 0.0087, 0.0091, 0.0089, 0.0085],\n",
      "          [0.0087, 0.0088, 0.0090, 0.0088, 0.0085]]],\n",
      "\n",
      "\n",
      "        [[[0.0089, 0.0090, 0.0088, 0.0088, 0.0088],\n",
      "          [0.0090, 0.0089, 0.0086, 0.0086, 0.0088],\n",
      "          [0.0091, 0.0089, 0.0086, 0.0086, 0.0090],\n",
      "          [0.0092, 0.0091, 0.0088, 0.0087, 0.0091],\n",
      "          [0.0090, 0.0091, 0.0088, 0.0087, 0.0090]],\n",
      "\n",
      "         [[0.0087, 0.0086, 0.0085, 0.0085, 0.0086],\n",
      "          [0.0087, 0.0086, 0.0084, 0.0085, 0.0087],\n",
      "          [0.0088, 0.0087, 0.0085, 0.0085, 0.0088],\n",
      "          [0.0088, 0.0088, 0.0086, 0.0085, 0.0087],\n",
      "          [0.0086, 0.0087, 0.0086, 0.0085, 0.0086]],\n",
      "\n",
      "         [[0.0091, 0.0094, 0.0088, 0.0085, 0.0086],\n",
      "          [0.0092, 0.0092, 0.0086, 0.0084, 0.0086],\n",
      "          [0.0091, 0.0090, 0.0086, 0.0085, 0.0087],\n",
      "          [0.0090, 0.0090, 0.0087, 0.0085, 0.0088],\n",
      "          [0.0089, 0.0089, 0.0087, 0.0085, 0.0089]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0086, 0.0086, 0.0085, 0.0084, 0.0085],\n",
      "          [0.0085, 0.0085, 0.0085, 0.0085, 0.0085],\n",
      "          [0.0085, 0.0086, 0.0087, 0.0086, 0.0086],\n",
      "          [0.0086, 0.0087, 0.0086, 0.0086, 0.0085],\n",
      "          [0.0085, 0.0085, 0.0085, 0.0086, 0.0085]],\n",
      "\n",
      "         [[0.0086, 0.0088, 0.0090, 0.0089, 0.0087],\n",
      "          [0.0086, 0.0087, 0.0088, 0.0088, 0.0085],\n",
      "          [0.0085, 0.0085, 0.0086, 0.0088, 0.0086],\n",
      "          [0.0087, 0.0086, 0.0087, 0.0090, 0.0089],\n",
      "          [0.0090, 0.0090, 0.0089, 0.0090, 0.0090]],\n",
      "\n",
      "         [[0.0086, 0.0084, 0.0084, 0.0086, 0.0086],\n",
      "          [0.0086, 0.0084, 0.0084, 0.0087, 0.0088],\n",
      "          [0.0087, 0.0084, 0.0084, 0.0088, 0.0089],\n",
      "          [0.0087, 0.0084, 0.0084, 0.0087, 0.0090],\n",
      "          [0.0087, 0.0085, 0.0084, 0.0087, 0.0088]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0089, 0.0090, 0.0090, 0.0088, 0.0087],\n",
      "          [0.0088, 0.0090, 0.0090, 0.0088, 0.0087],\n",
      "          [0.0090, 0.0092, 0.0090, 0.0088, 0.0087],\n",
      "          [0.0093, 0.0095, 0.0092, 0.0089, 0.0088],\n",
      "          [0.0092, 0.0093, 0.0092, 0.0089, 0.0087]],\n",
      "\n",
      "         [[0.0085, 0.0087, 0.0087, 0.0086, 0.0085],\n",
      "          [0.0086, 0.0087, 0.0086, 0.0085, 0.0085],\n",
      "          [0.0088, 0.0089, 0.0087, 0.0086, 0.0085],\n",
      "          [0.0088, 0.0089, 0.0088, 0.0086, 0.0085],\n",
      "          [0.0086, 0.0086, 0.0086, 0.0086, 0.0085]],\n",
      "\n",
      "         [[0.0088, 0.0092, 0.0094, 0.0089, 0.0087],\n",
      "          [0.0089, 0.0095, 0.0094, 0.0088, 0.0088],\n",
      "          [0.0090, 0.0095, 0.0092, 0.0090, 0.0090],\n",
      "          [0.0093, 0.0093, 0.0092, 0.0092, 0.0089],\n",
      "          [0.0092, 0.0091, 0.0091, 0.0090, 0.0086]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0086, 0.0086, 0.0086, 0.0085, 0.0085],\n",
      "          [0.0087, 0.0086, 0.0085, 0.0085, 0.0085],\n",
      "          [0.0088, 0.0086, 0.0087, 0.0087, 0.0086],\n",
      "          [0.0087, 0.0087, 0.0088, 0.0086, 0.0085],\n",
      "          [0.0085, 0.0085, 0.0085, 0.0085, 0.0085]],\n",
      "\n",
      "         [[0.0088, 0.0086, 0.0085, 0.0085, 0.0085],\n",
      "          [0.0087, 0.0086, 0.0086, 0.0086, 0.0085],\n",
      "          [0.0085, 0.0084, 0.0084, 0.0084, 0.0084],\n",
      "          [0.0088, 0.0086, 0.0085, 0.0085, 0.0085],\n",
      "          [0.0092, 0.0091, 0.0089, 0.0088, 0.0086]],\n",
      "\n",
      "         [[0.0088, 0.0087, 0.0085, 0.0085, 0.0084],\n",
      "          [0.0088, 0.0087, 0.0085, 0.0085, 0.0085],\n",
      "          [0.0088, 0.0086, 0.0085, 0.0085, 0.0084],\n",
      "          [0.0088, 0.0086, 0.0085, 0.0085, 0.0084],\n",
      "          [0.0087, 0.0087, 0.0086, 0.0085, 0.0084]]],\n",
      "\n",
      "\n",
      "        [[[0.0084, 0.0084, 0.0084, 0.0084, 0.0084],\n",
      "          [0.0084, 0.0085, 0.0085, 0.0086, 0.0086],\n",
      "          [0.0085, 0.0085, 0.0086, 0.0086, 0.0086],\n",
      "          [0.0084, 0.0085, 0.0085, 0.0085, 0.0085],\n",
      "          [0.0084, 0.0085, 0.0085, 0.0085, 0.0085]],\n",
      "\n",
      "         [[0.0084, 0.0084, 0.0084, 0.0085, 0.0085],\n",
      "          [0.0084, 0.0084, 0.0085, 0.0085, 0.0085],\n",
      "          [0.0084, 0.0084, 0.0084, 0.0084, 0.0085],\n",
      "          [0.0084, 0.0084, 0.0084, 0.0084, 0.0084],\n",
      "          [0.0084, 0.0084, 0.0085, 0.0084, 0.0084]],\n",
      "\n",
      "         [[0.0084, 0.0084, 0.0084, 0.0084, 0.0085],\n",
      "          [0.0084, 0.0084, 0.0085, 0.0086, 0.0086],\n",
      "          [0.0085, 0.0085, 0.0087, 0.0087, 0.0086],\n",
      "          [0.0085, 0.0085, 0.0086, 0.0086, 0.0085],\n",
      "          [0.0084, 0.0084, 0.0085, 0.0086, 0.0086]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0084, 0.0084, 0.0084, 0.0085, 0.0085],\n",
      "          [0.0084, 0.0085, 0.0085, 0.0086, 0.0085],\n",
      "          [0.0084, 0.0084, 0.0085, 0.0084, 0.0084],\n",
      "          [0.0084, 0.0084, 0.0084, 0.0084, 0.0084],\n",
      "          [0.0084, 0.0084, 0.0084, 0.0085, 0.0084]],\n",
      "\n",
      "         [[0.0084, 0.0084, 0.0084, 0.0084, 0.0084],\n",
      "          [0.0084, 0.0084, 0.0084, 0.0084, 0.0084],\n",
      "          [0.0085, 0.0086, 0.0087, 0.0087, 0.0086],\n",
      "          [0.0085, 0.0085, 0.0085, 0.0086, 0.0085],\n",
      "          [0.0084, 0.0084, 0.0084, 0.0084, 0.0084]],\n",
      "\n",
      "         [[0.0084, 0.0084, 0.0084, 0.0084, 0.0084],\n",
      "          [0.0084, 0.0084, 0.0084, 0.0084, 0.0084],\n",
      "          [0.0084, 0.0085, 0.0085, 0.0084, 0.0084],\n",
      "          [0.0084, 0.0085, 0.0084, 0.0084, 0.0084],\n",
      "          [0.0084, 0.0085, 0.0084, 0.0084, 0.0084]]],\n",
      "\n",
      "\n",
      "        [[[0.0091, 0.0092, 0.0090, 0.0088, 0.0088],\n",
      "          [0.0094, 0.0094, 0.0091, 0.0088, 0.0089],\n",
      "          [0.0094, 0.0095, 0.0093, 0.0089, 0.0089],\n",
      "          [0.0094, 0.0095, 0.0093, 0.0089, 0.0088],\n",
      "          [0.0094, 0.0094, 0.0091, 0.0087, 0.0087]],\n",
      "\n",
      "         [[0.0089, 0.0088, 0.0087, 0.0086, 0.0086],\n",
      "          [0.0089, 0.0090, 0.0088, 0.0086, 0.0086],\n",
      "          [0.0088, 0.0089, 0.0088, 0.0086, 0.0085],\n",
      "          [0.0088, 0.0088, 0.0087, 0.0085, 0.0085],\n",
      "          [0.0087, 0.0087, 0.0086, 0.0085, 0.0085]],\n",
      "\n",
      "         [[0.0091, 0.0093, 0.0093, 0.0090, 0.0089],\n",
      "          [0.0091, 0.0091, 0.0095, 0.0093, 0.0091],\n",
      "          [0.0089, 0.0093, 0.0101, 0.0095, 0.0089],\n",
      "          [0.0090, 0.0101, 0.0099, 0.0090, 0.0086],\n",
      "          [0.0093, 0.0098, 0.0091, 0.0086, 0.0087]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0088, 0.0087, 0.0086, 0.0086, 0.0086],\n",
      "          [0.0087, 0.0087, 0.0088, 0.0087, 0.0086],\n",
      "          [0.0086, 0.0088, 0.0089, 0.0087, 0.0085],\n",
      "          [0.0089, 0.0088, 0.0086, 0.0085, 0.0085],\n",
      "          [0.0088, 0.0085, 0.0085, 0.0085, 0.0085]],\n",
      "\n",
      "         [[0.0086, 0.0087, 0.0087, 0.0086, 0.0085],\n",
      "          [0.0087, 0.0087, 0.0087, 0.0088, 0.0087],\n",
      "          [0.0090, 0.0087, 0.0086, 0.0087, 0.0088],\n",
      "          [0.0088, 0.0088, 0.0088, 0.0087, 0.0087],\n",
      "          [0.0093, 0.0092, 0.0090, 0.0088, 0.0086]],\n",
      "\n",
      "         [[0.0087, 0.0086, 0.0086, 0.0086, 0.0086],\n",
      "          [0.0087, 0.0087, 0.0086, 0.0085, 0.0086],\n",
      "          [0.0089, 0.0088, 0.0085, 0.0084, 0.0086],\n",
      "          [0.0089, 0.0087, 0.0085, 0.0085, 0.0086],\n",
      "          [0.0087, 0.0086, 0.0084, 0.0085, 0.0086]]]]), tensor([0.0089, 0.0106, 0.0102, 0.0089, 0.0091, 0.0088, 0.0083, 0.0088, 0.0097,\n",
      "        0.0110, 0.0092, 0.0086, 0.0090, 0.0088, 0.0088, 0.0091, 0.0094, 0.0091,\n",
      "        0.0091, 0.0088, 0.0083, 0.0094, 0.0083, 0.0091, 0.0096, 0.0090, 0.0093,\n",
      "        0.0099, 0.0095, 0.0094, 0.0087, 0.0096]), tensor([[0.0086, 0.0095, 0.0122,  ..., 0.0122, 0.0239, 0.0190],\n",
      "        [0.0091, 0.0113, 0.0102,  ..., 0.0155, 0.0171, 0.0124],\n",
      "        [0.0091, 0.0127, 0.0176,  ..., 0.0202, 0.0269, 0.0215],\n",
      "        ...,\n",
      "        [0.0090, 0.0111, 0.0127,  ..., 0.0248, 0.0284, 0.0154],\n",
      "        [0.0101, 0.0119, 0.0169,  ..., 0.0187, 0.0410, 0.0457],\n",
      "        [0.0098, 0.0119, 0.0175,  ..., 0.0290, 0.0412, 0.0239]]), tensor([0.0098, 0.0101, 0.0112, 0.0111, 0.0108, 0.0105, 0.0098, 0.0109, 0.0115,\n",
      "        0.0119])]\n"
     ]
    }
   ],
   "source": [
    "print(MNIST_NN_Hessian_diag_120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter size:  torch.Size([32, 1, 5, 5])\n",
      "parameter size:  torch.Size([32])\n",
      "parameter size:  torch.Size([32, 32, 5, 5])\n",
      "parameter size:  torch.Size([32])\n",
      "parameter size:  torch.Size([10, 512])\n",
      "parameter size:  torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "MNIST_NN_Hessian_diag_1000 = get_Hessian_NN(model=mnist_model, train_loader=mnist_train_loader, prec0=1000,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0.0017, 0.0017, 0.0017, 0.0016, 0.0014],\n",
      "          [0.0017, 0.0017, 0.0017, 0.0015, 0.0014],\n",
      "          [0.0017, 0.0017, 0.0017, 0.0014, 0.0014],\n",
      "          [0.0017, 0.0018, 0.0017, 0.0015, 0.0014],\n",
      "          [0.0018, 0.0018, 0.0017, 0.0015, 0.0014]]],\n",
      "\n",
      "\n",
      "        [[[0.0015, 0.0016, 0.0017, 0.0016, 0.0014],\n",
      "          [0.0015, 0.0015, 0.0016, 0.0015, 0.0014],\n",
      "          [0.0015, 0.0015, 0.0016, 0.0015, 0.0015],\n",
      "          [0.0014, 0.0014, 0.0015, 0.0015, 0.0016],\n",
      "          [0.0013, 0.0014, 0.0015, 0.0016, 0.0016]]],\n",
      "\n",
      "\n",
      "        [[[0.0025, 0.0031, 0.0039, 0.0047, 0.0043],\n",
      "          [0.0030, 0.0040, 0.0049, 0.0045, 0.0034],\n",
      "          [0.0036, 0.0048, 0.0048, 0.0033, 0.0023],\n",
      "          [0.0045, 0.0051, 0.0038, 0.0022, 0.0017],\n",
      "          [0.0051, 0.0050, 0.0034, 0.0020, 0.0017]]],\n",
      "\n",
      "\n",
      "        [[[0.0013, 0.0013, 0.0015, 0.0020, 0.0023],\n",
      "          [0.0012, 0.0014, 0.0019, 0.0025, 0.0025],\n",
      "          [0.0014, 0.0017, 0.0025, 0.0029, 0.0024],\n",
      "          [0.0017, 0.0024, 0.0032, 0.0030, 0.0021],\n",
      "          [0.0022, 0.0031, 0.0032, 0.0026, 0.0019]]],\n",
      "\n",
      "\n",
      "        [[[0.0037, 0.0041, 0.0033, 0.0020, 0.0015],\n",
      "          [0.0042, 0.0042, 0.0028, 0.0017, 0.0014],\n",
      "          [0.0052, 0.0049, 0.0031, 0.0021, 0.0020],\n",
      "          [0.0061, 0.0059, 0.0041, 0.0031, 0.0028],\n",
      "          [0.0065, 0.0063, 0.0050, 0.0038, 0.0034]]],\n",
      "\n",
      "\n",
      "        [[[0.0018, 0.0017, 0.0016, 0.0020, 0.0021],\n",
      "          [0.0017, 0.0015, 0.0016, 0.0021, 0.0023],\n",
      "          [0.0017, 0.0015, 0.0019, 0.0025, 0.0023],\n",
      "          [0.0020, 0.0021, 0.0026, 0.0027, 0.0021],\n",
      "          [0.0025, 0.0028, 0.0030, 0.0025, 0.0019]]],\n",
      "\n",
      "\n",
      "        [[[0.0015, 0.0016, 0.0017, 0.0016, 0.0017],\n",
      "          [0.0015, 0.0017, 0.0017, 0.0015, 0.0014],\n",
      "          [0.0016, 0.0017, 0.0016, 0.0014, 0.0013],\n",
      "          [0.0015, 0.0017, 0.0018, 0.0014, 0.0013],\n",
      "          [0.0015, 0.0017, 0.0019, 0.0016, 0.0014]]],\n",
      "\n",
      "\n",
      "        [[[0.0013, 0.0014, 0.0015, 0.0014, 0.0013],\n",
      "          [0.0014, 0.0014, 0.0014, 0.0013, 0.0013],\n",
      "          [0.0014, 0.0014, 0.0013, 0.0013, 0.0013],\n",
      "          [0.0014, 0.0013, 0.0014, 0.0014, 0.0014],\n",
      "          [0.0013, 0.0013, 0.0014, 0.0015, 0.0015]]],\n",
      "\n",
      "\n",
      "        [[[0.0043, 0.0041, 0.0046, 0.0056, 0.0062],\n",
      "          [0.0048, 0.0039, 0.0032, 0.0037, 0.0045],\n",
      "          [0.0075, 0.0051, 0.0031, 0.0032, 0.0034],\n",
      "          [0.0099, 0.0080, 0.0052, 0.0044, 0.0037],\n",
      "          [0.0098, 0.0103, 0.0077, 0.0058, 0.0045]]],\n",
      "\n",
      "\n",
      "        [[[0.0023, 0.0025, 0.0026, 0.0025, 0.0022],\n",
      "          [0.0024, 0.0026, 0.0024, 0.0022, 0.0020],\n",
      "          [0.0024, 0.0021, 0.0016, 0.0015, 0.0015],\n",
      "          [0.0021, 0.0017, 0.0014, 0.0013, 0.0015],\n",
      "          [0.0020, 0.0016, 0.0014, 0.0015, 0.0019]]],\n",
      "\n",
      "\n",
      "        [[[0.0014, 0.0014, 0.0014, 0.0015, 0.0016],\n",
      "          [0.0016, 0.0016, 0.0017, 0.0019, 0.0019],\n",
      "          [0.0023, 0.0022, 0.0023, 0.0021, 0.0019],\n",
      "          [0.0029, 0.0026, 0.0025, 0.0022, 0.0019],\n",
      "          [0.0028, 0.0024, 0.0026, 0.0026, 0.0023]]],\n",
      "\n",
      "\n",
      "        [[[0.0038, 0.0041, 0.0047, 0.0044, 0.0040],\n",
      "          [0.0024, 0.0021, 0.0019, 0.0017, 0.0021],\n",
      "          [0.0014, 0.0012, 0.0012, 0.0012, 0.0018],\n",
      "          [0.0012, 0.0012, 0.0013, 0.0017, 0.0035],\n",
      "          [0.0018, 0.0019, 0.0026, 0.0040, 0.0057]]],\n",
      "\n",
      "\n",
      "        [[[0.0020, 0.0019, 0.0017, 0.0016, 0.0018],\n",
      "          [0.0021, 0.0019, 0.0017, 0.0018, 0.0022],\n",
      "          [0.0022, 0.0023, 0.0022, 0.0025, 0.0026],\n",
      "          [0.0021, 0.0025, 0.0027, 0.0028, 0.0025],\n",
      "          [0.0019, 0.0023, 0.0027, 0.0026, 0.0021]]],\n",
      "\n",
      "\n",
      "        [[[0.0016, 0.0013, 0.0012, 0.0012, 0.0014],\n",
      "          [0.0019, 0.0014, 0.0012, 0.0012, 0.0014],\n",
      "          [0.0029, 0.0023, 0.0018, 0.0017, 0.0022],\n",
      "          [0.0046, 0.0046, 0.0041, 0.0041, 0.0047],\n",
      "          [0.0056, 0.0066, 0.0065, 0.0065, 0.0072]]],\n",
      "\n",
      "\n",
      "        [[[0.0021, 0.0021, 0.0020, 0.0020, 0.0020],\n",
      "          [0.0021, 0.0020, 0.0018, 0.0018, 0.0019],\n",
      "          [0.0018, 0.0017, 0.0015, 0.0014, 0.0016],\n",
      "          [0.0017, 0.0015, 0.0013, 0.0012, 0.0013],\n",
      "          [0.0016, 0.0014, 0.0012, 0.0012, 0.0013]]],\n",
      "\n",
      "\n",
      "        [[[0.0017, 0.0019, 0.0021, 0.0021, 0.0018],\n",
      "          [0.0018, 0.0017, 0.0019, 0.0021, 0.0018],\n",
      "          [0.0016, 0.0014, 0.0016, 0.0020, 0.0019],\n",
      "          [0.0013, 0.0013, 0.0016, 0.0020, 0.0020],\n",
      "          [0.0013, 0.0014, 0.0017, 0.0020, 0.0020]]],\n",
      "\n",
      "\n",
      "        [[[0.0016, 0.0013, 0.0014, 0.0022, 0.0040],\n",
      "          [0.0013, 0.0011, 0.0013, 0.0027, 0.0058],\n",
      "          [0.0011, 0.0011, 0.0018, 0.0047, 0.0080],\n",
      "          [0.0013, 0.0016, 0.0034, 0.0073, 0.0091],\n",
      "          [0.0020, 0.0031, 0.0059, 0.0092, 0.0092]]],\n",
      "\n",
      "\n",
      "        [[[0.0017, 0.0016, 0.0014, 0.0014, 0.0014],\n",
      "          [0.0018, 0.0018, 0.0015, 0.0015, 0.0015],\n",
      "          [0.0020, 0.0021, 0.0019, 0.0018, 0.0018],\n",
      "          [0.0020, 0.0022, 0.0022, 0.0022, 0.0020],\n",
      "          [0.0019, 0.0020, 0.0023, 0.0022, 0.0019]]],\n",
      "\n",
      "\n",
      "        [[[0.0013, 0.0012, 0.0012, 0.0013, 0.0014],\n",
      "          [0.0013, 0.0012, 0.0013, 0.0014, 0.0014],\n",
      "          [0.0013, 0.0013, 0.0014, 0.0014, 0.0015],\n",
      "          [0.0014, 0.0014, 0.0015, 0.0016, 0.0016],\n",
      "          [0.0017, 0.0017, 0.0017, 0.0016, 0.0015]]],\n",
      "\n",
      "\n",
      "        [[[0.0018, 0.0015, 0.0015, 0.0018, 0.0021],\n",
      "          [0.0017, 0.0015, 0.0016, 0.0022, 0.0024],\n",
      "          [0.0019, 0.0019, 0.0023, 0.0029, 0.0026],\n",
      "          [0.0023, 0.0027, 0.0031, 0.0030, 0.0023],\n",
      "          [0.0026, 0.0030, 0.0030, 0.0024, 0.0019]]],\n",
      "\n",
      "\n",
      "        [[[0.0013, 0.0013, 0.0013, 0.0014, 0.0018],\n",
      "          [0.0012, 0.0011, 0.0011, 0.0012, 0.0016],\n",
      "          [0.0014, 0.0013, 0.0013, 0.0015, 0.0021],\n",
      "          [0.0021, 0.0022, 0.0023, 0.0029, 0.0034],\n",
      "          [0.0028, 0.0033, 0.0036, 0.0042, 0.0044]]],\n",
      "\n",
      "\n",
      "        [[[0.0016, 0.0016, 0.0017, 0.0019, 0.0021],\n",
      "          [0.0014, 0.0014, 0.0015, 0.0019, 0.0022],\n",
      "          [0.0013, 0.0013, 0.0015, 0.0020, 0.0021],\n",
      "          [0.0013, 0.0014, 0.0018, 0.0021, 0.0020],\n",
      "          [0.0015, 0.0017, 0.0020, 0.0021, 0.0018]]],\n",
      "\n",
      "\n",
      "        [[[0.0087, 0.0138, 0.0173, 0.0188, 0.0165],\n",
      "          [0.0122, 0.0174, 0.0178, 0.0164, 0.0144],\n",
      "          [0.0139, 0.0143, 0.0107, 0.0090, 0.0094],\n",
      "          [0.0099, 0.0067, 0.0050, 0.0056, 0.0073],\n",
      "          [0.0061, 0.0039, 0.0039, 0.0058, 0.0089]]],\n",
      "\n",
      "\n",
      "        [[[0.0017, 0.0018, 0.0022, 0.0023, 0.0021],\n",
      "          [0.0018, 0.0020, 0.0024, 0.0028, 0.0025],\n",
      "          [0.0020, 0.0021, 0.0023, 0.0025, 0.0025],\n",
      "          [0.0019, 0.0018, 0.0017, 0.0021, 0.0023],\n",
      "          [0.0016, 0.0015, 0.0016, 0.0021, 0.0022]]],\n",
      "\n",
      "\n",
      "        [[[0.0013, 0.0014, 0.0020, 0.0036, 0.0051],\n",
      "          [0.0011, 0.0012, 0.0019, 0.0044, 0.0065],\n",
      "          [0.0012, 0.0013, 0.0021, 0.0054, 0.0071],\n",
      "          [0.0013, 0.0016, 0.0028, 0.0059, 0.0073],\n",
      "          [0.0016, 0.0021, 0.0036, 0.0060, 0.0064]]],\n",
      "\n",
      "\n",
      "        [[[0.0013, 0.0016, 0.0028, 0.0043, 0.0048],\n",
      "          [0.0012, 0.0016, 0.0036, 0.0063, 0.0058],\n",
      "          [0.0013, 0.0020, 0.0053, 0.0077, 0.0059],\n",
      "          [0.0017, 0.0034, 0.0079, 0.0086, 0.0052],\n",
      "          [0.0029, 0.0058, 0.0087, 0.0075, 0.0045]]],\n",
      "\n",
      "\n",
      "        [[[0.0021, 0.0018, 0.0018, 0.0020, 0.0021],\n",
      "          [0.0016, 0.0014, 0.0015, 0.0019, 0.0023],\n",
      "          [0.0014, 0.0014, 0.0016, 0.0022, 0.0023],\n",
      "          [0.0016, 0.0018, 0.0023, 0.0025, 0.0020],\n",
      "          [0.0020, 0.0024, 0.0026, 0.0022, 0.0017]]],\n",
      "\n",
      "\n",
      "        [[[0.0028, 0.0027, 0.0020, 0.0018, 0.0019],\n",
      "          [0.0027, 0.0023, 0.0018, 0.0018, 0.0020],\n",
      "          [0.0026, 0.0023, 0.0020, 0.0021, 0.0023],\n",
      "          [0.0024, 0.0026, 0.0026, 0.0027, 0.0027],\n",
      "          [0.0023, 0.0027, 0.0029, 0.0028, 0.0027]]],\n",
      "\n",
      "\n",
      "        [[[0.0018, 0.0017, 0.0014, 0.0012, 0.0013],\n",
      "          [0.0018, 0.0017, 0.0014, 0.0012, 0.0013],\n",
      "          [0.0018, 0.0018, 0.0015, 0.0014, 0.0016],\n",
      "          [0.0018, 0.0019, 0.0017, 0.0017, 0.0017],\n",
      "          [0.0017, 0.0019, 0.0019, 0.0018, 0.0017]]],\n",
      "\n",
      "\n",
      "        [[[0.0031, 0.0024, 0.0018, 0.0021, 0.0030],\n",
      "          [0.0030, 0.0021, 0.0019, 0.0029, 0.0040],\n",
      "          [0.0031, 0.0026, 0.0031, 0.0044, 0.0044],\n",
      "          [0.0035, 0.0037, 0.0043, 0.0044, 0.0034],\n",
      "          [0.0033, 0.0038, 0.0037, 0.0033, 0.0029]]],\n",
      "\n",
      "\n",
      "        [[[0.0059, 0.0064, 0.0068, 0.0076, 0.0082],\n",
      "          [0.0048, 0.0048, 0.0048, 0.0048, 0.0057],\n",
      "          [0.0034, 0.0030, 0.0024, 0.0025, 0.0038],\n",
      "          [0.0031, 0.0022, 0.0016, 0.0020, 0.0034],\n",
      "          [0.0040, 0.0027, 0.0020, 0.0025, 0.0037]]],\n",
      "\n",
      "\n",
      "        [[[0.0016, 0.0018, 0.0025, 0.0038, 0.0045],\n",
      "          [0.0015, 0.0017, 0.0025, 0.0042, 0.0051],\n",
      "          [0.0014, 0.0016, 0.0027, 0.0046, 0.0059],\n",
      "          [0.0014, 0.0018, 0.0031, 0.0052, 0.0063],\n",
      "          [0.0015, 0.0021, 0.0037, 0.0056, 0.0061]]]]), tensor([0.0026, 0.0020, 0.0092, 0.0049, 0.0134, 0.0043, 0.0031, 0.0020, 0.0241,\n",
      "        0.0050, 0.0062, 0.0289, 0.0038, 0.0307, 0.0021, 0.0038, 0.0181, 0.0035,\n",
      "        0.0023, 0.0051, 0.0137, 0.0028, 0.0434, 0.0044, 0.0121, 0.0168, 0.0051,\n",
      "        0.0034, 0.0023, 0.0089, 0.0216, 0.0117]), tensor([[[[0.0011, 0.0012, 0.0013, 0.0013, 0.0013],\n",
      "          [0.0011, 0.0012, 0.0014, 0.0014, 0.0013],\n",
      "          [0.0012, 0.0012, 0.0014, 0.0015, 0.0014],\n",
      "          [0.0012, 0.0012, 0.0013, 0.0015, 0.0015],\n",
      "          [0.0012, 0.0013, 0.0013, 0.0014, 0.0014]],\n",
      "\n",
      "         [[0.0011, 0.0012, 0.0012, 0.0012, 0.0011],\n",
      "          [0.0011, 0.0011, 0.0012, 0.0013, 0.0012],\n",
      "          [0.0011, 0.0011, 0.0012, 0.0013, 0.0012],\n",
      "          [0.0011, 0.0011, 0.0011, 0.0012, 0.0012],\n",
      "          [0.0011, 0.0011, 0.0011, 0.0011, 0.0011]],\n",
      "\n",
      "         [[0.0011, 0.0011, 0.0012, 0.0014, 0.0013],\n",
      "          [0.0011, 0.0012, 0.0012, 0.0014, 0.0014],\n",
      "          [0.0012, 0.0013, 0.0012, 0.0013, 0.0014],\n",
      "          [0.0012, 0.0012, 0.0012, 0.0013, 0.0014],\n",
      "          [0.0011, 0.0011, 0.0012, 0.0013, 0.0013]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0011, 0.0011, 0.0011, 0.0012, 0.0011],\n",
      "          [0.0011, 0.0011, 0.0011, 0.0012, 0.0012],\n",
      "          [0.0011, 0.0011, 0.0011, 0.0011, 0.0012],\n",
      "          [0.0011, 0.0011, 0.0011, 0.0011, 0.0012],\n",
      "          [0.0011, 0.0011, 0.0011, 0.0011, 0.0011]],\n",
      "\n",
      "         [[0.0011, 0.0011, 0.0011, 0.0011, 0.0011],\n",
      "          [0.0012, 0.0013, 0.0011, 0.0011, 0.0011],\n",
      "          [0.0011, 0.0013, 0.0013, 0.0011, 0.0010],\n",
      "          [0.0011, 0.0012, 0.0013, 0.0012, 0.0011],\n",
      "          [0.0012, 0.0012, 0.0014, 0.0015, 0.0014]],\n",
      "\n",
      "         [[0.0011, 0.0012, 0.0012, 0.0011, 0.0011],\n",
      "          [0.0011, 0.0012, 0.0013, 0.0011, 0.0010],\n",
      "          [0.0011, 0.0012, 0.0013, 0.0012, 0.0010],\n",
      "          [0.0011, 0.0011, 0.0013, 0.0012, 0.0011],\n",
      "          [0.0011, 0.0011, 0.0012, 0.0012, 0.0011]]],\n",
      "\n",
      "\n",
      "        [[[0.0015, 0.0015, 0.0013, 0.0012, 0.0013],\n",
      "          [0.0016, 0.0013, 0.0012, 0.0013, 0.0015],\n",
      "          [0.0016, 0.0013, 0.0013, 0.0017, 0.0020],\n",
      "          [0.0017, 0.0015, 0.0017, 0.0022, 0.0024],\n",
      "          [0.0018, 0.0018, 0.0021, 0.0025, 0.0023]],\n",
      "\n",
      "         [[0.0013, 0.0011, 0.0011, 0.0011, 0.0012],\n",
      "          [0.0013, 0.0012, 0.0012, 0.0013, 0.0014],\n",
      "          [0.0014, 0.0013, 0.0014, 0.0016, 0.0016],\n",
      "          [0.0015, 0.0015, 0.0015, 0.0016, 0.0016],\n",
      "          [0.0014, 0.0015, 0.0015, 0.0016, 0.0015]],\n",
      "\n",
      "         [[0.0021, 0.0020, 0.0012, 0.0011, 0.0013],\n",
      "          [0.0022, 0.0015, 0.0011, 0.0012, 0.0019],\n",
      "          [0.0018, 0.0013, 0.0012, 0.0018, 0.0029],\n",
      "          [0.0015, 0.0014, 0.0017, 0.0027, 0.0028],\n",
      "          [0.0015, 0.0016, 0.0022, 0.0026, 0.0021]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0013, 0.0011, 0.0011, 0.0011, 0.0012],\n",
      "          [0.0012, 0.0011, 0.0011, 0.0013, 0.0015],\n",
      "          [0.0012, 0.0013, 0.0015, 0.0017, 0.0016],\n",
      "          [0.0013, 0.0016, 0.0017, 0.0016, 0.0014],\n",
      "          [0.0014, 0.0016, 0.0015, 0.0013, 0.0014]],\n",
      "\n",
      "         [[0.0012, 0.0013, 0.0013, 0.0013, 0.0012],\n",
      "          [0.0012, 0.0012, 0.0012, 0.0011, 0.0011],\n",
      "          [0.0012, 0.0012, 0.0012, 0.0011, 0.0011],\n",
      "          [0.0012, 0.0013, 0.0013, 0.0013, 0.0013],\n",
      "          [0.0016, 0.0016, 0.0018, 0.0017, 0.0015]],\n",
      "\n",
      "         [[0.0011, 0.0010, 0.0011, 0.0013, 0.0013],\n",
      "          [0.0011, 0.0011, 0.0013, 0.0015, 0.0013],\n",
      "          [0.0011, 0.0012, 0.0016, 0.0016, 0.0012],\n",
      "          [0.0012, 0.0014, 0.0018, 0.0016, 0.0011],\n",
      "          [0.0014, 0.0015, 0.0017, 0.0015, 0.0012]]],\n",
      "\n",
      "\n",
      "        [[[0.0016, 0.0016, 0.0015, 0.0014, 0.0015],\n",
      "          [0.0017, 0.0016, 0.0013, 0.0013, 0.0015],\n",
      "          [0.0018, 0.0016, 0.0013, 0.0013, 0.0016],\n",
      "          [0.0018, 0.0018, 0.0014, 0.0014, 0.0017],\n",
      "          [0.0017, 0.0017, 0.0015, 0.0013, 0.0017]],\n",
      "\n",
      "         [[0.0013, 0.0012, 0.0011, 0.0012, 0.0013],\n",
      "          [0.0014, 0.0012, 0.0011, 0.0011, 0.0014],\n",
      "          [0.0015, 0.0014, 0.0012, 0.0012, 0.0015],\n",
      "          [0.0014, 0.0014, 0.0013, 0.0012, 0.0014],\n",
      "          [0.0013, 0.0014, 0.0012, 0.0012, 0.0013]],\n",
      "\n",
      "         [[0.0018, 0.0021, 0.0015, 0.0011, 0.0013],\n",
      "          [0.0019, 0.0019, 0.0013, 0.0010, 0.0013],\n",
      "          [0.0017, 0.0017, 0.0013, 0.0011, 0.0014],\n",
      "          [0.0016, 0.0017, 0.0014, 0.0012, 0.0015],\n",
      "          [0.0015, 0.0016, 0.0013, 0.0012, 0.0016]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0013, 0.0012, 0.0011, 0.0011, 0.0011],\n",
      "          [0.0012, 0.0012, 0.0011, 0.0011, 0.0012],\n",
      "          [0.0012, 0.0013, 0.0013, 0.0013, 0.0013],\n",
      "          [0.0012, 0.0013, 0.0013, 0.0012, 0.0012],\n",
      "          [0.0011, 0.0012, 0.0012, 0.0012, 0.0012]],\n",
      "\n",
      "         [[0.0013, 0.0015, 0.0016, 0.0015, 0.0013],\n",
      "          [0.0013, 0.0014, 0.0015, 0.0015, 0.0012],\n",
      "          [0.0012, 0.0011, 0.0012, 0.0015, 0.0013],\n",
      "          [0.0014, 0.0013, 0.0014, 0.0017, 0.0016],\n",
      "          [0.0017, 0.0016, 0.0016, 0.0017, 0.0016]],\n",
      "\n",
      "         [[0.0013, 0.0011, 0.0011, 0.0013, 0.0013],\n",
      "          [0.0013, 0.0011, 0.0011, 0.0014, 0.0015],\n",
      "          [0.0013, 0.0011, 0.0011, 0.0014, 0.0016],\n",
      "          [0.0014, 0.0011, 0.0011, 0.0014, 0.0016],\n",
      "          [0.0014, 0.0012, 0.0011, 0.0014, 0.0015]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0015, 0.0017, 0.0016, 0.0014, 0.0013],\n",
      "          [0.0015, 0.0017, 0.0016, 0.0014, 0.0013],\n",
      "          [0.0017, 0.0018, 0.0017, 0.0014, 0.0014],\n",
      "          [0.0020, 0.0021, 0.0019, 0.0016, 0.0014],\n",
      "          [0.0019, 0.0020, 0.0018, 0.0016, 0.0014]],\n",
      "\n",
      "         [[0.0012, 0.0014, 0.0013, 0.0012, 0.0012],\n",
      "          [0.0012, 0.0013, 0.0013, 0.0012, 0.0012],\n",
      "          [0.0015, 0.0015, 0.0014, 0.0013, 0.0012],\n",
      "          [0.0015, 0.0016, 0.0015, 0.0013, 0.0012],\n",
      "          [0.0012, 0.0013, 0.0013, 0.0012, 0.0012]],\n",
      "\n",
      "         [[0.0015, 0.0018, 0.0021, 0.0016, 0.0014],\n",
      "          [0.0015, 0.0022, 0.0020, 0.0015, 0.0015],\n",
      "          [0.0017, 0.0022, 0.0018, 0.0017, 0.0017],\n",
      "          [0.0019, 0.0020, 0.0019, 0.0019, 0.0016],\n",
      "          [0.0019, 0.0017, 0.0017, 0.0016, 0.0013]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0012, 0.0013, 0.0013, 0.0012, 0.0011],\n",
      "          [0.0013, 0.0012, 0.0012, 0.0012, 0.0012],\n",
      "          [0.0015, 0.0013, 0.0014, 0.0014, 0.0012],\n",
      "          [0.0014, 0.0014, 0.0014, 0.0013, 0.0011],\n",
      "          [0.0012, 0.0012, 0.0012, 0.0011, 0.0011]],\n",
      "\n",
      "         [[0.0015, 0.0013, 0.0012, 0.0012, 0.0012],\n",
      "          [0.0013, 0.0013, 0.0013, 0.0012, 0.0012],\n",
      "          [0.0011, 0.0011, 0.0011, 0.0011, 0.0011],\n",
      "          [0.0014, 0.0013, 0.0012, 0.0012, 0.0012],\n",
      "          [0.0019, 0.0018, 0.0016, 0.0014, 0.0013]],\n",
      "\n",
      "         [[0.0014, 0.0014, 0.0012, 0.0011, 0.0011],\n",
      "          [0.0015, 0.0013, 0.0012, 0.0012, 0.0011],\n",
      "          [0.0014, 0.0013, 0.0012, 0.0012, 0.0011],\n",
      "          [0.0015, 0.0013, 0.0012, 0.0011, 0.0011],\n",
      "          [0.0014, 0.0013, 0.0012, 0.0011, 0.0011]]],\n",
      "\n",
      "\n",
      "        [[[0.0011, 0.0011, 0.0011, 0.0011, 0.0011],\n",
      "          [0.0011, 0.0011, 0.0012, 0.0012, 0.0013],\n",
      "          [0.0011, 0.0012, 0.0012, 0.0013, 0.0013],\n",
      "          [0.0011, 0.0012, 0.0012, 0.0012, 0.0012],\n",
      "          [0.0011, 0.0012, 0.0012, 0.0012, 0.0011]],\n",
      "\n",
      "         [[0.0011, 0.0011, 0.0011, 0.0011, 0.0011],\n",
      "          [0.0011, 0.0011, 0.0012, 0.0012, 0.0012],\n",
      "          [0.0010, 0.0011, 0.0011, 0.0011, 0.0011],\n",
      "          [0.0010, 0.0011, 0.0011, 0.0011, 0.0011],\n",
      "          [0.0011, 0.0011, 0.0011, 0.0011, 0.0011]],\n",
      "\n",
      "         [[0.0010, 0.0011, 0.0011, 0.0011, 0.0012],\n",
      "          [0.0011, 0.0011, 0.0011, 0.0013, 0.0013],\n",
      "          [0.0011, 0.0012, 0.0013, 0.0014, 0.0012],\n",
      "          [0.0011, 0.0012, 0.0013, 0.0012, 0.0012],\n",
      "          [0.0011, 0.0011, 0.0012, 0.0012, 0.0012]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0010, 0.0011, 0.0011, 0.0011, 0.0012],\n",
      "          [0.0011, 0.0011, 0.0012, 0.0012, 0.0012],\n",
      "          [0.0011, 0.0011, 0.0011, 0.0011, 0.0010],\n",
      "          [0.0011, 0.0011, 0.0011, 0.0011, 0.0011],\n",
      "          [0.0010, 0.0011, 0.0011, 0.0011, 0.0011]],\n",
      "\n",
      "         [[0.0010, 0.0010, 0.0010, 0.0010, 0.0010],\n",
      "          [0.0011, 0.0011, 0.0011, 0.0011, 0.0011],\n",
      "          [0.0012, 0.0012, 0.0013, 0.0013, 0.0013],\n",
      "          [0.0012, 0.0012, 0.0012, 0.0012, 0.0012],\n",
      "          [0.0011, 0.0011, 0.0011, 0.0011, 0.0011]],\n",
      "\n",
      "         [[0.0011, 0.0011, 0.0011, 0.0011, 0.0010],\n",
      "          [0.0011, 0.0011, 0.0011, 0.0011, 0.0010],\n",
      "          [0.0011, 0.0011, 0.0011, 0.0011, 0.0011],\n",
      "          [0.0011, 0.0011, 0.0011, 0.0011, 0.0011],\n",
      "          [0.0011, 0.0011, 0.0011, 0.0011, 0.0011]]],\n",
      "\n",
      "\n",
      "        [[[0.0018, 0.0018, 0.0017, 0.0015, 0.0015],\n",
      "          [0.0021, 0.0021, 0.0018, 0.0015, 0.0015],\n",
      "          [0.0021, 0.0022, 0.0020, 0.0016, 0.0015],\n",
      "          [0.0021, 0.0022, 0.0020, 0.0016, 0.0014],\n",
      "          [0.0021, 0.0021, 0.0017, 0.0014, 0.0013]],\n",
      "\n",
      "         [[0.0015, 0.0015, 0.0014, 0.0013, 0.0013],\n",
      "          [0.0016, 0.0017, 0.0015, 0.0013, 0.0013],\n",
      "          [0.0015, 0.0016, 0.0015, 0.0013, 0.0012],\n",
      "          [0.0015, 0.0014, 0.0013, 0.0012, 0.0012],\n",
      "          [0.0013, 0.0013, 0.0012, 0.0011, 0.0012]],\n",
      "\n",
      "         [[0.0018, 0.0020, 0.0019, 0.0017, 0.0016],\n",
      "          [0.0018, 0.0018, 0.0022, 0.0020, 0.0018],\n",
      "          [0.0016, 0.0019, 0.0027, 0.0021, 0.0015],\n",
      "          [0.0017, 0.0028, 0.0026, 0.0016, 0.0013],\n",
      "          [0.0020, 0.0024, 0.0017, 0.0012, 0.0013]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0.0015, 0.0014, 0.0013, 0.0013, 0.0013],\n",
      "          [0.0014, 0.0014, 0.0015, 0.0014, 0.0013],\n",
      "          [0.0013, 0.0015, 0.0015, 0.0013, 0.0012],\n",
      "          [0.0016, 0.0015, 0.0013, 0.0012, 0.0012],\n",
      "          [0.0014, 0.0012, 0.0011, 0.0012, 0.0012]],\n",
      "\n",
      "         [[0.0013, 0.0013, 0.0013, 0.0013, 0.0012],\n",
      "          [0.0014, 0.0013, 0.0014, 0.0014, 0.0014],\n",
      "          [0.0016, 0.0014, 0.0013, 0.0014, 0.0014],\n",
      "          [0.0015, 0.0015, 0.0014, 0.0014, 0.0013],\n",
      "          [0.0019, 0.0019, 0.0017, 0.0014, 0.0013]],\n",
      "\n",
      "         [[0.0013, 0.0013, 0.0012, 0.0013, 0.0012],\n",
      "          [0.0014, 0.0013, 0.0013, 0.0012, 0.0012],\n",
      "          [0.0015, 0.0014, 0.0012, 0.0011, 0.0013],\n",
      "          [0.0015, 0.0014, 0.0011, 0.0011, 0.0013],\n",
      "          [0.0014, 0.0013, 0.0011, 0.0012, 0.0013]]]]), tensor([0.0015, 0.0033, 0.0029, 0.0016, 0.0017, 0.0015, 0.0010, 0.0015, 0.0023,\n",
      "        0.0036, 0.0019, 0.0013, 0.0017, 0.0014, 0.0014, 0.0018, 0.0021, 0.0018,\n",
      "        0.0017, 0.0015, 0.0010, 0.0020, 0.0010, 0.0018, 0.0023, 0.0017, 0.0020,\n",
      "        0.0025, 0.0022, 0.0020, 0.0014, 0.0022]), tensor([[0.0013, 0.0022, 0.0049,  ..., 0.0049, 0.0166, 0.0116],\n",
      "        [0.0018, 0.0039, 0.0028,  ..., 0.0081, 0.0098, 0.0051],\n",
      "        [0.0017, 0.0054, 0.0103,  ..., 0.0129, 0.0196, 0.0142],\n",
      "        ...,\n",
      "        [0.0017, 0.0038, 0.0054,  ..., 0.0175, 0.0211, 0.0081],\n",
      "        [0.0028, 0.0045, 0.0096,  ..., 0.0114, 0.0337, 0.0383],\n",
      "        [0.0025, 0.0046, 0.0102,  ..., 0.0217, 0.0339, 0.0166]]), tensor([0.0025, 0.0027, 0.0039, 0.0038, 0.0035, 0.0032, 0.0025, 0.0035, 0.0042,\n",
      "        0.0046])]\n"
     ]
    }
   ],
   "source": [
    "print(MNIST_NN_Hessian_diag_1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As you can see, the variance gets smaller, the higher the precision gets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we want to look at the single layers of our network, and how they behave w.r.t. the variance\n",
    "* every tensor represents one of the six layers of out network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meancalc(Hessian_diag_x): \n",
    "    for ith_tensor in range(len(Hessian_diag_x)) :\n",
    "        mean = torch.mean(Hessian_diag_x[ith_tensor])\n",
    "        print(\"mean variance of layer {0:d}: {1:.4f}\".format(ith_tensor+1, mean.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 10:\n",
      "mean variance of layer 1: 0.1025\n",
      "mean variance of layer 2: 0.1109\n",
      "mean variance of layer 3: 0.1003\n",
      "mean variance of layer 4: 0.1009\n",
      "mean variance of layer 5: 0.1124\n",
      "mean variance of layer 6: 0.1025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"precision 60:\")\\nmeancalc(MNIST_NN_Hessian_diag_60)\\nprint(\"precision 120:\")\\nmeancalc(MNIST_NN_Hessian_diag_120)\\nprint(\"precision 1000:\")\\nmeancalc(MNIST_NN_Hessian_diag_1000)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"precision 10:\")\n",
    "meancalc(MNIST_NN_Hessian_diag_10)\n",
    "\"\"\"\n",
    "print(\"precision 60:\")\n",
    "meancalc(MNIST_NN_Hessian_diag_60)\n",
    "print(\"precision 120:\")\n",
    "meancalc(MNIST_NN_Hessian_diag_120)\n",
    "print(\"precision 1000:\")\n",
    "meancalc(MNIST_NN_Hessian_diag_1000)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### it's not save to say, that the variance gets smaller in deeper parts of this network\n",
    "* it's clear, that the flatten-layer has a bigger variance, than the previous layers\n",
    "* after the flatten-layer it drops in all of the observations\n",
    "* also in all cases the variance in the first layer is smaller, than in the fc-layer\n",
    "* the first maxpool layer has the biggest variance in all obsersations - obviously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom PIL import Image\\nyticks = np.arange(10, 0, step=1)\\nxticks = np.arange(0, 512, step=100)\\na = np.array(MNIST_NN_Hessian_diag_10[4])\\nplt.yticks = yticks\\nplt.xticks = xticks\\nplt.plot(a)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from PIL import Image\n",
    "yticks = np.arange(10, 0, step=1)\n",
    "xticks = np.arange(0, 512, step=100)\n",
    "a = np.array(MNIST_NN_Hessian_diag_10[4])\n",
    "plt.yticks = yticks\n",
    "plt.xticks = xticks\n",
    "plt.plot(a)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport seaborn as sns\\ntest = MNIST_NN_Hessian_diag_10[0][0]\\ntest2 = MNIST_NN_Hessian_diag_10[0][1]\\ntestit = np.concatenate((test, test2))\\ntestittp = testit.transpose(2, 0, 1).reshape(5, -1)\\narr = np.array(testittp)\\nprint(testit)\\nprint(\"---\")\\nprint(arr)\\nax = sns.heatmap(arr, linewidth=0.5)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import seaborn as sns\n",
    "test = MNIST_NN_Hessian_diag_10[0][0]\n",
    "test2 = MNIST_NN_Hessian_diag_10[0][1]\n",
    "testit = np.concatenate((test, test2))\n",
    "testittp = testit.transpose(2, 0, 1).reshape(5, -1)\n",
    "arr = np.array(testittp)\n",
    "print(testit)\n",
    "print(\"---\")\n",
    "print(arr)\n",
    "ax = sns.heatmap(arr, linewidth=0.5)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize the first layer of our networks in a heatmap\n",
    "* therefore we put the tensor in the right form/dimensions, by concatening all of its included arrays and then reshaping the tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def visualize(tensor):\n",
    "    output = tensor[0][0]\n",
    "    for i in range(1, len(tensor[0])):\n",
    "        output = np.concatenate((output, tensor[0][i]))\n",
    "    output = output.transpose(2, 0, 1).reshape(5, -1)\n",
    "    heatmap = sns.heatmap(output)\n",
    "    plt.xticks = (np.arange(0, step=20))\n",
    "    plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEBCAYAAABR6+96AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dfbxcVX3v8c935jzknJyQRwiQoKAEEcQHCEGLAmqF0FbgKlzRe1uw2rS1SFvrvXJf+gIFr9XWavWWqrmKrVakYOs1KhXRitqiEgwYiIDE8BQEDEnIc3LOzPzuH2udyWQy58yc5BwyZ/J957Vf2Wfttddee+09a9Zee+3ZigjMzKx9FQ50BszMbHSuqM3M2pwrajOzNueK2syszbmiNjNrc10TvYE/OPqi2Bi7ADhaUwE4d0eFXQiAi7b8GIBKBMMjUIqF9P3RVSgyracPgG4Vc1gXvYXuPbZxSt88evJ3zs4oAzC8zU3lnTw1uAmAKcW0XpECZSoADFZKAKzd+jQFqbpdgO5CEeWwogrV/2f0DADw3J7ZABxamMLppSkAzBsq5W0EQ3kfNxVTeu8bvI+hyhBANY1ZXVMZipSXB7asBWBHaZBSJe2HchrTe/s5si9tb3Z3Wvfo4rTd+53354fbHmJHOe37lsEd1TIa6E75O+OQBdV0nypvA+DJoVQ+W4a2AzCtu5/+Ym+1rAC2V3ZVlx/XfyQAu2Kounyg0FMtn68/8VNqDZchpOMM0NvVzVC5tMfyGb1TOXYgpf2rneur60ztSufAgt5D0/+FAf5x410AFPJxmd4zlWk53vAxPbR7WnX+yXwOrNvxDEO5bP/0sFcA0B1iu1L5PcUgAE+Ut3HX5ocA2DE0mLel6nnQlY/psO1DuyhXUhrD509BoqeYPmLDy6Z09XDYlBmpzIrpmDyxa2P1nC7UlNXwthZNmZfSINiVz5W1pc1pf4a28Pi2p/fa7vC65Rz/6KlzmdHVD8DMQtruLPVQyOfXb+1M677mHQU0kOI9tjSdj/9n5yEs2/xzgGrZ7SoPVfPZnbe7ozRYPZbD+xuk4y3EUD4WtSPNhuMPH8cdOx7ZXQD7aOjpNS0PZeue87z93t6zwS1qM5tQw40N23cT3qI2M3tW1bT2O4UrajPrLLnbpZO4ojazjhLhitrMrL25RW1m1ubcojYza3N5CGEncUVtZp0lj8/vJK6ozayj+GaimVm7881EM7M25xa1mVmb881EM7M255uJZmZtzl0fZmZtzjcTzczaW4T7qM3M2pu7PszM2py7PszM2tzB+OIASccD5wPzctDjwLKIuG8iM2Zmtk86sOtj1HcmSnoPcAMg4I48CfiypCsmPntmZmNUqbQ+TRLNWtRvA06MiD2uJSR9DFgFfLjRSpKWAEsAXjnrZOYOzGsUzcxs/B1sLWqgAhzZIPyIvKyhiFgaEQsjYuHx0563P/kzMxubg7BF/WfAdyU9CDyWw54DHAtcNpEZMzPbJ5OoAm7VqC3qiPgWcBzwAeCWPL0feEFeZmbWVqI81PLUjKTFkh6QtLrRfTlJZ0haIakk6cK6Zd+S9Iykb9SFfymnea+k6yR1N8tH01EfkX6F+8dN98jMrB2MUx+1pCJwLfA6YC2wXNKyiPh5TbRHgUuBdzdI4q+BfuAP68K/BPz3PH898HbgU6PlxeOozayzjF/XxyJgdUSsAZB0A2mocrWijoiH87K9NhoR35V0VoPwm4fnJd0BzG+WkWY3E83MJpeotDxJWiLpzpppSU1K89h9bw5Sq3rchrDlLo/fBZp2I7tFbWadZQwt6ohYCiyduMyM6u+BH0TED5tFdEVtZp1l/F4c8DhwVM3f83PYfpN0FXAoe/dfN+SK2sw6y/j1US8HFkg6hlRBXwy8ZX8TlfR24BzgtdHiK9PdR21mnWUMfdSjJhNRIj0vcgtwH3BjRKySdLWk8wAknSppLXAR8BlJq4bXl/RD4CbgtZLWSjonL/o0MBf4kaS7JV3ZbJfcojazzjKOD7zkERo314VdWTO/nBFGbUTEq0YIH3O964razDpLB/7WhytqM+ssHfgIuStqM+ss4zfqo224ojazzuIWtZlZm4s40DkYd66ozayzuEVtZtbmXFGbmbU5D88zM2tz5fKBzsG4m/CK+iXlXk4upW+44178q2r4Lfek3zopKj3FLoJQ7BEGcHjvTAB6C+klCN0qsLOSht9sKm0H4NiYQjcCYHtOY2Z+acKvVGQo0oHbVUlvdBiMUnUb/cVeAHqKXRQLez5RX44KlUpKb6B7CgBTu/p4bs9sABYUBlJ6BC+ObQBsy0VaVHBo72Bad1faRqlmu10q5n3YwbrBTXuVWyHHG+hJ233O1MPoUUp7RiGldyS9HFZO+72pkPL5H4hy3aVfT7GL/q6UzlHqA2ALZaZ3zeCuwV+zftdmAHaUUn4X9B/BnGI/ABsrOwHYMLSV7aVdKaycyn1beSeVfOPmqN5ZAMxRH4W6cowIou4GT6lSRkp5n9LVA8C8/jmc1n0YAP+8/SkAeos9HNo9DYCzmA7A83aW+WIun76uVBYDxSmUc0tqeznlc0bvHJ7Ox357Oe1Huaa1dWoKYkjwk5QMj5TSsXhycFM1z8PnRSGfY13FYvU4DuahYLVlHkTeVlT3saeYj13PAMf3pn2cp3RMbqsMVvM1mM/tIKphR5Iyt50Kv4ytAPx6KB2zraUd1W0Mxy+oWA0r5l+JeH7PbA7P25uXH4ybXoKt+VC96rXps9nzjs9S+tbnALh9yw4AHi9uqqZdit2VYHehmLeXP8MSpUp5r/IA6Mpxh+NV5xHjzl0f1knuGvz1gc7CpNNVLDaPZHuoraSfFa6ozczanPuozczaW1Q8jtrMrL35EXIzszbnFrWZWZvzzUQzszbnitrMrM35R5nMzNqcW9RmZm3Oj5CbmbU5j/owM2tv4a4PM7M214Et6kLzKGZmk0hUWp+akLRY0gOSVku6osHyMyStkFSSdGHdsm9JekbSN+rCj5H0k5zmP0vqaZYPV9Rm1llK5danUUgqAtcC5wInAG+WdEJdtEeBS4HrGyTx18DvNgj/CPDxiDgW2Ai8rdkuuaI2s85Sidan0S0CVkfEmogYBG4Azq+NEBEPR8RKYK/meUR8F9hSG6b0Y9yvAb6Sg/4RuKBZRlxRm1lnGUPXh6Qlku6smZbUpDQPeKzm77U5bH/MBp6JiOFfjmopTd9MNLPOMoabiRGxFFg6cZkZH66ozayjjOPwvMeBo2r+np/D9sd6YIakrtyqbilNd32YWWcZvz7q5cCCPEqjB7gYWLY/WYv0Is7vAcMjRC4BvtZsPVfUZtZZyuXWp1HkFu9lwC3AfcCNEbFK0tWSzgOQdKqktcBFwGckrRpeX9IPgZuA10paK+mcvOg9wLskrSb1WX+u2S7tc9eHpLdGxOdHWLYEWAJw8YxFnDxl/r5uxsxsbMbxgZeIuBm4uS7sypr55aTui0brvmqE8DWkESUt258W9QdGWhARSyNiYUQsPH1gwX5swsxsbKISLU+TxagtakkrR1oEzB3/7JiZ7adJVAG3qlnXx1zgHNLTM7UE3D4hOTIz2x8H4Y8yfQMYiIi76xdIum1CcmRmtj8OthZ1RIz4DHpEvGX8s2Nmtn+ifPC1qM3MJpeDrUVtZjbpuKI2M2tvk2nYXatcUZtZZ3FFbWbW3qLkitrMrL25RW1m1uY6b3SeK2oz6yy+mWhm1u7cojYza29uUZuZtbnqa2M7iCtqM+ss7vowM2tv4YrazKzNuaI2M2tvblGbmbU5V9T7IICT3rgjbWzx+QD8+sqb2TnKa3XLuaQrleCI7ukATFcPADsp8XhsyWmnYTgbVWZdDKZtIABm0A3APPXzcKQ3iW0u7aiuN6fnEACO6JoGwK+K6ylV0uvjd5aGAChVyhQLKaNz+2YCcHTvbJ5XGMh5Sfl8qLyF73TNBmBV13YAelRgUTlt47Ac77DeGfSoa499XDe0mV3ltL1Dp8yo5q+3kPJ/Uu/hAJw/2MeHKg+ndYtTU3oVcdxgusW9VYU9ygSgv6s3lUXPANO7+gGYGUUAtqjMhqGtad3BnQAMVVJaz+06hGn51Hiiksp6y9B2hnL5PLlzQ1pvaCe9xZTPubk8i4iIkYdHKf8/raePKV3pmL6g/0gALtBhnKVNAPxLIeVzRvdUTumaA8DLB1PZForBQHdfSqcr/V9Qgc1D2wDYUd4FQB9ddCml05PLs7erm0LOxYsPfTrtz9PTeDLned1Q2t9yVOjKeShq75N1+PgN/99VKFbLvlKz/9O6+6v7AfCCnjmcN5SPXzmV99fK29k6tH2P9Ioq0F1Mx2BeKeV3S6HIykjnyvCx6Cl0M1jekstA1XU1XNL5v6PUx/RI+7Er53NNV4XNpHS6X3RUyvtTD1F5+BEA1qfdZxdltg6lc2T4MzJ83IHq+VuqlBkq7znkolgoUo4KfV091XWV8xkRu8tsHF+fFWU1jzTJuEVtZhOqL38hP1s6sUU9SrvWzGzyiYpanpqRtFjSA5JWS7qiwfIzJK2QVJJ0Yd2ySyQ9mKdLasLfLOkeSSslfUvSnGb5cEVtZh0lKq1Po5FUBK4FzgVOAN4s6YS6aI8ClwLX1607C7gKOA1YBFwlaaakLuATwKsj4sXASuCyZvvkitrMOkqEWp6aWASsjog1ETEI3ACcv+e24uGIWMnegwLPAW6NiA0RsRG4FVhMumsgYKpSZ/0hwK+aZcR91GbWUSql1m8mSloCLKkJWhoRS/P8POCxmmVrSS3kVjRad15EDEn6Y+AeYBvwIPAnzRJzi9rMOkrEWKZYGhELa6alzbew7yR1A38MvAw4ktT18b+areeK2sw6yjjeTHwcOKrm7/k5rBUjrftSgIj4ZaRxrDcCv9EsMVfUZtZRxrGiXg4skHSMpB7gYmBZi9m4BTg730CcCZydwx4HTpB0aI73OuC+Zom5j9rMOsooz1uNMZ0oSbqMVMEWgesiYpWkq4E7I2KZpFOBrwIzgddL+kBEnBgRGyRdQ6rsAa6OiA0Akj4A/EDSEPAIadTIqFxRm1lHaWV8dMtpRdwM3FwXdmXN/HJSt0ajda8DrmsQ/mng02PJhytqM+soFT9CbmbW3irNx0dPOq6ozayjtPAgy6TjitrMOsp49lG3C1fUZtZRxmvURztxRW1mHcUtajOzNleudN5zfK6ozayjuOvDzKzNdeLwvKbXCJKOl/RaSQN14YsnLltmZvtmHH+Pum2MWlFLuhz4GvBO4F5JtT+a/aGJzJiZ2b4Yy8+cThbNuj7+ADglIrZKOhr4iqSjI+IT7H6h9F5qf4z7TTMWcSmzxym7Zmaj68Sbic32qBARWyG9cgY4CzhX0scYpaKu/THu0wcWjFdezcyaqoRaniaLZhX1U5JeOvxHrrR/B5gDnDSRGTMz2xcxhmmyaNb18XtAqTYgIkrA70n6zITlysxsH02mlnKrRq2oI2LtKMv+c/yzY2a2fybTaI5WeRy1mXWUyoHOwARwRW1mHaXsFrWZWXurjDwgbdJyRW1mHSVcUZuZtTf3UZuZtTm3qM3M2lypeZRJp/Meijezg1qglqdmJC2W9ICk1ZKuaLD8DEkrJJUkXVi37BJJD+bpkprwHklLJf1C0v2S3tgsH25Rm1lHGa83cUkqAtcCrwPWAsslLYuIn9dEexS4FHh33bqzgKuAhaSn1X+a190IvBf4dUQcJ6kAzGqWF1fUZtZRxnF43iJgdUSsAZB0A3A+UK2o84/VIan+HuY5wK0RsSEvvxVYDHwZ+H3g+Lx+BXi6WUbc9WFmHWUsP8okaYmkO2umJTVJzQMeq/l7bQ5rRcN1Jc3If1+Tu0xukjS3WWKuqM2so1TGMNX+JHOelk5w9rqA+cDtEXEy8CPgo81WckVtZh2lLLU8NfE4cFTN3/NzWCtGWnc9sB341xx+E3Bys8RcUZtZRxlLi7qJ5cACScdI6gEuBpa1mI1bgLMlzZQ0EzgbuCUiAvg66SUsAK+lps97JL6ZaGYdZbxGfURESdJlpEq3CFwXEaskXQ3cGRHLJJ0KfBWYCbxe0gci4sSI2CDpGlJlD3D18I1F4D3AFyX9LbAOeGuzvLiiNrOOMp4/yhQRNwM314VdWTO/nNSt0Wjd64DrGoQ/ApwxlnxMeEW9rQBU0ktv4qHVKWxTL8eXdu4RLwjKlXQxUondFyXdSr0zh6s3LaOHncUyAEOV9AzS7YNPsmFoKwCzugcAeFnPYelvulg/uDnFj7TerJ5pHNedXrh7ZE73xxEMVcrVvABIopi3P6d7GgCzC32sj0EA7h9cB8D6wc2s792e57cAcEhXH0w5IuWFKQAcXZhJL0UANkTa/12VIaYUuwF405RjAThlZ4UTD08jdg59Q1/Ky0A/H/yrlK8epTSOGqxw2JS03am7egDoLXTT25vS6yumsEMKU6jkfZqS3z+0lRKn9T+HH2xdTSnvdyWX/6F0M5jj74ihapkUC6kstpd2AVCOSrWstlVSmTxTGKRS93pn5bIEiLzspEOey6ldcwB4/c60jRec+BjF/rTOjOXpOB7dM4tTdxV2JwT8IqYyo3sqAF25LLaUdrBlKJVFKR/nXhWYplQG07v6q/HL+fya9aK03W0/HmRGpOXze9KQ1m4VWFl+tLqfAIP5fBssl6r7MXzONFJUgRf0HQ7AccXpAPzmTvHCWenYbtmazot165+pptNTTB/JYrFQPS4nlXcA8ED00VNM+zu9u7+6jce3pvQKuSyKhQKFav9r+n89gzwY6bg9UUrn6Lbyzmr5UUnnXmz+NVu/mwYrbCykAQ69lWJ1f4c/D92FYvWYDpdPJaIaVsjx+rp6qnlSgz7h4XNuPF+LNZlesdUqt6gPYj/YuvpAZ2HSGSx34gPKE2v4C/7ZMl5dH+3EFbWZdZSRr3EmL1fUZtZR3KI2M2tz/j1qM7M254razKzNdeC7bV1Rm1ln6cRxOa6ozayjeBy1mVmb86gPM7M255uJZmZtzhW1mVmbcx+1mVmbK7mP2sysvblFbWbW5iodWFW7ojazjuKbiWZmba7z2tOuqM2sw7hFbWbW5krqvDa1K2oz6yidV023UFFLWgRERCyXdAKwGLg/v53XzKytdGLXx6hvnZR0FfBJ4FOS/hL4O2AqcIWk946y3hJJd0q6846tD45rhs3MRlMhWp4mi2avB74QOB04A/gT4IKIuAY4B3jTSCtFxNKIWBgRCxcNLBi3zJqZNRNjmJqRtFjSA5JWS7qiwfIzJK2QVJJ0Yd2ySyQ9mKdLGqy7TNK9rexTs66PUkSUge2SfhkRmwEiYoekTrzCMLNJrjROLWVJReBa4HXAWmC5pGUR8fOaaI8ClwLvrlt3FnAVsJD0nfDTvO7GvPwNwNZW89KsRT0oqT/Pn1KTiel0ZleQmU1y49iiXgSsjog1ETEI3ACcv8e2Ih6OiJXsXR+eA9waERty5Xwr6f4ekgaAdwEfbHWfmlXUZ0TE9pyh2ox0A3s15c3MDrTKGKba+2l5WlKT1DzgsZq/1+awVoy27jXA3wDbW92nUbs+ImLXCOFPA0+3uhEzs2dLjKHrIyKWAksnLjd7kvRS4PkR8eeSjm51vWYtajOzSWUsLeomHgeOqvl7fg5rxUjrvgJYKOlh4D+A4yTd1iwxV9Rm1lHGcXjecmCBpGMk9QAXA8tazMYtwNmSZkqaCZwN3BIRn4qIIyPiaOCVwC8i4qxmibmiNrOOUiZankYTESXgMlKlex9wY0SsknS1pPMAJJ0qaS1wEfAZSavyuhtIfdHL83R1DtsnfoTczDrKeA5Hy09g31wXdmXN/HJSt0ajda8Drhsl7YeBF7WSD1fUZtZRxnIzcbJwRW1mHaUTH/BwRW1mHcUtajOzNucWtZlZmyuHW9RmZm1tMv18aatcUZtZR3EftZlZm3MftZlZm3PXh5lZm2v2aPhk5IrazDpKeNSHmVl7c9fHPji8BJrSDcDQnQ8AsHNwgBeeti6FfbsMpG/B+ru1kqrzU0jzBQrMVC8AO4p9AKze8STl/AKa6d3pzWHDB2sDper8tK607Jie2RyZ0xi+8SCJAru3B9BdKFJU+oHBvkLah00xyBNDmwB4Ymf6MazBSomCtqR9K6d3LfQVexjKeVpXzPsVUMz71J+Lfl7PDHZGCYA/OnZtyudbTqVwxjv3yEvl9mX0F1OeD9cUAHqjws6hlM5DhRQ2wJRqnrvz/0NR5plyepnE41PmALCxsouiigD0FFMalUL6e5BgZy6ZgULa5iHdU6t52bBrc7V8eoupXEqVdByfKe+gXu1xHJ6/oDCXM9MrODnihak8d27q4lf3TQdgVlcqz7mawtZiWufBSjp+a7oDhlJ6O8uDAGwr7aASe95GKiL6lPZtelc6VyoEg5VU3ltWp/IpV8TLymk/ZnTNTGHAypzO8L7tGBqsnmeFvB/D2xSq7luhZn9fWkzpvXgwhc1gF09tmAbA/V3pmA3l9IHqsZNU3da2StqHwSLMK6Qy6O7O56W6uFePVPOQ9qfCIGkfh8/pu3c+yYahVKa7ykPV/Ro+fkP3ppeRxNav8OuHD6mWH8DhhT668rlRLOzOX33LtSBRzOU9HK8cFcrlyh5xh+cnanSGbyaamY3Rs90V4eF5ZmZtzl0fZmZtzo+Qm5m1OXd9mJm1OXd9mJm1OY+jNjNrc25Rm5m1uXJ03khqV9Rm1lE6rz3titrMOkwndn0UDnQGzMzGU4VoeWpG0mJJD0haLemKBsvPkLRCUknShXXLLpH0YJ4uyWH9kr4p6X5JqyR9uJV9ckVtZh0lIlqeRiOpCFwLnAucALxZ0gl10R4FLgWur1t3FnAVcBqwCLhK0sy8+KMRcTzwMuB0Sec22ydX1GbWUcaxRb0IWB0RayJiELgBOL82QkQ8HBEr2fu3oM4Bbo2IDRGxEbgVWBwR2yPie3ndQWAFML9ZRlxRm1lHqUSl5UnSEkl31kxLapKaBzxW8/faHNaKputKmgG8Hvhus8R8M9HMOspYbiZGxFJg6cTlpjFJXcCXgU9GxJpm8d2iNrOOMl591MDjwFE1f8/PYa1otu5S4MGI+NtWEnNFbWYdZRz7qJcDCyQdI6kHuBhY1mI2bgHOljQz30Q8O4ch6YPAdODPWt0nV9Rm1lFiDP9GTSeiBFxGqmDvA26MiFWSrpZ0HoCkUyWtBS4CPiNpVV53A3ANqbJfDlwdERskzQfeSxpFskLS3ZLe3myf3EdtZh2lMo4/yhQRNwM314VdWTO/nBFGbUTEdcB1dWFroe6dfy0Yc4ta0hfGuo6Z2bOlHJWWp8li1Ba1pPr+GAGvzsNKiIjzJipjZmb74mB8ccB84OfAZ0m/dSJgIfA3o62UxyIuAbhk+iIuZO7+59TMrAXj2fXRLpp1fSwEfkrq/N4UEbcBOyLi+xHx/ZFWioilEbEwIhaeNXXB+OXWzKyJ8bqZ2E5GbVFHRAX4uKSb8v9PNVvHzOxA6sQWdUuVbr5TeZGk3wY2T2yWzMz2XSXKBzoL425MreOI+CbwzQnKi5nZfuvE36N2N4aZdRS/3NbMrM25RW1m1ubcojYza3MH7agPM7PJojKJHg1vlStqM+so7qM2M2tz7qM2M2tz7qM2M2tzblGbmbU591GbmbW5csWjPszM2tpk+vnSVrmiNrOO4puJZmZtzjcTzczanLs+zMzaXMU3E83MxkbSs9od0XntaVJ/zkRPwJKJij+RaR9MeW+nvDjvzounurJ7VjYCd05U/IlM+2DKezvlxXl3XjztORVaa3ebmdmB4orazKzNPVsV9dIJjD+RaU90fOdlfOK3U17GGt95saaU+47MzKxNuevDzKzNuaI2M2tzrqjNzNrchDyZKOl44HxgXg56HFgWEfc1iHs58NWIeGwi8nIwkzQ7ItYf6HyY2f4Z9xa1pPcANwAC7siTgC9LuqLBKtcAP5H0Q0nvkHToPmzzsH1Y598ahC2U9D1J/yTpKEm3Stokabmkl9XFfXHNfLek90laJulDkvobpF2U9IeSrpF0et2y9zWIX5D0+5K+KelnklZIukHSWSPsz4clzanZjzWkcn1E0pl1cQ+X9ClJ10qaLen9ku6RdKOkIxqkPT2nf7+kDZLWS7ovh81oEH9FLo/nN8prM5J+sY/r7dcxNWtb4/0EDfALoLtBeA/wYIPwu0hfGGcDnwPWAd8CLgGmNYg/q26aDTwMzARm1cU9eYTpFOCJBmnfAZwLvBl4DLgwh78W+FFd3BU1838D/ANwJvBx4AsN0v4scD3wZ8BPgY81Sqsm7PPA+4FXAn8LXA28DvgO8M4G8e+pmf8ecGqeP466J8Jy+b4TuAJYCbwHOCqHfa1B2rfkOIfXhB2ew77dIP5DwEeBR3OZ/jlw5AjnyxZgc5625Kk8HN4g/oQd01HO6VktxGl0zs8ZIe5C4L8A5wHHj5JmD3lkVv771cBfAOeO4fPYSt7n1pTj3BHizGh1m6Ns5x37m8bBOo1/gnA/8NwG4c8FHmgQvqLu7+58An8ZWNcgfiVXBLXTUP5/TV3cMvDvueKqn3Y0SPuumvlHR1rWIO7dwx9U0tXDygZpr6yZ7yKNKf1XoLc+7fr4+e8f5/97gfsaxL8P6KqNW7PsnlHyXr+fdzdIe6/jNtoy9vwSexXw98CTudyX1MX9JPCF2goCeGiU7U3YMc1h76uZP4HU8HiI1Bg4rUH8VwNrgaeBbwNHj3JunwncSfqy3Qh8A/hP4DbgqAZp/wyYmef/B3A78D7gVuAvG8Q/PZ8Hq4DTcrxfkr6gXtEg/kuBH+d1vpOn+3PYyXVxS3n522ih0gbeVTf9RS6jdwHvara+p7ryHPcEYTGwGvg3UmW0lNSCWw0sbhB/rw9LzbL+BmF/kdM7qSbsoRHWvxdYMMKyxxqE/YjUsr8IeAS4IIefyd6t0jXAG4A3UldxAj9rkPb9DcKuyh/URlcaPwWen+dPBn5Qs+znDeK/M1cUryG1xD+R8/0B4Isj5Q/4YN2yRl8y3wb+J3tWpnNJLervtHJMgWI+Nz7fYNkppMr3ctLV1Zr6OM/GMc3htV8y3yS3XoFFwO0N4o1Jjg4AAAecSURBVC8HTszzFwIPAi9vVA6kq8dD8/wxpHszkK6UGl2Z3FszfyfQl+e7RjhOdwAnAa8gVYqvrDl//rNB/Ltp/OXz8vpzGLgH+B3gS8B64GvAxcN5apDGFuCfgSvzeX4V6cvpKuCqkY6vpxHO+wlJNH3YXk6qxN6Y54sjxD1uH9KfD9wEfAyYNtIHO39wXjDCsgsahL2EdJn/b8DxpMruGVIL5Tfq4n6+bpqbww8Hvtsg7X+i8RfV24GhBuGvIXUdrCa16IY//IcCfzXCPp2VPxx35Q/WzcAS6i7LSd0oAw3WPxb4SoPwmcBHSK2tjcAGUivsIzS4tAZu2Mdz5nLgh8CvRok3Hsd0Yz6mpzeIX1tRj3gVVRNWX6GdCDwAXMDeLeraq6pi3bZWNUj7duBFef5b7G5dT6GmEm+UP/ZuPDTqXturgVCzbPUo5dIH/FfSFeF64PoG6z+H9Bn9CLnBxShfwJ6afD4OdAb2K/Opi+THwJOjxDme1B85UBe+V6WZw1/YanzS5eVwX/AJpMu63xpD/vfqy65bLmr6OZvFr1v3VaSrj7NHyPcheb6P1Or+ev5QTW8Q/3IaXJqPsu2W45P6YX8P+M389++SrlbeQYN+3xznecC7c6X7MeCPhvdnhPjPJ3UdDMf/45Hik76Yl+XyWEfNVd0IleOd1PTd57D5pNbqlrrw60j3Yf4b6Qv1Yzm8n8ZXXC8mdX98IU+/JDUK7gTe0iB+7ZXSBXXLGuX9k6SrhjcBv5GnN+Wwv6uL2/DKF5gOXDJK2Z9Pumq8EFfU+zxN+kfIJfWRugjulfTWiPh8zbLLgT8htf5eCvxpRHwtL1sRESfXpXU5qYK4v1l8SVeRblJ1kfoCF5H6Gl8H3BIR/7su7WX1WSf1b/47QESc1yQ+pFb2SPHviIhFef7teb//H+my/+sR8eGauKuAl0RESdJSYDvwFdIX1Esi4g11aW8CtpEqiuuBmyLi6Qb5axT/yzn+uhHifolUhv2kSnIq8NWcF0XEJXXxLyddgv8A+C3S1cMzpJtz74iI2/Yz/pl1WVwREVskzSXdiLy2Lv5vku6l/KwufDpwWe15IKkb+APSl/rPgOsiopzP4cMi4pEG5VMkHcPjcjmtJZ1fzzSIex6pK2p7XfjzgTdGxF81WOdcGg+lvbku3rsj4qP167dC0lRSd9xpEXHGvqRx0DvQ3xTjObH3zaJ7yC1j4GhSS+RP89+NLmNbjp/jFkkVzGb2bKE26j+8i9T9cRapf/Qs4Ik8f+Z4xK+ZX87uvtCp7H0z8b6a+frL80Y3E8c6Mqfl+MNlRaqEniJ3kTHyTdl7auL0A7fl+eeMckxbjn+wT6QvjHGP62n/pkn3ZKKklSNM95BucNUqRMRWgIh4mFTZnSvpY6SKoN5Y4pciohyp9fLLiNic19tBGplS7xTSDcL3ApsiteR2RMT3I+L74xC/IGmmpNmklui6nJ9tpDv2te6V9NY8/zNJCwEkHUcaQVMvIqISEd+OiLcBR5JGciwmdVPsT/yCpB7SvYZ+0qU0pNEt3Q3Sht0PavUCA3mDj45H/LGOGR9No3HdY4kr6ZC83S9KenPdsr9vEH+s4+Nn1U/AHfk8mtUk7uyR4ub4i2vmZ0j6bP6cXp+vTmwMJuM7E+cC55BuCNUS6eZLrackvTQi7gaIiK2SfofUV3hSg7THEn9QUn+uqE+pZiJd8u5VUUdEBfi4pJvy/08xSvmPNT6pgvspqRxC0hER8YSkAfb+knk78AmlB22eBn4k6THSMK63N0h7j/UjYojUj7tMDR7uGWP8z5G6moqkL6WblB7WeTnpwal6nwWWS/oJqR/+IwBKD0ptGIf4N5K6l86KiCdz3MNJVwM3kq4Sdu+odPJeKeRFpO6zfYqbfZ40iuRfgN+XdCGpb3oXqXzq/QOpf3kqabjil0jdPRcAnyZ1cdR6mjQSptY8YAXp1YPP28e4AB8iXUVBGlP/JPB60kipz+Q8WasOdJN+rBPpg/3KEZZdX/f3fOpu9NQsa3THv+X4QO8I8eZQM3RwlP34beBDY9jvMcWvWa8fOGaEZYeQRkWcwggPOuR4YxqZsw/xjyQ/EAPMIN14WjRK/BNznBEfFtnX+Ix9zHjL47rHEjfHv7vu7/eSbszNpvEojrGOjx/LUNeW4+ZlK0badqO8eGpyXh7oDHjy1E4TYx8z3vK47rHEzWH3kbrjasMuJQ0tfKRB/NHGx98zwnZbGuq6D3HXsvtBlzXs+YTlXvcePI0+Tbo+arMJ9iZSi/X7uY96A2k0zyzSQzP13s/Iv5nzzv2IC2mI4GtqAyLiH0iV32CD+F/LXV1ERPX3YyQdSxrbvZeIWBsRF5H28VbSFVhDY4kL/F9SZT4A/CPpSnO4G+nuUdazBib98DyzZ0v98M/xjD+Rabcaf7ShrvsTd3/zbq6ozVom6dGIeM5ExJ/ItCc6/kTnxSbnqA+zCSNp5UiL2Hv455jiT2TaEx1/ovNio3NFbbansQz/HGv8iUx7sufdRuGK2mxP3yA9nbrXDS9Jt+1n/IlMe7Ln3UbhPmozszbn4XlmZm3OFbWZWZtzRW1m1uZcUZuZtbn/D8izAtsRgG2oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(MNIST_NN_Hessian_diag_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
